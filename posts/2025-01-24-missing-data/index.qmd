---
title: "The Missing Medical Data Holding Back AI"
date: "2025-01-24"
image: "/posts/2025-01-24-missing-data/negative-space-header.jpg"
description: "The negative spaces of what data is missing shape how AI is applied to healthcare."
author: "Rachel Thomas"
categories: [ethics, machine learning, science]
toc: true
---

Amidst the barrage of executive orders and announcements Trump made during his first week in office are two which stand in contradiction to each other: 
 
- He announced a [freeze on communications](https://apnews.com/article/trump-health-communications-cdc-hhs-fda-1eeca64c1ccc324b31b779a86d3999a4) from scientific and health agencies, stopping them from sharing health data with the public, including infectious disease data about the emerging H5N1 bird flu outbreak. The CDC was unable to send out its [weekly MMWR report](https://www.medpagetoday.com/infectiousdisease/generalinfectiousdisease/113905) for the first time in 60 years. Without data, it can be nearly impossible to understand, much less respond, to growing threats.
- He announced a [large investment in AI](https://apnews.com/article/trump-ai-openai-oracle-softbank-son-altman-ellison-be261f8a8ee07a0623d4170397348c41), including promises to use AI to analyze health records, help doctors care for patients, and treat cancer. 

Hiding health-related data from the public does not improve the lives of patients. These orders exemplify common misunderstandings and obfuscations about the relationship between [data, AI, and power](https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/).  As I wrote in a [previous post](https://rachel.fast.ai/posts/2024-02-20-ai-medicine/), claims that AI will cure cancer are often used as superficial marketing, ignoring the ways that AI could further disempower patients (whose knowledge and experiences are already disregarded by the medical system).

The orders for scientific agencies to pause communications are a particularly vivid and drastic example of the [political nature of data](https://rachel.fast.ai/posts/2021-10-12-medicine-political/). However, choices about what data is collected and who it is made available to have been shaped by social influences, financial factors, and power disparities long before this past week.

## Missing Data Sets

A decade ago, Mimi Onuoha coined the concept of [Missing Data Sets](https://github.com/MimiOnuoha/missing-datasets).  She uses this term specifically to refer to “*blank spots that exist in spaces that are otherwise data-saturated*.” So it’s not just that this data does not exist, but that it ought to exist. 

Originally writing in 2016, Onuoha gives the example of how “*traditionally there has been little history of standardized and rigorous data collected about police brutality… The group who would make the most sense to monitor this issue—the law enforcement agents who create the data set in the first place—have no incentive to actually gather such data, which could prove incriminating*.”

Missing Datasets are not just a USA-based phenomenon. In early 2024, the [UK government announced](https://theconversation.com/the-uk-government-aims-to-stop-publishing-stats-on-homeless-peoples-deaths-heres-why-thats-a-problem-223879) that it would stop collecting and publishing statistics about homeless people’s deaths, even as rising evictions and a housing shortage were making the issue more urgent than ever. Public outcry led the government to reconsider.  As another example, [wastewater data provides](https://thesicktimes.org/2024/02/06/how-we-track-covid-19-with-wastewater-and-other-data-sources/) a reliable indicator of covid rates, even in the absence of tests. The health department in my home state (Queensland, Australia) used to monitor covid wastewater data, but [stopped doing so in 2022](https://www.data.qld.gov.au/dataset/queensland-wastewater-surveillance-for-sars-cov-2), even as several other states in Australia have continued to collect and share such data. This was a political decision. The lack of this data for Queensland from late 2022 onwards registers as a blank space compared to [other countries](https://www.cdc.gov/nwss/rv/COVID19-nationaltrend.html) and [other](https://www.health.wa.gov.au/articles/a_e/coronavirus/covid19-wastewater-surveillance) [Australian states](https://www.health.nsw.gov.au/Infectious/covid-19/Pages/sewage-surveillance.aspx), and compared to Queensland’s own record in 2020-2022. There have been multiple covid waves since 2022. This is missing data.

![This graph from San Jose, California shows how closely wastewater data (in red) tracked with covid positive tests (green) up until most people stopped testing in mid-2022. In Queensland, we do not have access to this data.](covid-wastewater.jpg){width=70%}

Onuoha explains several reasons that [data may be missing](https://github.com/MimiOnuoha/missing-datasets). Those who could collect it lack incentives to do so, or in some cases may even want to hide or obscure it.  Another possible reason is that the data in question may be of a type that resists straight-forward quantification or doesn’t fit with our current modes of collection.  Her work also reminds us that data won’t solve all problems, and that in some cases missing data can function as protection for disadvantaged groups.

## Decades of work, not instant magic

Some people mistakenly believe AI can just be sprinkled on a problem to achieve a magic solution, without understanding the many necessary underlying ingredients. The example of AlphaFold, whose creators won a Nobel Prize in Chemistry for their work, disproves these misconceptions. AlphaFold can predict the 3D structures of proteins with unprecedented accuracy. While clever algorithmic innovations were pivotal to AlphaFold,  its success would not have been possible without a large, high-quality dataset that thousands of researchers contributed to for decades.

![AlphaFold takes a string of amino acids (on the left) and converts it into a 3D structure (on the right)](insulin-2ways.jpg){width=70%}

The construction of the dataset that made AlphaFold possible began a full 50 years earlier. The Protein Data Bank (PDB) was [announced in 1971](https://www.nature.com/articles/newbio233223b0) as a database to store information about the 3D structures of proteins. The files were originally shared and distributed using magnetic tape data storage. Initially, just a handful of entries were added to the database each year.  By 1980, there were a total of 69 entries present in the database.  However, that number [grew exponentially](https://www.rcsb.org/stats/growth/growth-released-structures), reaching 500 entries (cumulative) by 1990, 34,000 entries by 2005, and nearly 200,000 entries by 2022.  Access to the data was updated from magnetic tapes to the world wide web. 

![The number of proteins stored in PDB grew exponentially with time](PDB-per-year.jpg){width=70%}

In the mid-1990s, a [bi-annual competition](https://onlinelibrary.wiley.com/doi/10.1002/prot.340230303) known as CASP (Critical Assessment of Structure Prediction) was created, in which teams were given sequences of amino acids and asked to predict the 3D structure.  The existence and quality of the PDB and CASP are what led to the creation of AlphaFold, which shattered all previous records of prediction accuracy by a large factor. 

AlphaFold wouldn’t have been possible without the rich data of the PDB. Machine learning engineer [Abhishaike Mahajan writes](https://www.owlposting.com/p/wet-lab-innovations-will-lead-the),  “*In my opinion, what Alphafold2 pulled off — applying a clever model to a large body of pre-existing data to revolutionize a field — is something that will be extremely hard to replicate. Why? Because we’re almost out of that pre-existing data. If we had enough, sure, throw ML at it and call it a day, just as Alphafold2 did. But we don’t have that luxury anymore*.” 

Mahajan argues that [“*We are running out of data*,”](https://www.owlposting.com/p/wet-lab-innovations-will-lead-the) and that the next big innovations of AI applied to biology will require new wet-lab techniques to collect larger quantities of different biological data types than currently possible. 

## AI projects begin at the wrong starting point

Many machine learning projects begin with an existing dataset, and ask “what can we do with this data?” However, this ignores all the data that we don’t have and ends up overlooking many important questions. The harder question is, “what are the biggest questions in your area, and what data would be useful to answering them?” 

In some cases, technical limitations prevent the collection of more, better, or different data.  In the case of PDB and CASP, creating those datasets required large teams working for decades to produce, curate, and organize data.

One thing that is holding back the application of AI to medicine is lack of the **right** data. It is not just that medical data may be scattered or hard to access; in many cases, the most interesting variables aren’t being measured or collected at all. Scores of useful and high impact data are not being gathered. For example, widespread medical biases often lead doctors to incorrectly dismiss the pain or physiological symptoms of patients as “anxiety” or “drug-seeking” behavior.  In these cases, doctors may fail to record relevant observations or run tests that could gather valuable data.  Promises about what AI can achieve with electronic health records must be tempered with the awareness that the data within is too often biased, incorrect, or missing.

![An AI analysis of electronic health records will be shaped by all the above biases in diagnosis delays, pain mismanagement, and misdiagnoses](med-bias-research.jpg){width=85%}

As another example, many people have observed that an infection was the trigger for onset of Type 1 Diabetes in themselves or their children, yet they often don’t know which type of virus caused that infection. Determining causality around this requires large longitudinal studies, which are expensive and difficult to run. 

AI is great at finding patterns in existing data. However, AI will not be able to solve this problem of missing and erroneous underlying data. 

## Asking the right questions

The most fundamental machine learning question, prior to the questions I mentioned above, is “what type of society do we want to live in?”  

When [school districts implemented a computer program](https://archive.is/OdM2b) to automatically fire supposedly low-performing teachers, there were numerous issues with the underlying algorithm and data.  One key type of data used as input was student test scores, which had often been altered due to cheating scandals by school administrators. The algorithms were also based on the dubious assumption that changes in standardized test scores were a reasonable proxy for teacher quality. 

![Washington Post headline about a teacher who was loved by students and parents, but fired by an algorithm](teacher-fired.jpg){width=70%}

Test scores don’t capture a teacher’s creativity, care for their students, or ingenuity.  They don’t capture the challenges their particular students are facing, or how those students may grow and flourish apart from test scores.  

This is an example of an algorithm where there was low quality data, the wrong data, and faulty assumptions. However, even if it had been implemented differently, the whole premise would still be a terrible idea. Many of us (myself included) find the idea of a society where we use computerized algorithms to fire teachers to be dystopian. The answer to “How can we best use AI to fire teachers?” is that we shouldn’t.

## Negative spaces

The decisions around which, where, and how data is collected, and who it is shared with, all exert a strong but often overlooked influence on the shape of scientific research and algorithm creation.  As I dive deeper into the intersection of microbiology and machine learning, I am seeking to understand not just the data that I’m shown, but also the factors shaping its collection and the negative spaces of what is missing.

![Negative Space, image by Boris Thaser, Wikimedia Commons](negative-space.jpg){width=45%}

We are in a disturbing era, in which relevant health and safety data that we previously had access to are actively being cut off. Issues of bias and politics that dismiss the viewpoints of marginalized groups were already bad and seem to be worsening.  

While promises of AI improving healthcare may seem appealing, systems that ignore patient expertise risk building on faulty premises and causing more harm than good.

## Further Reading

- [Lessons from archives: strategies for collecting sociocultural data in machine learning](https://dl.acm.org/doi/10.1145/3351095.3372829) by Eun Seo Jo and Timnit Gebru, on lessons machine learning practitioners could learn from the library sciences
- [On Missing Data Sets](https://github.com/MimiOnuoha/missing-datasets) by Mimi Onuoha
- [The end of forgetting: Strategic agency beyond the panopticon](https://www.researchgate.net/publication/258173934_The_end_of_forgetting_Strategic_agency_beyond_the_panopticon) by Jonah Bossewitch and Aram Sinnreich, on how information flow relates to power dynamics
- [“AI will cure cancer” misunderstands both AI and medicine](https://rachel.fast.ai/posts/2024-02-20-ai-medicine/) by Rachel Thomas
- [Avoiding Data Disasters](https://rachel.fast.ai/posts/2021-11-04-data-disasters/) by Rachel Thomas


<br><br>

You can subscribe to be notified of new blog posts by submitting your email below:

<script type="text/javascript" src="https://campaigns.zoho.com.au/js/zc.iframe.js"></script>
<iframe scrolling="no" frameborder="0" id="iframewin" width="100%" height="100%" src="https://zcmp-pd.maillist-manage.com.au/ua/Optin?od=11d0c075b7ed49&zx=11a17553b1&tD=156971d471c7b09&sD=156971d471c7cb3"></iframe>

