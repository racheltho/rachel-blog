<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rachel Thomas">
<meta name="dcterms.date" content="2018-07-16">
<meta name="description" content="AutoML is being heavily hyped– but would AugmentedML be a better approach?">

<title>Rachel Thomas, PhD - An Opinionated Introduction to AutoML and Neural Architecture Search</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Rachel Thomas, PhD - An Opinionated Introduction to AutoML and Neural Architecture Search">
<meta property="og:description" content="an AI researcher going back to school for immunology">
<meta property="og:image" content="https://rachel.fast.ai/posts/2018-07-16-automl2/automl-headlines.png">
<meta property="og:site-name" content="Rachel Thomas, PhD">
<meta property="og:image:height" content="905">
<meta property="og:image:width" content="2160">
<meta name="twitter:title" content="Rachel Thomas, PhD - An Opinionated Introduction to AutoML and Neural Architecture Search">
<meta name="twitter:description" content="an AI researcher going back to school for immunology">
<meta name="twitter:image" content="https://rachel.fast.ai/posts/2018-07-16-automl2/automl-headlines.png">
<meta name="twitter:creator" content="@math_rachel">
<meta name="twitter:site" content="@math_rachel">
<meta name="twitter:image-height" content="905">
<meta name="twitter:image-width" content="2160">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Rachel Thomas, PhD</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/racheltho" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/math_rachel" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/rachel-thomas-942a7923/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">An Opinionated Introduction to AutoML and Neural Architecture Search</h1>
                  <div>
        <div class="description">
          AutoML is being heavily hyped– but would AugmentedML be a better approach?
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">technical</div>
                <div class="quarto-category">machine learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Rachel Thomas </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 16, 2018</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<!--Zoho Campaigns Web-Optin Form's Header Code Starts Here-->

<script type="text/javascript" src="https://zcmp-pd.maillist-manage.com.au/js/optin.min.js" onload="setupSF('sf3zdfb6745d9acad780281060170790e51ac477370600802a15ea307e524ccb10b7','ZCFORMVIEW',false,'light',false,'0')"></script>
<script type="text/javascript">
    function runOnFormSubmit_sf3zdfb6745d9acad780281060170790e51ac477370600802a15ea307e524ccb10b7(th){
        /*Before submit, if you want to trigger your event, "include your code here"*/
    };
</script>

<style>
.quick_form_8_css * {
    -webkit-box-sizing: border-box !important;
    -moz-box-sizing: border-box !important;
    box-sizing: border-box !important;
    overflow-wrap: break-word
}
@media only screen and (max-width: 600px) {.quick_form_8_css[name="SIGNUP_BODY"] { width: 100% !important; min-width: 100% !important; margin: 0px auto !important; padding: 0px !important } .SIGNUP_FLD { width: 90% !important; margin: 10px 5% !important; padding: 0px !important } .SIGNUP_FLD input { margin: 0 !important; border-radius: 25px !important } }
</style>

<!--Zoho Campaigns Web-Optin Form's Header Code Ends Here--><!--Zoho Campaigns Web-Optin Form Starts Here-->

<div id="sf3zdfb6745d9acad780281060170790e51ac477370600802a15ea307e524ccb10b7" data-type="signupform" style="opacity: 1;">
    <div id="customForm">
        <div class="quick_form_8_css" style="background-color: rgb(255, 255, 255); z-index: 2; font-family: Arial; border-width: 1px; border-color: rgb(235, 235, 235); overflow: hidden; width: 202px; height: 160px; border-style: none" name="SIGNUP_BODY">
            <div>
                <div style="font-size: 14px; font-family: Arial; font-weight: bold; color: rgb(100, 100, 100); text-align: left; padding: 10px 20px 5px; width: 100%; display: block" id="SIGNUP_HEADING">Receive new blog posts</div>
                <div style="position:relative;">
                    <div id="Zc_SignupSuccess" style="display:none;position:absolute;margin-left:4%;width:90%;background-color: white; padding: 3px; border: 3px solid rgb(194, 225, 154);  margin-top: 10px;margin-bottom:10px;word-break:break-all">
                        
<table data-quarto-postprocess="true" width="100%" data-cellpadding="0" data-cellspacing="0" data-border="0" class="table">
<tbody>
<tr class="odd">
<td width="10%"><img src="https://zcmp-pd.maillist-manage.com.au/images/challangeiconenable.jpg" class="successicon img-fluid" data-align="absmiddle"></td>
<td><span id="signupSuccessMsg" style="color: rgb(73, 140, 132); font-family: sans-serif; font-size: 14px;word-break:break-word">&nbsp;&nbsp;Thank you for Signing Up</span></td>
</tr>
</tbody>
</table>


                    </div>
                </div>
                <form method="POST" id="zcampaignOptinForm" style="margin: 0px; width: 100%" action="https://zcmp-pd.maillist-manage.com.au/weboptin.zc" target="_zcSignup">
                    <div style="background-color: rgb(255, 235, 232); padding: 10px; color: rgb(210, 0, 0); font-size: 11px; margin: 20px 10px 0px; border: 1px solid rgb(255, 217, 211); opacity: 1; display: none" id="errorMsgDiv">Please correct the marked field(s) below.</div>
                    <div style="position: relative; margin: 10px; height: 30px; display: inline-block; width: 176px" class="SIGNUP_FLD">
                        <div id="Zc_SignupSuccess" style="position: absolute; width: 87%; background-color: white; padding: 3px; border: 3px solid rgb(194, 225, 154); margin-bottom: 10px; word-break: break-all; opacity: 1; display: none">
                            <div style="width: 20px; padding: 5px; display: table-cell">
                                <img class="successicon" src="https://campaigns.zoho.com/images/challangeiconenable.jpg" style="width: 20px">
                            </div>
                            <div style="display: table-cell">
                                <span id="signupSuccessMsg" style="color: rgb(73, 140, 132); font-family: sans-serif; font-size: 14px; line-height: 30px; display: block"></span>
                            </div>
                        </div>
                        <input type="text" style="font-size: 14px; border: 1px solid rgb(157, 155, 155); border-radius: 0px; width: 100%; height: 100%; z-index: 4; outline: none; padding: 5px 10px; color: rgb(100, 100, 100); text-align: left; font-family: Arial; background-color: rgb(255, 255, 255); box-sizing: border-box" placeholder="Email" changeitem="SIGNUP_FORM_FIELD" name="CONTACT_EMAIL" id="EMBED_FORM_EMAIL_LABEL">
                    </div>
                    <div style="position: relative; margin: 10px; width: 100px; height: 30px; text-align: left; display: inline-block" class="SIGNUP_FLD">
                        <input type="button" style="text-align: center; border-radius: 5px; width: 100%; height: 100%; z-index: 5; border: 0px; color: rgb(255, 255, 255); cursor: pointer; outline: none; font-size: 14px; background-color: rgb(66, 148, 118); margin: 0px 0px 0px -5px" name="SIGNUP_SUBMIT_BUTTON" id="zcWebOptin" value="Subscribe">
                    </div>
                    <input type="hidden" id="fieldBorder" value="">
                    <input type="hidden" id="submitType" name="submitType" value="optinCustomView">
                    <input type="hidden" id="emailReportId" name="emailReportId" value="">
                    <input type="hidden" id="formType" name="formType" value="QuickForm">
                    <input type="hidden" name="zx" id="cmpZuid" value="11a17553b1">
                    <input type="hidden" name="zcvers" value="2.0">
                    <input type="hidden" name="oldListIds" id="allCheckedListIds" value="">
                    <input type="hidden" id="mode" name="mode" value="OptinCreateView">
                    <input type="hidden" id="zcld" name="zcld" value="156971d471c7bcf">
                    <input type="hidden" id="zctd" name="zctd" value="156971d471c7b09">
                    <input type="hidden" id="document_domain" value="">
                    <input type="hidden" id="zc_Url" value="zcmp-pd.maillist-manage.com.au">
                    <input type="hidden" id="new_optin_response_in" value="2">
                    <input type="hidden" id="duplicate_optin_response_in" value="0">
                    <input type="hidden" name="zc_trackCode" id="zc_trackCode" value="ZCFORMVIEW">
                    <input type="hidden" id="zc_formIx" name="zc_formIx" value="3zdfb6745d9acad780281060170790e51ac477370600802a15ea307e524ccb10b7">
                    <input type="hidden" id="viewFrom" value="URL_ACTION">
                    <span style="display: none" id="dt_CONTACT_EMAIL">1,true,6,Contact Email,2</span>
                </form>
            </div>
        </div>
    </div>
    <img src="https://zcmp-pd.maillist-manage.com.au/images/spacer.gif" id="refImage" onload="referenceSetter(this)" style="display:none;">
</div>
<input type="hidden" id="signupFormType" value="QuickForm_Horizontal">
<div id="zcOptinOverLay" oncontextmenu="return false" style="display:none;text-align: center; background-color: rgb(0, 0, 0); opacity: 0.5; z-index: 100; position: fixed; width: 100%; top: 0px; left: 0px; height: 988px;"></div>
<div id="zcOptinSuccessPopup" style="display:none;z-index: 9999;width: 800px; height: 40%;top: 84px;position: fixed; left: 26%;background-color: #FFFFFF;border-color: #E6E6E6; border-style: solid; border-width: 1px;  box-shadow: 0 1px 10px #424242;padding: 35px;">
    <span style="position: absolute;top: -16px;right:-14px;z-index:99999;cursor: pointer;" id="closeSuccess">
        <img src="https://zcmp-pd.maillist-manage.com.au/images/videoclose.png">
    </span>
    <div id="zcOptinSuccessPanel"></div>
</div>

<!--Zoho Campaigns Web-Optin Form Ends Here-->
</div></div>
        
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><em>This is part 2 in a series. Check out <a href="https://rachel.fast.ai/posts/2018-07-12-automl1/">part 1 here</a> and <a href="http://www.fast.ai/2018/07/23/auto-ml-3/">part 3 here</a>.</em></p>
<p>Researchers from CMU and DeepMind recently released an interesting new paper, called <a href="https://www.groundai.com/project/darts-differentiable-architecture-search/">Differentiable Architecture Search (DARTS)</a>, offering an alternative approach to <em>neural architecture search</em>, a very hot area of machine learning right now. Neural architecture search has been heavily hyped in the last year, with Google’s CEO <a href="https://blog.google/technology/ai/making-ai-work-for-everyone/">Sundar Pichai</a> and Google’s Head of AI <a href="https://www.youtube.com/watch?v=kSa3UObNS6o">Jeff Dean</a> promoting the idea that <em>neural architecture search</em> and the <em>large amounts of computational power</em> it requires <strong>are essential to making machine learning available to the masses</strong>. Google’s work on neural architecture search has been widely and adoringly covered by the tech media (see <a href="https://nordic.businessinsider.com/google-has-started-using-ai-to-build-more-advanced-ai-2017-5/">here</a>, <a href="https://www.wired.com/story/googles-learning-software-learns-to-write-learning-software/">here</a>, <a href="https://www.zdnet.com/article/google-launches-cloud-automl-an-effort-to-simplify-and-automate-the-grunt-work-behind-ai-and-machine/">here</a>, and <a href="https://venturebeat.com/2018/05/09/googles-ai-chief-on-automl-autonomous-weapons-and-the-future/">here</a> for examples).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="automl-headlines.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Headlines from just a few of the many, many articles written about Google’s AutoML and Neural Architecture Search</figcaption>
</figure>
</div>
<p>During his <a href="https://www.youtube.com/watch?v=kSa3UObNS6o">keynote</a> (starts around 22:20) at the TensorFlow DevSummit in March 2018, Jeff Dean posited that perhaps in the future <strong>Google could replace machine learning expertise with 100x computational power</strong>. He gave computationally expensive <em>neural architecture search</em> as a primary example (the only example he gave) of why we need 100x computational power in order to make ML accessible to more people.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="jeff_dean.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Slide from Jeff Dean’s Keynote at the TensorFlow Dev Summit</figcaption>
</figure>
</div>
<p>What is neural architecture search? Is it the key to making machine learning available to non-machine learning experts? I will dig into these questions in this post, and in my next post, I will look specifically at Google’s AutoML. Neural architecture search is a part of a broader field called <em>AutoML</em>, which has also been receiving a lot of hype and which we will consider first.</p>
<p>Part 2 table of contents:</p>
<ul>
<li>
<a href="#auto-ml">What is AutoML?</a>
</li>
<li>
<a href="#useful-automl">How useful is AutoML?</a>
</li>
<li>
<a href="#nas">What is neural architecture search?</a>
</li>
<li>
<a href="#darts">What about DARTS?</a>
</li>
<li>
<a href="#nas-useful">How useful is Neural Architecture Search?</a>
</li>
<li>
<a href="#vs">How else could we make machine learning practitioners more effective?</a>
</li>
</ul>
<h2 id="auto-ml" class="anchored">
What is AutoML?
</h2>
<p>The term AutoML has traditionally been used to describe <em>automated methods for model selection and/or hyperparameter optimization</em>. These methods exist for many types of algorithms, such as random forests, gradient boosting machines, neural networks, and more. The field of AutoML includes <a href="https://www.automl.org/automl/">open-source AutoML libraries</a>, <a href="https://www.automl.org/workshops/">workshops</a>, <a href="https://www.automl.org/automl/literature-on-neural-architecture-search/">research</a>, and <a href="http://automl.chalearn.org/">competitions</a>. Beginners often feel like they are just guessing as they test out different hyperparameters for a model, and automating the process could make this piece of the machine learning pipeline easier, as well as speeding things up even for experienced machine learning practitioners.</p>
<p>There are a number of AutoML libraries, the oldest of which is <a href="http://www.cs.ubc.ca/labs/beta/Projects/autoweka/">AutoWEKA</a>, which was first released in 2013 and automatically chooses a model and selects hyperparameters. Other notable AutoML libraries include <a href="http://automl.github.io/auto-sklearn/stable/">auto-sklearn</a> (which extends AutoWEKA to python), <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html">H2O AutoML</a>, and <a href="http://automl.info/tpot/">TPOT</a>. <a href="https://www.automl.org/">AutoML.org</a> (formerly known as ML4AAD, Machine Learning for Automated Algorithm Design) has been organzing <a href="https://www.automl.org/workshops/">AutoML workshops</a> at the academic machine learning conference <a href="https://icml.cc/">ICML</a> yearly since 2014.</p>
<h2 id="#useful-automl" class="anchored">
How useful is AutoML?
</h2>
<p>AutoML provides a way to select models and optimize hyper-parameters. It can also be useful in getting a baseline to know what level of performance is possible for a problem. So does this mean that data scientists can be replaced? Not yet, as we need to keep the context of <a href="https://rachel.fast.ai/posts/2018-07-12-automl1/"><em>what else it is that machine learning practitioners do</em></a>.</p>
<p>For many machine learning projects, choosing a model is just one piece of the <a href="http://www.fast.ai/2018/07/12/auto-ml-1/#complex">complex process</a> of building machine learning products. As I covered in my <a href="https://rachel.fast.ai/posts/2018-07-12-automl1/">previous post</a>, <a href="http://www.fast.ai/2018/07/12/auto-ml-1/#fail">projects can fail</a> if participants don’t see how interconnected the various parts of the pipeline are. I thought of <a href="http://www.fast.ai/2018/07/12/auto-ml-1/#steps">over 30 different steps</a> that can be involved in the process. I highlighted two of the most time-consuming aspects of machine learning (in particular, deep learning) as <strong>cleaning data</strong> (and <a href="http://www.fast.ai/2018/07/12/auto-ml-1/#steps">yes, this is an inseparable part of machine learning</a>) and <a href="http://www.fast.ai/2018/07/12/auto-ml-1/#training"><strong>training models</strong></a>. While AutoML can help with selecting a model and choosing hyperparameters, it is important to keep perspective on what other data expertise is still needed and on the difficult problems remain.</p>
<p>I will suggest some alternate approaches to AutoML for making machine learning practitioners more effective in the <a href="#id">final section</a>.</p>
<h2 id="nas" class="anchored">
What is neural architecture search?
</h2>
<p>Now that we’ve covered some of what AutoML is, let’s look at a particularly active subset of the field: <strong>neural architecture search</strong>. Google CEO Sundar Pichai <a href="https://blog.google/technology/ai/making-ai-work-for-everyone/">wrote that</a>, <i>“designing neural nets is extremely time intensive, and requires an expertise that limits its use to a smaller community of scientists and engineers. That’s why we’ve created an approach called AutoML, showing that <b> it’s possible for neural nets to design neural nets</b>.”</i></p>
<p>What Pichai refers to as using “neural nets to design neural nets” is known as <strong>neural architecture search</strong>; typically <strong>reinforcement learning</strong> or <strong>evolutionary algorithms</strong> are used to design the new neural net architectures. This is useful because it allows us to discover architectures far more complicated than what humans may think to try, and these architectures can be optimized for particular goals. Neural architecture search is often very computationally expensive.</p>
<p>To be precise, neural architecture search usually involves learning something like a layer (often called a “cell”) that can be assembled as a stack of repeated cells to create a neural network:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="evolvable-cell.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Diagram from Zoph et. al.&nbsp;2017. On the left is the full neural network of stacked cells, and on the right is the inside structure of a cell</figcaption>
</figure>
</div>
<p>The literature of <a href="http://www.ml4aad.org/automl/literature-on-neural-architecture-search/">academic papers on neural architecture search</a> is extensive, so I will highlight just a few recent papers here:</p>
<ul>
<li>The term <em>AutoML</em> jumped to “mainstream” prominence with <a href="https://ai.googleblog.com/2017/05/using-machine-learning-to-explore.html">work by Google AI researchers</a> (<a href="https://arxiv.org/pdf/1611.01578.pdf">paper here</a>) Quoc Le and Barret Zoph, which was featured <a href="https://www.technologyreview.com/s/607894/why-googles-ceo-is-excited-about-automating-artificial-intelligence/">at Google I/O in May 2017</a>. This work used reinforcement learning to find new architectures for the computer vision problem Cifar10 and the NLP problem Penn Tree Bank, and achieved similar results to existing architectures.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="automl_diagram.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Diagram from Le and Zoph’s blog post: the simpler architecture on the left was designed by a human and the more complicated architecture on the right was designed by a neural net.</figcaption>
</figure>
</div>
<ul>
<li><p><strong>NASNet</strong> from <a href="https://arxiv.org/abs/1707.07012">Learning Transferable Architectures for Scalable Image Recognition</a> (<a href="https://ai.googleblog.com/2017/11/automl-for-large-scale-image.html">blog post here</a>). This work searches for an architectural building block on a small data set (Cifar10) and then builds an architecture for a large data set (ImageNet). This research was <strong>very computationally intensive</strong> with it taking 1800 GPU days (the equivalent of almost 5 years for 1 GPU) to learn the architecture (the team at Google used <strong>500 GPUs for 4 days</strong>!).</p></li>
<li><p><strong>AmoebaNet</strong> from <a href="https://arxiv.org/abs/1802.01548">Regularized Evolution for Image Classifier Architecture Search</a> This research was <strong>even more computationally intensive</strong> than NASNet, with it taking the equivalent of 3150 GPU days (the equivalent of almost 9 years for 1 GPU) to learn the architecture (the team at Google used 450 K40 GPUs for 7 days!). AmoebaNet consists of “cells” learned via an <em>evolutionary algorithm</em>, showing that artificially-evolved architectures can match or surpass human-crafted and reinforcement learning-designed image classifiers. After incorporating <a href="https://www.fast.ai/posts/2018-04-30-dawnbench-fastai.html">advances from fast.ai</a> such as an aggressive learning schedule and changing the image size as training progresses, AmoebaNet is now the <strong>cheapest way to train ImageNet on a single machine</strong>.</p></li>
<li><p><a href="https://arxiv.org/pdf/1802.03268.pdf"><strong>Efficient Neural Architecture Search (ENAS)</strong></a>: used much fewer GPU-hours than previously existing automatic model design approaches, and notably, was 1000x less expensive than standard Neural Architecture Search. This research was done using a single GPU for just 16 hours.</p></li>
</ul>
<h3 id="darts" class="anchored">
What about DARTS?
</h3>
<p><a href="https://www.groundai.com/project/darts-differentiable-architecture-search/">Differentiable architecture search (DARTS)</a>. This research was recently released from a team at Carnegie Mellon University and DeepMind, and I’m excited about the idea. DARTS assumes the space of candidate architectures is continuous, not discrete, and this allows it to use gradient-based aproaches, which are vastly more efficient than the inefficient black-box search used by most neural architecture search algorithms.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="darts.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Diagram from DARTS, which treats the space of all possible architectures as continuous, not discrete</figcaption>
</figure>
</div>
<p>To learn a network for Cifar-10, <strong>DARTS takes just 4 GPU days</strong>, compared to <strong>1800 GPU days for NASNet</strong> and <strong>3150 GPU days for AmoebaNet</strong> (all learned to the same accuracy). This is a huge gain in efficiency! Although more exploration is needed, this is a promising research direction. Given how Google frequently equates neural architecture search with huge computational expense, efficient ways to do architecture search have most likely been under-explored.</p>
<h2 id="nas-useful" class="anchored">
How useful is Neural Architecture Search?
</h2>
<p>In his <a href="https://www.youtube.com/watch?v=kSa3UObNS6o">TensorFlow DevSummit keynote</a> (starts around 22:20), Jeff Dean suggested that a significant part of deep learning work is trying out different architectures. This was the only step of machine learning that Dean highlighted in his short talk, and I was surprised by his emphasis. Sundar Pichai’s <a href="https://blog.google/technology/ai/making-ai-work-for-everyone/">blog post</a> contained a similar assertion.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="neural_arch_search.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Jeff Dean’s slide showing that neural architecture search can try 20 different models to find the most accurate</figcaption>
</figure>
</div>
<p>However, choosing a model is just one piece of the <a href="http://www.fast.ai/2018/07/12/auto-ml-1/#complex">complex process</a> of building machine learning products. In most cases, architecture selection is nowhere near the hardest, most time-consuming, or most significant part of the problem. <strong>Currently, there is no evidence that each new problem would be best modeled with it’s own unique architecture,</strong> and most practitioners consider it unlikely this will ever be the case.</p>
<p>Organizations like Google working on architecture design and sharing the architectures they discover with the rest of us are providing an important and helpful service. However, the underlying architecture search method is only needed for that tiny fraction of researchers that are working on foundational neural architecture design. The rest of us can just use the architectures they find via <a href="http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html#transfer"><em>transfer learning</em></a>.</p>
<h2 id="vs" class="anchored">
How else could we make machine learning practitioners more effective? AutoML vs.&nbsp;Augmented ML
</h2>
<p>The field of <em>AutoML</em>, including <em>neural architecture search</em>, has been largely focused on the question: <b>how can we automate model selection and hyperparameter optimization?</b> However, automation ignores the important role of human input. I’d like to propose an alternate question: <strong>how can humans and computers work together to make machine learning more effective?</strong> The focus of <em>augmented ML</em> is on figuring out how a human and machine can best work together to take advantage of their different strengths.</p>
<p>An example of <em>augmented ML</em> is Leslie Smith’s <a href="https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0"><em>learning rate finder</em></a> (<a href="https://arxiv.org/abs/1506.01186">paper here</a>), which is implemented in the <a href="https://github.com/fastai/fastai">fastai library</a> (a high level API that sits on top of PyTorch) and taught as a key technique in our <a href="http://course.fast.ai/">free deep learning course</a>. The <em>learning rate</em> is a hyperparameter that can determine how quickly your model trains, or even whether it successfully trains at all. The learning rate finder allows a human to find a good learning rate in a single step, by looking at a generated chart. It’s faster than AutoML approaches to the same problem, improves the data scientist’s understanding of the training process, and encourages more powerful multi-step approaches to training models.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="learning_rate_finder.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Diagram from Surmenok’s blog post on the learning rate finder, showing relationship between learning rate and loss</figcaption>
</figure>
</div>
<p>There’s another problem with the focus on automating hyperparameter selection: it overlooks the possibility that some types of model are more widely useful, have fewer hyperparameters to tune, and are less sensitive to choice of hyperparameters. For example, a key benefit of random forests over gradient boosting machines (GBMs) is that random forests are more robust, whereas GBMs tend to be fairly sensitive to minor changes in hyperparameters. As a result, random forests are widely used in industry. <strong>Researching ways to effectively remove hyperparameters (through smarter defaults, or through new models) can have a huge impact.</strong> When I <a href="https://vimeo.com/214233053">first became interested</a> in deep learning in 2013, it was overwhelming to feel that there were such a huge number of hyperparameters, and I’m happy that newer research and tools has helped eliminate many of those (especially for beginners). For instance, in the fast.ai course, beginners start by only having to choose a single hyperparameter, the learning rate, and we even give you a tool to do that!</p>
<h2 id="end" class="anchored">
Stay tuned…
</h2>
<p>Now that we have an overview of what the fields of AutoML and neural architecture search are, we can take a closer look at Google’s AutoML in the next post.</p>
<p><strong>If you haven’t already, check out Part 1: <a href="http://www.fast.ai/2018/07/12/auto-ml-1/">What is it that machine learning practitioners do?</a> and Part 3: <a href="https://www.fast.ai/2018/07/23/auto-ml-3/">Google’s AutoML: Cutting Through the Hype</a> of this series.</strong></p>
<p><strong>Please be sure to check out Part 3 of this post next week!</strong></p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="racheltho/rachel-blog" data-repo-id="R_kgDOIxf7pQ" data-category="Announcements" data-category-id="DIC_kwDOIxf7pc4CcEZ1" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>