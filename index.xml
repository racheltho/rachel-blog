<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Rachel Thomas, PhD</title>
<link>https://rachel.fast.ai/index.html</link>
<atom:link href="https://rachel.fast.ai/index.xml" rel="self" type="application/rss+xml"/>
<description>an AI researcher going back to school for immunology</description>
<image>
<url>https://rachel.fast.ai/images/thomas-card.jpg</url>
<title>Rachel Thomas, PhD</title>
<link>https://rachel.fast.ai/index.html</link>
</image>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Mon, 05 Feb 2024 14:00:00 GMT</lastBuildDate>
<item>
  <title>How Immune Cells Communicate</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2024-02-06-cytokines2/index.html</link>
  <description><![CDATA[ 




<p><em>This post is part 2 in a series. Be sure to <a href="https://rachel.fast.ai/posts/2024-01-23-cytokines1/">read part 1 here</a>.</em></p>
<p>A key obstacle hindering medical research for a range of diseases is our lack of understanding of the immune system. <a href="https://www.freethink.com/health/human-immunome">Harvard Professor Wayne Koff described</a> his decades of HIV research, “<em>slowly, over time, we began to see that we understood a lot about HIV at the molecular level, but we didn’t know anything about ourselves. And the reason is that the immune system is incredibly complex</em>.”</p>
<p>Many diseases involve the immune system overreacting, underreacting, or having a mistargeted reaction. Deepening our understanding of the immune system is crucial for better understanding and treating a range of diseases. In <a href="https://rachel.fast.ai/posts/2024-01-23-cytokines1/">part 1 of this series</a>, I shared about the networks by which immune cells communicate and coordinate via the use of protein messengers called <em>cytokines</em>. These networks are complex and not fully mapped. Studying these networks is part of determining how and why the immune system reacts as it does. Here, I will share some more research on immune cell-cytokine networks.</p>
<section id="immune-cells-coordinate-like-a-social-network" class="level2">
<h2 class="anchored" data-anchor-id="immune-cells-coordinate-like-a-social-network">Immune Cells Coordinate Like a Social Network</h2>
<p>Immune cells and the cytokines they use to communicate can be analyzed using the same techniques as are used for social networks. Networks can be represented as matrices, in which each column/row represents a node, and the matrix values represent the presence or strength of connections between them. This type of representation underlies how the network of the internet is represented for search engines such as Google. Matrix math is everywhere! I covered many applications of it in the computational linear algebra course that Jeremy Howard and I designed and taught at University of San Francisco and fast.ai.</p>
<p>The <a href="https://www.nature.com/articles/ni.3693">paper ImmProt</a> sampled immune cells from the bloodstream of humans and used proteomics (the large-scale analysis of proteins) to study immune communication networks. The researchers considered 28 cell types in both steady and activated states, and over 10,000 proteins. ImmProt used several classic math techniques to analyze the network, including principal component analysis, supervised clustering, and Lasso regression analysis.</p>
<p>Cytokines bind to receptors on the surface of the cell that is receiving them. Receptors for some cytokines are found on many different types of immune cells (these receptors are said to be “broadly expressed”), while receptors for other cytokines may be expressed on a very limited number of cell types. The researchers found that there were two types of cytokine communication patterns: there were either many types of cells sending and few types receiving for a given cytokine, or there were few types of cells sending and many receiving. This is a directed, asymmetric information exchange.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2024-02-06-cytokines2/rieckmann-6h.jpg" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption class="figure-caption">A single type of message (in this case, CCL5/3) can be sent to many different cells (figure 6h from ImmProt)</figcaption>
</figure>
</div>
<p>The authors looked at the number of in-going and out-going communication between various cell types, and determined how much cross-talk there is between different clusters of cell types. In the above diagram, the outer circle lists cell types and the middle circle lists receptor and cytokine gene names. This picture shows that eosinophils and basophils (two cell types that evolved primarily to address parasites) send the cytokine CCL5/3 to a variety of other cells that receive the message using the receptor CCR3. The color of the lines indicates the type of cell sending the cytokine.</p>
<p>While many of the relationships found were well established in existing scientific papers, they also discovered new relationships, and validated two of these new relationships experimentally: one in-going and one out-going. <a href="https://www.nature.com/articles/ni.3693">The authors wrote</a>, “<em>The immune system displays an almost infinite diversity in cell types and activation states, and achieving completeness in both dimensions is particularly challenging for human cells</em>.”</p>
</section>
<section id="ai-does-not-replace-other-ways-of-knowing-about-the-world-benchtop-research-is-still-crucial" class="level2">
<h2 class="anchored" data-anchor-id="ai-does-not-replace-other-ways-of-knowing-about-the-world-benchtop-research-is-still-crucial">AI does not replace other ways of knowing about the world: benchtop research is still crucial</h2>
<p>AI is a powerful tool, but it does not replace other ways of knowing about the world, including <a href="https://rachel.fast.ai/posts/2022-06-01-qualitative/">qualitative research</a> (as I wrote about together with Louisa Bartolo) and benchtop quantitative experiments. Machine learning and AI techniques are great at learning patterns in existing data. However, they are limited by what types of data have been collected so far, and it is still crucial to continue running new laboratory-based experiments. For this reason, the recent <a href="https://www.nature.com/articles/s41586-023-06816-9">Immune Dictionary paper</a> was a valuable contribution to the field. The researchers gathered direct measurements of over &gt;1,400 cytokine-cell type pairings in an in vivo experiment.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2024-02-06-cytokines2/immune-dictionary-1.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Steps for creating a dictionary of immune gene expression signatures (Figure 1A from Immune Dictionary)</figcaption>
</figure>
</div>
<p>This study was significant because it consdiered all major immune cell types and all major cytokines (studies typically look at only 5 immune cell types) and was conducted in vivo (not in a culture). The researchers injected 86 different cytokines into individual mice and measured the responses of 17 types of immune cells in the mouse lymph nodes. They used single-cell RNA sequencing, which is more direct than considering ligand and receptor expression association data. They released their findings as an “Immune Dictionary” and developed <a href="https://www.immune-dictionary.org/app/home">accompanying computer software</a>. This software was then used to identify cytokine networks in tumors after checkpoint blockade therapy (a cancer therapy that helps to reactivate exhausted immune cells).</p>
<p><a href="https://www.nature.com/articles/s41586-023-06816-9">One key finding</a> was that the responses induced by cytokines are highly cell-specific. Rarer types of immune cells expressed a greater number of cytokine types than more common cell types. One rare cell type, typically not even covered in immunology courses, was found to express the highest number of distinct cytokines, influencing nearly every other cell type. This result suggests that rare immune cell types are crucial for cell-to-cell communication.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2024-02-06-cytokines2/immune-dictionary-software.jpg" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Software for the dictionary of 17+ immune cell types responding to 86 cytokines in vivo</figcaption>
</figure>
</div>
<p>Another important finding was that every immune cell type could be polarized into multiple states depending on the combination of cytokines that it received. The <a href="https://www.broadinstitute.org/news/new-dictionary-immune-responses-reveals-far-more-complexity-immune-system-previously-thought">two key researchers were surprised</a> at this level of plasticity and complexity in immune cell types, with even the most well-studied cytokines inducing more complex responses than previously expected.</p>
</section>
<section id="an-ongoing-area-of-research" class="level2">
<h2 class="anchored" data-anchor-id="an-ongoing-area-of-research">An Ongoing Area of Research</h2>
<p>This is an exciting area of research to follow. There is still much work to be done in more thoroughly understanding the intricate and complex ways immune cells coordinate with one another to respond to threats. Immune cell-cytokine networks are a great illustration of the power of interdisciplinary work, since NLP, mathematics, and bench top immunology research all provide important insights into the problem. And this is just one of several important problems in immunology where AI is being applied!</p>
<p>You can subscribe to be notified of new blog posts by submitting your email below:</p>
<script type="text/javascript" src="https://campaigns.zoho.com.au/js/zc.iframe.js"></script>
<iframe scrolling="no" frameborder="0" id="iframewin" width="100%" height="100%" src="https://zcmp-pd.maillist-manage.com.au/ua/Optin?od=11d0c075b7ed49&amp;zx=11a17553b1&amp;tD=156971d471c7b09&amp;sD=156971d471c7cb3">
</iframe>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>machine learning</category>
  <category>science</category>
  <guid>https://rachel.fast.ai/posts/2024-02-06-cytokines2/index.html</guid>
  <pubDate>Mon, 05 Feb 2024 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2024-02-06-cytokines2/rieckmann-network.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Applying AI to Immune Cell Networks</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2024-01-23-cytokines1/index.html</link>
  <description><![CDATA[ 




<section id="the-value-of-domain-expertise" class="level2">
<h2 class="anchored" data-anchor-id="the-value-of-domain-expertise">The value of domain expertise</h2>
<p>Back in 2016, Jeremy Howard and I founded the research lab <a href="https://www.fast.ai/posts/2016-10-07-fastai-launch.html">fast.ai</a>. At the time, deep learning (the technique behind recent advances in AI) was the purview of a small and homogeneous handful of practitioners. The standard approach was to have computer science PhDs tackle problems in domains they had little familiarity with.</p>
<p>Jeremy and I proposed an ambitious idea–we wanted to teach people from all domains and backgrounds to be able to use deep learning. We weren’t even sure if our goal was possible. However, <a href="https://course.fast.ai/">our online course</a> became one of the most popular deep learning courses in the world, and members of the fast.ai community went on to join top research labs and major tech companies, <a href="https://www.theverge.com/2018/5/7/17316010/fast-ai-speed-test-stanford-dawnbench-google-intel">win competitions against Google</a>, and launch their own startups.</p>
<p>A core part of our mission was the belief that the people closest to a topic best understand the problems in that area and are best equipped to address them. I’m now one of those people in another domain, as I have <a href="https://rachel.fast.ai/posts/2023-02-07-school-immunology/">immersed myself in the field of immunology</a>. I am particularly interested in studying the intersection of immunology and AI. In this 2-part series, I will share some exciting research at this intersection.</p>
</section>
<section id="a-most-complicated-system" class="level2">
<h2 class="anchored" data-anchor-id="a-most-complicated-system">A Most Complicated System</h2>
<p>The immune system is even “more complicated than the human genome,” <a href="https://www.freethink.com/health/human-immunome">says John Tsang</a>, a professor at Yale School of Medicine. One component of this complexity is the complicated network by which immune cells communicate with one another via protein messengers known as <em>cytokines</em>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2024-01-23-cytokines1/biolegend.jpg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Poster of immune cell interactions from <a href="https://www.biolegend.com/en-ie/immunologic-networks-2011">https://www.biolegend.com/en-ie/immunologic-networks-2011</a></figcaption>
</figure>
</div>
<p>Immune cell communication through cytokines is a key area for us to better understand medicine and disease. Various immune cell types must communicate to coordinate their response to threats. However, the immune system may end up over-reacting, under-reacting, or having a misplaced reaction, all of which can cause disease. Sepsis occurs when the immune system responds too vigorously, damaging our own organs. In cancer, the immune system may under-respond, failing to attack cancerous cells that it should. Several types of cancer therapies involve trying to activate or reactivate our own immune cells. In other cases, the immune system mistakenly attacks our own tissue, causing autoimmune diseases including Type 1 diabetes, rheumatoid arthritis, multiple sclerosis, and psoriasis.</p>
<p>Recent research, drawing on a blend of immunology, mathematics, and natural language processing (NLP) AI, is helping us better understand immune cell-cytokine networks. I have a PhD in math, taught a <a href="https://www.fast.ai/posts/2019-07-08-fastai-nlp.html">masters course in NLP</a>, and <a href="https://rachel.fast.ai/posts/2023-02-07-school-immunology/">now study immunology</a>, so I have a particular interest in this work. Understanding how the immune system is communicating and coordinating is necessary for knowing why and how the immune response can go awry.</p>
</section>
<section id="how-immune-cells-communicate" class="level2">
<h2 class="anchored" data-anchor-id="how-immune-cells-communicate">How Immune Cells Communicate</h2>
<p>There are dozens of types of immune cells. The main way that immune cells communicate and coordinate with each other is by sending small protein messengers known as cytokines. There are hundreds of types of cytokines. A single cytokine can have different effects on different cell types. The impact of a cytokine depends on the type of cell sending it, the type of cell receiving it, and the state of the cell. This makes interpreting immune responses challenging!</p>
<p>Cytokine-based therapies are used to treat some diseases, including cancer and autoimmune disorders. The interactions between cells and cytokines form complex networks, which are not fully mapped.</p>
<p><em>Note: You may have heard the term “cytokine storm” in <a href="https://www.nytimes.com/2020/04/01/health/coronavirus-cytokine-storm-immune-system.html">the news</a> during early coverage of covid (other diseases and some medical treatments can lead to cytokine storms as well). A cytokine storm occurs when the immune system reacts too vigorously, sending tons of messages and ramping up its inflammatory response to a level that is dangerous to the patient. The double-edged nature of the immune system is part of what piqued my interest about the topic.</em></p>
</section>
<section id="nlp-for-cell-cytokine-interactions" class="level2">
<h2 class="anchored" data-anchor-id="nlp-for-cell-cytokine-interactions">NLP for Cell-Cytokine Interactions</h2>
<p>Language models such as ChatGPT are part of the active field Natural Language Processing (NLP). NLP applies data science and machine learning to collections of text documents. At fast.ai, Jeremy Howard, Sylvain Gugger, and I developed a <a href="https://www.fast.ai/posts/2019-07-08-fastai-nlp.html">course on NLP in 2019</a>, teaching cutting edge techniques like transformers, which are now used in ChatGPT and other popular models.</p>
<p>One paper in immunology is published every 30 minutes! That is a lot of immunology papers, and NLP techniques can be used to help synthesize this huge quantity of information. While models like ChatGPT are trained using a huge variety of texts scraped from the internet, immune-focused work may focus on a more specific group of documents, such as PubMed abstracts. <a href="https://www.nature.com/articles/nbt.4152">A computer program called ImmuneXpresso</a> was developed to text-mine the 16 million abstracts available on PubMed and create triples containing a cell type, cytokine, and whether the relationship was in-coming or out-going (i.e.&nbsp;if the cell was sending or receiving the cytokine).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2024-01-23-cytokines1/immunexpresso.jpg" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Information flow of families of cytokines between families of cells (Figure 2A from ImmuneXpresso)</figcaption>
</figure>
</div>
<p>The above figure from the <a href="https://www.nature.com/articles/nbt.4152">ImmuneXpresso paper</a> shows some of the information flow. Each family of cytokines shown contains multiple cytokines, and each family of cells contains multiple sub-types. The researchers relied on sentence syntax to parse these relationships, and captured associations with 188 diseases. A machine learning classifier was used to predict whether the data captured were related to cell-cytokine relationships. Over 4,000 directional cell–cytokine interactions were documented via this process. The authors experimentally tested two interactions that were predicted, but are not well-established in the literature, and validated that they hold true.</p>
</section>
<section id="a-famous-data-scientist-turns-to-immunology" class="level2">
<h2 class="anchored" data-anchor-id="a-famous-data-scientist-turns-to-immunology">A famous data scientist turns to immunology</h2>
<p>Jeff Hammerbacher created and led the data team at Facebook in 2006-2008 and was a founder of the successful cloud computing company Cloudera. A decade ago he made a similar pivot to the one I am currently attempting, starting <a href="https://www.hammerlab.org/">his own immunology lab</a> at Mt. Sinai and later the Medical University of South Carolina. He has applied machine learning to a variety of immunology problems, including <a href="https://pubmed.ncbi.nlm.nih.gov/26856372/">predicting surgery outcomes</a>, <a href="https://www.frontiersin.org/articles/10.3389/fimmu.2017.01807/full">designing cancer vaccines</a>, and starting a <a href="https://www.related.vc/">data science focused drug-discovery firm</a>.</p>
<p>Hammerbacher, together with Ed Czech, tackled the problem of <a href="https://www.biorxiv.org/content/10.1101/643767v2">using NLP to extract cell type-cytokine relationships</a>. To give an example of the type of problems that must be addressed in NLP, “<em>Th1 (CD4+IL-17-IFN-γhi) cells</em>” is referring to the same cell type as “<em>helper CD4+IL-17-IFN-γhi type 1 cells</em>.” Expert knowledge must be encoded in how to properly parse and categorize cells, knowing when two different strings refer to the same cell type and when they are different.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2024-01-23-cytokines1/t-cells.jpg" class="img-fluid figure-img" style="width:85.0%"></p>
<figcaption class="figure-caption">A few different T-cells communicating. Source: biolegend.com</figcaption>
</figure>
</div>
<p>They compared two different deep learning models. In one case, they used a generative model with weak supervision, which allowed for them to begin with a smaller labeled dataset to generate labels for previously unlabeled data. In the other case, they used a language model (SciBERT) which had been pre-trained on scientific texts, and then they fine-tuned it for the specific PubMed immunology articles they were using. This is an example of <strong>transfer learning</strong>, a technique in which a machine learning model trained on a large dataset can be customized for use on a much smaller dataset. Transfer learning has been a central part of the fast.ai approach from the start, and was a key technique I featured in my <a href="https://www.youtube.com/watch?v=frc7FgheUj4&amp;list=PLtmWHNX-gukLQlMvtRJ19s7-8MrnRV6h6&amp;index=11">keynotes at JupyterCon 2017</a> and <a href="https://www.youtube.com/watch?v=KChtdexd5Jo&amp;list=PLtmWHNX-gukLQlMvtRJ19s7-8MrnRV6h6&amp;index=6">SciPy 2019</a>.</p>
<p>As part of Czech and Hammerbacher’s research, they created a database of T-cell specific cytokines and transcription factors, including relationships between 75 cell types, 262 cytokines, and 382 transcription factors. Their work was distinctive for having a tiny team (just 2 people, compared to 16 authors and 11 annotators for ImmuneXpresso), using 53k full-text documents (rather than solely abstracts), and focusing more narrowly on T-cells (as opposed to all immune cells). Techniques such as transfer learning are powerful in that they allow small teams of researchers to leverage previous models via fine-tuning. In addition to <a href="https://www.biorxiv.org/content/10.1101/643767v2">the paper</a>, Hammerbacher shared about this work in a <a href="https://www.youtube.com/watch?v=pvj9tIdvOXQ">talk he gave at the Allen Institute for AI</a>.</p>
</section>
<section id="stay-tuned" class="level2">
<h2 class="anchored" data-anchor-id="stay-tuned">Stay Tuned</h2>
<p>Stay tuned for part 2 of this series, which will cover more fascinating research about how immune cells communicate. You can subscribe to be notified of new blog posts by submitting your email below:</p>
<script type="text/javascript" src="https://campaigns.zoho.com.au/js/zc.iframe.js"></script>
<iframe scrolling="no" frameborder="0" id="iframewin" width="100%" height="100%" src="https://zcmp-pd.maillist-manage.com.au/ua/Optin?od=11d0c075b7ed49&amp;zx=11a17553b1&amp;tD=156971d471c7b09&amp;sD=156971d471c7cb3">
</iframe>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>machine learning</category>
  <category>science</category>
  <guid>https://rachel.fast.ai/posts/2024-01-23-cytokines1/index.html</guid>
  <pubDate>Mon, 22 Jan 2024 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2024-01-23-cytokines1/biolegend-zoom.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>4 Things I Learned About Bugs</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2024-01-09-insects/index.html</link>
  <description><![CDATA[ 




<p>I am currently halfway through my Masters of Microbiology &amp; Immunology. My goal is to apply my previous decade of experience as a data scientist and AI researcher to immunology. Even though my primary interest is on long-term impacts of viruses on humans, I wanted a broader and deeper understanding of microbiology in general. This past semester, I was pleasantly surprised to learn several fascinating facts about insects!</p>
<section id="insects-are-useful-for-making-medications-and-vaccines" class="level2">
<h2 class="anchored" data-anchor-id="insects-are-useful-for-making-medications-and-vaccines">Insects are useful for making medications and vaccines</h2>
<p>Proteins are a key component of many vaccines and medications. To create these proteins, scientists have come up with a range of <strong>protein expression systems</strong>. Bacteria, yeast, mammalian cells, and genetically modified animals can all be used to produce proteins for medications. And so can insects! For instance, <a href="https://www.nature.com/articles/nbt1095">baculovirus is a virus</a> that mostly infects insects, and its genome can be modified to produce various cytokines (chemical messengers), antivirals (such as type 1 interferons), and vaccine components.</p>
<p>There are trade-offs with any choice of protein expression system. For example, <em>bacteria</em> are fast and cheap to use, but because they are quite dissimilar to humans, they are much worse for key steps such as protein folding or adding sugars to proteins (a process called glycosylation). And while <em>mammalian</em> cells or genetically modified animals will produce much more accurately folded proteins and glycosylation, they are expensive and slow for production. Baculoviruses from insects aren’t the worst in any of these categories, which makes them a widely useful workhorse for protein expression.</p>
<p>Insect cells are more similar to human cells than yeast or bacteria are, which means that the proteins they produce (when infected with <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7159335/">modified baculoviruses</a>) are more likely to be folded correctly, and they make for cheaper and faster expression systems than mammalian cells do. A baculovirus expression system is used, for example, to produce Novavax, a popular protein-based covid vaccine (which may have fewer side-effects than mRNA-based covid vaccines such as Pfizer and Moderna).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2024-01-09-insects/expression-systems.jpg" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption class="figure-caption">Comparing Different Expression Systems, image from brainkart.com</figcaption>
</figure>
</div>
</section>
<section id="insects-have-the-same-problems-humans-do-viral-bacterial-fungal-and-protozoan-infections" class="level2">
<h2 class="anchored" data-anchor-id="insects-have-the-same-problems-humans-do-viral-bacterial-fungal-and-protozoan-infections">Insects have the same problems humans do: viral, bacterial, fungal, and protozoan infections</h2>
<p>Insects can be infected with harmful viruses, bacteria, fungi, and protozoa. <strong>Entomopathogens</strong> is a fun vocabulary word for pathogens that infect arthropods (arthropods include insects, mites, ticks, spiders, and more). These are sometimes used as natural pesticides, in order to try to control insect pests that may be feeding on crops or spreading disease. <a href="https://ucanr.edu/blogs/blogcore/postdetail.cfm?postnum=24119">Entomopathogens may kill, limit reproduction, or shorten the life of arthropod pests</a>. They are generally less toxic to humans and other animals than other pesticides, although it is a risk that they could spread to related species.</p>
</section>
<section id="insects-really-need-the-bacteria-in-their-guts" class="level2">
<h2 class="anchored" data-anchor-id="insects-really-need-the-bacteria-in-their-guts">Insects really need the bacteria in their guts</h2>
<p>While some bacteria are harmful to insects, other bacteria are not only beneficial, but even essential. A diet consisting only of sap is not nutritionally complete. Neither is a diet just of blood. Some arthropods can’t produce all the vitamins they need, and instead rely on bacteria in their guts to help synthesize essential vitamins. These bacteria (known as obligate symbionts) rely on their hosts as well, in a mutually beneficial relationship. Bioinformatics and modern gene sequencing has revolutionized the study of these obligate symbionts by allowing for their genomes to be sequenced and studied. One paper calls them the <a href="https://pubmed.ncbi.nlm.nih.gov/24995872/">“The Tiniest Tiny Genomes”</a>, and describes how through a long process of coevolution the bacteria lost the genes to manufacture cell membrane components. They are completely reliant on their hosts, while also producing B vitamins and essential amino acids.</p>
<p>While many types of bacteria help bugs synthesize nutrients, other types can help synthesize protective toxins to be used against predators. Diaphorina is an insect pest of citrus plants. Profftella, one of the bacterial obligate symbionts in its gut, is noteworthy for helping to <a href="https://pubmed.ncbi.nlm.nih.gov/32797185/">synthesize both vitamins and protective toxins</a> for its host, whereas many symbionts provide either vitamins or toxins, but not both.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2024-01-09-insects/psyllid.jpg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">A Diaphorina on a leaf– gut bacteria not pictured. Photo by David Hall, USDA ID d595-1.</figcaption>
</figure>
</div>
</section>
<section id="a-common-bacteria-in-insects-reduces-risk-of-dengue-virus-to-humans" class="level2">
<h2 class="anchored" data-anchor-id="a-common-bacteria-in-insects-reduces-risk-of-dengue-virus-to-humans">A common bacteria in insects reduces risk of Dengue Virus to humans</h2>
<p>An astonishing <a href="https://www.cdc.gov/mosquitoes/mosquito-control/community/emerging-methods/wolbachia.html">60% of insects</a> (including butterflies, bees, and beetles) around the world have the bacteria Wolbachia. This fascinating bacteria can have some surprising impacts, including reducing the ability of mosquitoes to carry or transmit dengue virus.</p>
<p><em>A. aegypti</em> mosquitoes are carriers of dengue virus. They do not naturally carry Wolbachia, but when mosquitoes with Wolbachia were <a href="https://www.nature.com/articles/s41598-023-42336-2">released in North Queensland, Australia</a>, predicted transmission of dengue infections dropped by 95% over the following 2 years. <a href="https://www.nejm.org/doi/full/10.1056/nejmoa2030243">A randomized study in Indonesia</a> released Wolbachia-infected mosquitoes in some regions but not others, and found the regions with the Wolbachia-infected mosquitoes had 77% fewer dengue cases.</p>
<p>Another surprising effect of the bacteria is that a male mosquito with Wolbachia mates with a female mosquito that doesn’t have it, the fertilized eggs will not be viable. And two mosquitoes with different strains of Wolbachia can not produce viable eggs. Isn’t this weird??? This has been used in some efforts to reduce mosquito populations.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2024-01-09-insects/cytoplasmic-incompatibility.jpg" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption class="figure-caption">Cytoplasmic incompatibility, figure from https://almob.biomedcentral.com/articles/10.1186/s13015-020-00174-1</figcaption>
</figure>
</div>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>science</category>
  <guid>https://rachel.fast.ai/posts/2024-01-09-insects/index.html</guid>
  <pubDate>Mon, 08 Jan 2024 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2024-01-09-insects/psyllid.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI and Power: The Ethical Challenges of Automation, Centralization, and Scale</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/index.html</link>
  <description><![CDATA[ 




<p>Friends with no previous interest in AI ethics have begun asking me questions in the wake of the release of ChatGPT4, Bard, and Bing Chat. This new generation of large language models <a href="https://www.nytimes.com/2022/12/10/technology/ai-chat-bot-chatgpt.html">has made headlines</a> and sparked widespread debate. To consider the risks posed by new AI applications, it is useful to first understand several underlying concepts. <a href="https://rachel.fast.ai/about.html">I spent years</a> researching the mechanisms by which algorithmic systems can cause harm, and in late 2021, I gave a 20-minute talk on what I consider key ideas at the heart of AI ethics. With the advent of the newest generation of language models, these concepts are more relevant than ever.</p>
<p>Over the past decade, topics such as <em>explainability</em> (having computers generate an explanation of why they compute the outputs they do) and <em>fairness/bias</em> (addressing when algorithms have worse accuracy on some groups of people than others) have gained more attention within the field of AI and in the media. Some computer scientists and journalists have stopped there: assuming that a computer program that can explain the logic behind its decision making, or a program that has the same accuracy on light-skinned men as on dark-skinned women, must now be ethical. While these principles are important, on their own they are not enough to address nor prevent harms of AI systems.</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/spHB7IEFXbg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="">
</iframe>
</center>
<p>Below is an edited transcript of this talk.</p>
<section id="actionable-recourse" class="level2">
<h2 class="anchored" data-anchor-id="actionable-recourse">Actionable Recourse</h2>
<p><em>Explainability</em> on its own is insufficient. Consider an algorithmic system that is making decisions about whether or not someone should get a loan. Often a question will be “why was my loan denied?”, but really the underlying question is “what can I change about my situation to get a loan in the future?”</p>
<p>An explanation should be <em>actionable</em>. For example, it’s not okay to deny a loan because of ethnicity. That’s discrimination and it would not make for a satisfying explanation. For decisions impacting people’s lives, there also needs to be a mechanism for <em>recourse</em>, so that decisions can be changed. This is <em>actionable recourse</em>, as <a href="https://arxiv.org/abs/1809.06514">described by Berk Ustun</a>.</p>
<p>This underlying idea of actionable recourse shows up in many applications. There is an example I return to often, since it’s a pattern that we see across many countries. In the USA there is an algorithm to determine poor people’s health care benefits. When it was implemented in one state there was a <a href="https://www.theverge.com/2018/3/21/17144260/healthcare-medicaid-algorithm-arkansas-cerebral-palsy">bug in the code that incorrectly cut care</a> for people with cerebral palsy. Tammy Dobbs was one of the many people that lost care due to a software bug. She needed this care for very basic life functions: to help her get out of bed in the morning, to get her breakfast, and so on. She asked for an explanation and they didn’t give her one; they just said this is what the algorithm determined. At the root, what she needed was not just an explanation, but a mechanism for recourse to get the decision changed. Eventually the error was revealed through a lengthy court case, but that is a terrible setup.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/cuts-healthcare2.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">When an algorithm cuts your health care</figcaption>
</figure>
</div>
<p>This illustrates a common issue that shows up again and again: <strong>automated systems are often implemented with no way to identify and address mistakes</strong>.</p>
<p>There are a few reasons why there is no mechanism for catching mistakes. Often automation is being used as a cost cutting measure and having robust error checking in place and ways to surface mistakes would cost more. There can also be biases of people mistakenly believing that computers are perfectly accurate.</p>
<p><a href="https://www.hrw.org/news/2021/11/10/how-eus-flawed-artificial-intelligence-regulation-endangers-social-safety-net">Human Rights Watch put out a report</a> on automated system use in the EU for social benefits. Country after country had alarming examples where there were errors, yet no clear way to identify, much less address, them. There was a case in France where an algorithm to determine food benefits made errors in at least 60,000 cases. One woman said her case manager even agreed this was a bug and that she deserved to receive benefits, but the case manager didn’t have the power to reinstate them!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/hrw-eu.jpg" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Human Rights Watch report</figcaption>
</figure>
</div>
<p>Another domain to consider is content moderation. The <a href="https://santaclaraprinciples.org/">Santa Clara Principles for content moderation</a> were developed by a group of ethicists, although these principles are not observed by the major platforms. I want to share Principle 3, because I love the wording, which is that companies should provide a <em>meaningful opportunity for timely appeal</em>. I really like this idea of appeal being <em>meaningful</em> and <em>timely</em>. I think this is relevant far, far beyond content moderation. Too often, even when there is a way to try to report a mistake, you just get an automated response that clearly hasn’t been read or you have to wait months for an answer. It is important that appeals are not just available, but also that they are meaningful and timely.</p>
</section>
<section id="contestability" class="level2">
<h2 class="anchored" data-anchor-id="contestability">Contestability</h2>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3311957.3359435"><em>Contestability</em></a> is the idea of building an algorithmic system to include mechanisms for questioning and disagreeing with results as part of the system, rather than as an external add-on. Too often we build computational systems assuming okay this is going to work great, and then when there are errors, we tack on something extra at the end. I found this provocative to think about how we <strong>include disagreement into the core of the system</strong>.</p>
<p>I had considered this from a slightly different angle in my work with fast.ai, where we have a concept of what we call <em>augmented machine learning</em>. This is in contrast to auto machine learning, which is often about automating a process end to end. With <a href="https://slideslive.com/38917533/lessons-learned-from-helping-200000-nonml-experts-use-ml">augmented machine learning</a> we really wanted to think about what are the things that humans are really good at and how can we take advantage of human strengths as opposed to simply trying to automate everything and then being left with weird gaps of stuff that computers are not doing well. How can humans and computers best work together? This is important to keep in mind with system design.</p>
</section>
<section id="fairness-and-bias" class="level2">
<h2 class="anchored" data-anchor-id="fairness-and-bias">Fairness and Bias</h2>
<p>It is important to consider fairness and bias, but that alone is insufficient. I imagine many of you are familiar with the <a href="http://gendershades.org/overview.html">Gender Shades research</a> on facial recognition by Joy Boulamwini, Timnit Gebru, and Deborah Raji. They evaluated commercial computer vision products that had been released from a number of big name companies including Microsoft, IBM, and <a href="https://www.nytimes.com/2019/01/24/technology/amazon-facial-technology-study.html">Amazon</a>. They found that the products performed worse on women than on men and worse on people with dark skin than on people with light skin, leading to terrible results for dark-skinned women. For instance, IBM’s product had 99.7% accuracy on light skinned men, but just 65% accuracy on dark-skinned women. That is a huge discrepancy in a product that had been commercially released. This research was ground-breaking in bringing attention to a pernicious issue.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/gendershades.jpg" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption class="figure-caption">Results from one of the GenderShades studies</figcaption>
</figure>
</div>
<p>Some people have reacted with a superficial response, which is not consistent what the researchers wrote, concluding that the solution is solely to get more pictures of dark-skinned women and then call it a day. While issues of representation in underlying training datasets need to be addressed, this is only one part of the problem. We have to look at how these systems are used, which poses many other significant harms.</p>
</section>
<section id="harmful-if-it-doesnt-work-harmful-if-it-works" class="level2">
<h2 class="anchored" data-anchor-id="harmful-if-it-doesnt-work-harmful-if-it-works">Harmful if it doesn’t work; Harmful if it works</h2>
<p>In several USA cities, <a href="https://www.nbcmiami.com/investigations/miami-police-used-facial-recognition-technology-in-protesters-arrest/2278848/">police have</a> used <a href="https://www.theverge.com/2020/8/18/21373316/nypd-facial-recognition-black-lives-matter-activist-derrick-ingram">facial recognition</a> to <a href="https://www.theverge.com/2016/10/11/13243890/facebook-twitter-instagram-police-surveillance-geofeedia-api">identify Black people</a> protesting police racism and police murders of unarmed civilians. There’s a huge power issue when you look at this type of use of technology. I believe this is unethical whether or not it works. It is certainly terrible to misidentify people and arrest the wrong person, but it’s a threat to civil rights to identify protesters.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/police-facial-rec.jpg" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Headlines about police use of facial recognition to identify protesters in Miami, NYC, and Baltimore</figcaption>
</figure>
</div>
<p><a href="https://www.nytimes.com/2019/11/19/technology/artificial-intelligence-bias.html">Dr.&nbsp;Timnit Gebru wrote</a>, <em>“A lot of times, people are talking about bias in the sense of equalizing performance across groups. They’re not thinking about the underlying foundation, whether a task should exist in the first place, who creates it, who will deploy it on which population, who owns the data, and how is it used?”</em> These are all crucial questions to ask. They are questions of power. Yes, you should check the error rates on different subgroups, but that alone is insufficient, and doesn’t address questions of power.</p>
<p>While the policing examples are from the USA, this is a pattern throughout history and throughout the world. <a href="https://digitalrepository.unm.edu/nmlr/vol50/iss3/2/">Professor Alvaro Bedoya wrote</a>, <em>“It is a pattern throughout history that surveillance is used against those considered ‘less than’, against the poor man, the person of color, the immigrant, the heretic. It is used to try to stop marginalized people from achieving power.”</em> The history of surveillance as a weapon used against the marginalised stretches back centuries and predates computers, but <strong>AI has now turbocharged this dynamic</strong>.</p>
</section>
<section id="operating-at-scale" class="level2">
<h2 class="anchored" data-anchor-id="operating-at-scale">Operating at scale</h2>
<p>Robodebt was a program where the Australian government created unlawful debts for hundreds of thousands of people through an automated system. People would be notified that they had been overpaid on welfare (often, this was false, but contesting it required documentation most people didn’t have) and that they now owed the government significant amounts of money. This destroyed many lives, even driving some <a href="https://www.theguardian.com/australia-news/2023/feb/20/platitudes-and-false-words-mother-of-robodebt-victim-who-took-own-life-tells-inquiry-of-government-stonewalling">victims to suicide</a>. A <a href="https://www.theguardian.com/australia-news/2020/may/29/robodebt-government-to-repay-470000-unlawful-centrelink-debts-worth-721m">detail that struck me</a> is that the number of debts issued went from 20,000 <em>per year</em>, back when it was a more manual process, to 20,000 <em>per week</em> with automation. That is a 50x scale up! <strong>Automation was used to drastically scale putting poor people into debt</strong>. This is another disturbing pattern in machine learning.</p>
</section>
<section id="centralizing-power" class="level2">
<h2 class="anchored" data-anchor-id="centralizing-power">Centralizing Power</h2>
<p>Machine learning often has the effect of centralizing power. It can be implemented with no system for recourse and no way to identify mistakes, as we saw earlier with people whose <a href="https://www.theverge.com/2018/3/21/17144260/healthcare-medicaid-algorithm-arkansas-cerebral-palsy">healthcare was wrongly cut due to a bug</a>. It can be used cheaply at massive scale, as shown with Robodebt. It can also replicate identical biases or errors at scale.</p>
<p>Often when I teach about how automated systems can cause harm, <a href="https://rachel.fast.ai/posts/2018-08-07-hbr-bias-algorithms/">people will point out</a> how humans make mistakes and are biased too. However, there are key differences in automated systems. It is not just plug-and-play interchangeable when you switch from a human decision maker to an automated decision maker.</p>
<p>Automated systems can also be used to evade responsibility. This is true of bureaucracy in general. While in non-automated bureaucracies you also get a passing of the buck (“I was just following orders” or ”it’s this other person’s fault”); however, as dana boyd has pointed out, <a href="https://www.youtube.com/watch?v=NTl0yyPqf3E">automated systems are often being used to extend bureaucracy</a> (as explained by danah boyd), adding additional places to deflect responsibility.</p>
<p>In the example health care software bug example that I shared, a journalist interviewed the creator of that algorithm. He is earning royalties through a private company, and he said it’s not the company’s responsibility to offer an explanation. He blamed policymakers for the errors. The policymakers could blame the particular people that implemented this software. Everyone can point to somebody else or even to the software itself. Systems where nobody takes responsibility do not lead to good outcomes.</p>
</section>
<section id="feedback-loops" class="level2">
<h2 class="anchored" data-anchor-id="feedback-loops">Feedback loops</h2>
<p>Feedback loops occur when you create the outcome that you were trying to predict. Data can become tainted from the output of the model. Furthermore, machine learning models can amplify bias, not just encode it. There have been <a href="https://arxiv.org/abs/1901.09451">multiple papers</a> showing that if <a href="https://www.wired.com/story/machines-taught-by-photos-learn-a-sexist-view-of-women/">you start</a> with <a href="https://arxiv.org/abs/1706.09847">a biased dataset</a> you can actually train a model that is even <strong>more</strong> biased than the training dataset.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/talk-power.jpg" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Screenshot from my talk at QUT, on ways that AI can centralize power</figcaption>
</figure>
</div>
<p>In summary, these are several reasons why machine learning can end up centralising power and why automated systems are different from human decision makers. AI researcher Pratyusha Kalluri advises us that rather than ask whether an AI application is fair to instead <a href="https://www.nature.com/articles/d41586-020-02003-2">ask how it shifts power</a>.</p>
</section>
<section id="the-people-impacted" class="level2">
<h2 class="anchored" data-anchor-id="the-people-impacted">The People Impacted</h2>
<p>Another thing I want to highlight about the healthcare example is that the people whose healthcare was incorrectly cut saw the problem right away, but there was no way to get that mistake acknowledged or addressed.</p>
<p>Another tragic example of people recognizing an issue but not being able to get it addressed is Facebook’s role in the genocide in Myanmar. In 2018, the UN found that Facebook had <a href="https://www.reuters.com/article/us-myanmar-rohingya-facebook-idUSKCN1GO2PN">played a “determining role”</a> in the genocide; however that was not not a surprise to anyone who had been following the events. A tech entepreneur <a href="https://www.wired.com/story/how-facebooks-rise-fueled-chaos-and-confusion-in-myanmar/">based in Myanmar said</a>, “That’s not 20/20 hindsight. The scale of this problem was significant. It was already apparent [going back to 2013].”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/myanmar.jpg" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Articles about the role of Facebook in the Myanmar genocide</figcaption>
</figure>
</div>
<p>It’s important to understand that genocide does not come out of nowhere. It gradually escalates. From 2013, people warned executives about how Facebook was being used in Myanmar to incite violence and to dehumanize an ethnic minority. In 2013, 2014, and 2015, people raised warnings and they were not listened to.</p>
<p>An indication of how little Facebook did to address the issues is that the start of 2015 they only had two contractors who spoke Burmese, and they only hired 2 more that year. Compared to the number of Burmese-speaking users in Myanmar, it was a tiny number. Facebook invested very few resources in this (contrast the situation with when <a href="https://www.fast.ai/posts/2018-04-19-facebook.html#myanmar">Facebook rapidly hired over a thousand content moderators</a> in Germany to avoid a fine).</p>
<p>This is a pattern that we see over and over, that often the people most impacted by a system recognize the issues earliest, but they are not listened to and don’t have effective ways to raise an alarm. They also best understand the needed interventions for addressing the ethical risk. It is crucial that the people most impacted have avenues for participation and power.</p>
</section>
<section id="practical-resources" class="level2">
<h2 class="anchored" data-anchor-id="practical-resources">Practical Resources</h2>
<p>The <a href="https://icml.cc/virtual/2020/workshop/5720">participatory approaches to machine learning</a> workshop at ICML 2020 was fantastic. The organizers of the workshop highlighted that the designers of a machine learning system have far more power over the system than the individuals impacted. Even within algorithmic fairness or human-centered ML, <strong>ethics work is often focused on centralized solutions, which can further increase the power of system creators</strong>. The workshop organizers called for more democratic, cooperative, and participatory approaches.</p>
<p>I want to share some practical resources with you. The Markkula Center for Applied Ethics at Santa Clara University has a packet of resources online for ethics and technology practice and in particular I love their <a href="https://www.scu.edu/ethics-in-technology-practice/ethical-toolkit/">Tech Ethics Toolkit</a>. This is a set of practices that you could implement within your organization. As an example, tool 3 is “expanding the ethical circle”, which involves setting a regular time aside to make sure you are going through who all the stakeholders are that will be directly affected by a system, as well as who will be indirectly affected in significant ways. It involves asking whose skills, experiences, and values have we simply assumed rather than actually consulted. The toolkit goes into more detail about this on questions to ask and things to look for.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/diverse-voices.jpg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Diverse Voices Guide</figcaption>
</figure>
</div>
<p>Another useful resource on this is the <a href="https://techpolicylab.uw.edu/news/diverse-voices-guide/">Diverse Voices guide</a> from the University of Washington Tech Policy Lab. In addition to an academic paper, they have a practical how-to guide on assembling panels of groups who are not be well-represented and whose input you need. They include examples, such as panels of people who are formerly incarcerated, people who don’t drive cars, and extremely low income people.</p>
</section>
<section id="data-are-not-bricks-to-be-stacked-oil-to-be-drilled" class="level2">
<h2 class="anchored" data-anchor-id="data-are-not-bricks-to-be-stacked-oil-to-be-drilled">Data are not bricks to be stacked, oil to be drilled</h2>
<p>In conclusion, explainability on its own is insufficient; we need actionable recourse and contestability. Fairness is insufficient; we need justice. The people most impacted by a system need avenues for participation and power.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/talk-end.jpg" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Screenshot from my talk at QUT</figcaption>
</figure>
</div>
<p>These are very difficult problems but some steps towards solutions are:</p>
<ul>
<li>making sure you have ways to identify, report, and address errors quickly</li>
<li>offering timely meaningful appeals</li>
<li>include consultation with voices that are often overlooked (and not just in a tokenistic way</li>
<li>designing products processes processes and technology with contestability in mind</li>
<li>diversity in hiring retention and promotions (diversity including nationality and language)</li>
</ul>
<p>I’ll close with a quote that I love from <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7296309/">AI researcher Inioluwa Deborah Raji</a>, <em>“But data are not bricks to be stacked, oil to be drilled, gold to be mined, opportunities to be harvested. Data are humans to be seen, maybe loved, hopefully taken care of.”</em></p>
<p>The video version of my talk is <a href="https://www.youtube.com/watch?v=spHB7IEFXbg&amp;list=PLtmWHNX-gukLQlMvtRJ19s7-8MrnRV6h6&amp;index=6">available here</a>.</p>
</section>
<section id="further-reading-watching" class="level2">
<h2 class="anchored" data-anchor-id="further-reading-watching">Further reading / watching</h2>
<p>You may also be intersted in:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=KChtdexd5Jo&amp;list=PLtmWHNX-gukLQlMvtRJ19s7-8MrnRV6h6&amp;index=6">The New Era in NLP | SciPy 2019 | Rachel Thomas</a>: keynote talk I gave at SciPy 2019, just after the release of GPT-2, about the technical advances and ethical risks of language models</li>
<li><a href="https://rachel.fast.ai/posts/2021-08-17-eleven-ethics-videos/">11 Short Videos About AI Ethics</a>: short videos about machine learning ethics, which I created for the fast.ai deep learning course</li>
<li><a href="https://www.cell.com/patterns/fulltext/S2666-3899(22)00056-3">Reliance on metrics is a fundamental challenge for AI</a>: academic paper David Uminsky and I wrote about how AI is perhaps too good at optimizing metrics, and the problems this can create</li>
</ul>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>ethics</category>
  <category>machine learning</category>
  <guid>https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/index.html</guid>
  <pubDate>Mon, 15 May 2023 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2023-05-16-ai-centralizes-power/cuts-healthcare.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Viruses: The Silent Triggers of Autoimmune and Neurodegenerative Diseases</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2023-03-22-viruses2/index.html</link>
  <description><![CDATA[ 




<p><em>This is Part 2 in a series. Read <a href="https://rachel.fast.ai/posts/2023-03-07-viruses1/">Part 1 here</a>.</em></p>
<p>Your previously healthy 1-year old develops Type 1 diabetes, a condition they will have for the rest of their life and that will require constant monitoring. Your partner has a stroke. Your parent shows early symptoms of Alzheimer’s disease. What do these seemingly disparate health events have in common? All can be triggered by viruses where the immediate infection seems mild.</p>
<section id="a-life-changing-diagnosis" class="level2">
<h2 class="anchored" data-anchor-id="a-life-changing-diagnosis">A Life-Changing Diagnosis</h2>
<p><a href="https://raisingachildwithdiabetes.com/our-story/">When Maria’s 1-year old daughter</a> came down with a cold, it initially seemed like no big deal. However, her cough lingered, and in the coming months she was diagnosed with type 1 diabetes, a condition which can not be cured and which her daughter will have for the rest of her life. Maria was thrust into a stressful world of needing to constantly monitor her baby’s blood sugar, where either too much or too little insulin could kill her baby.</p>
<p>In the wake of her cold, the baby’s immune system had mistakenly turned on her pancreas, permanently destroying the cells needed to generate insulin. Type 1 diabetes is not related to diet or lifestyle, and is far less predictable than the more famous type 2 diabetes. As <a href="https://raisingachildwithdiabetes.com/our-story/">Maria writes</a>, “<em>We can do the same thing every day… and all our efforts simply do not work. It’s a never-ending battle. Diabetes never takes a break and needs to be managed 24/7/365 days a year… If we give too much insulin, she can go into a coma, and if we do not give her sufficient insulin, she can go into DKA [a life-threatening condition].</em>”</p>
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-03-22-viruses2/T1-diabetes.jpg" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption class="figure-caption">In Type 1 Diabetes, the pancreas is incapable of producing sufficient insulin. Image: Scientific Animations, Creative Commons License</figcaption>
</figure>
</div>
<p>Type 1 diabetes is often triggered by a viral infection. <a href="https://www.nature.com/articles/s41591-019-0667-0">One study</a> tracked viruses in stool samples from young children, month after month, and discovered that when kids have certain common childhood viruses for consecutive months, they are at much higher risk of having their immune systems develop autoimmunity against their own pancreas (a precursor to Type 1 diabetes).</p>
</section>
<section id="what-are-autoimmune-diseases-and-how-do-they-relate-to-viruses" class="level2">
<h2 class="anchored" data-anchor-id="what-are-autoimmune-diseases-and-how-do-they-relate-to-viruses">What are autoimmune diseases, and how do they relate to viruses?</h2>
<p>Type 1 diabetes is just one of many, many diseases caused by our own immune systems gone awry. These are known as <em>autoimmune diseases</em>. The Greek prefix <em>auto</em> means <em>self</em>. A key role of the immune system is to be able to distinguish between what is foreign and what is self, and it is harmful when the immune system erroneously learns to attack self. At its best, the immune system is a beautiful and complex orchestra working together for our good. However, the immune system is a double-edged sword that can cause great harm when it goes awry.</p>
<p>Despite impacting a wide range of body systems, all of the following examples are united in being autoimmune diseases:</p>
<ul>
<li>Crohn’s disease occurs when the immune system attacks the colon</li>
<li>Rheumatoid arthritis occurs when the immune system attacks its own antibodies</li>
<li>Multiple sclerosis occurs when the immune system attacks the protective coverings of neurons</li>
<li>Lupus occurs when the immune system attacks our own DNA</li>
<li>Hashimoto’s disease occurs when the immune system attacks the thyroid</li>
<li>Psoriasis occurs when the immune system attacks skin cells</li>
</ul>
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-03-22-viruses2/autoimmune.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Autoimmune disease can impact the whole body. Image: Glover, Mishra and Singh; Creative Commons License</figcaption>
</figure>
</div>
<p>There is still much that is unknown about the onset of autoimmune diseases, although in many cases, a viral infection can be the trigger (there are likely other factors involved too, including genetic predisposition). During an infection, our adaptive immune systems learn to recognize small patterns of molecules that indicate a pathogen or infected cell. Unfortunately, if these small patterns appear similar to elements of our own bodies, the body may continue attacking itself even once the acute infection is over.</p>
</section>
<section id="obstacles-in-research-and-treatment" class="level2">
<h2 class="anchored" data-anchor-id="obstacles-in-research-and-treatment">Obstacles in research and treatment</h2>
<p>Women are more likely to <a href="https://www.sciencedirect.com/science/article/pii/S0091302214000466">develop autoimmune diseases</a>, and there are numerous <a href="https://www.nature.com/articles/nri.2016.90">differences in women’s immune systems</a> compared to men. Like most diseases disproportionately impacting women or people of colour, autoimmune diseases have too often been neglected when it comes to funding and research, leaving a rudimentary understanding, inadequate treatments, and lots of open questions.</p>
<p>Moreover, autoimmune diseases have often been treated in different silos, based on which body system they impact. Crohn’s disease is studied by gastroenterologists, psoriasis by dermatologists, and Hashimoto’s by endocrinologists. While there are reasons for this approach, it can also hinder research on deeper patterns amongst autoimmune disorders. Once someone develops one autoimmune disease, they are <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3150011/">significantly more likely</a> to develop additional ones, which is another reason why studying common underlying causes and mechanisms would be helpful.</p>
<p>Autoimmune disorders are often treated with medications that suppress the immune system to keep it from attacking the patient’s own body. While these medications can be crucial in addressing symptoms, they come with the significant downside of inhibiting how the immune system responds to foreign invaders, making the patient vulnerable to infection.</p>
</section>
<section id="viruses-can-cause-neurodegenerative-diseases-too" class="level2">
<h2 class="anchored" data-anchor-id="viruses-can-cause-neurodegenerative-diseases-too">Viruses can cause neurodegenerative diseases too</h2>
<p>Diseases that cause cells in the brain or nervous system to lose function and eventually die are referred to as neurodegenerative diseases. Some are also autoimmune diseases. Multiple sclerosis is perhaps the best known disease that is firmly established as both neurodegenerative and autoimmune. In this disease, the immune system attacks the protective sheaths coating nervous cells in the spinal cord and brain. Evidence is growing that <a href="https://pubmed.ncbi.nlm.nih.gov/31507117/">ALS</a> (also known as Lou Gerig’s disease), <a href="https://pubmed.ncbi.nlm.nih.gov/33131704/">Parkinson’s disease</a> have autoimmune causes, and some researchers are asking if <a href="https://alz-journals.onlinelibrary.wiley.com/doi/10.1002/alz.12789">Alzheimer’s</a> is an autoimmune disease too.</p>
<p>Common viruses increase the risk of developing a neurodegenerative disease, for up to 15 years after the viral infection. A <a href="https://pubmed.ncbi.nlm.nih.gov/36669485/">study drawing on datasets of 800,000 people</a> across Finland and the UK looked at how various viruses could increase likelihood of neurodegenerative diseases such as multiple sclerosis, ALS, Parkinson’s, Alzheimer’s and dementia, and found many significant links. For instance, six different groups of viruses (including flu and viral pneumonia) were linked to an increased risk of developing dementia. Viral encephalitis (a virus which in many cases causes only mild, flu-like symptoms) raised the risk of developing Alzheimer’s disease. These were just a few of the associations found.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-03-22-viruses2/mri-alzheimers-dementia.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">MRIs of a brain with Alzheimer’s, with dementia, and a normal control, from Wikimedia</figcaption>
</figure>
</div>
<p>For decades, research on Alzheimer’s Disease was dominated by a hypothesis that mostly turned out to be a dead-end. Funding and support was funnelled toward projects that failed (and in some cases, were based on fraudulent data), while other researchers (whose ideas are now being proven correct) <a href="https://theconversation.com/my-work-investigating-the-links-between-viruses-and-alzheimers-disease-was-dismissed-for-years-but-now-the-evidence-is-building-184201">faced hostility and extreme difficulty</a> obtaining grants. For decades, the idea of viruses being a cause of Alzheimer’s was considered absurd, with only a few lone researchers pursuing it in the face of pushback and ostracism, yet now <a href="https://www.theguardian.com/society/2023/feb/19/could-alzheimers-be-caused-by-an-infection">ever more research</a> is accumulating to <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8234998/">support this idea</a>.</p>
<p>A core idea in Alzheimer’s research has <a href="https://pubmed.ncbi.nlm.nih.gov/30314800/">turned out to be backwards</a>: what was considered to be an intrinsically abnormal and useless protein (amyloid-beta) causing Alzheimer’s has turned out to be a part of our innate immune response, intended to protect the brain against infection. Amyloid-beta may be inadvertently causing harm, but it likely builds up as a protective reaction against a more fundamental root cause. <a href="https://pubmed.ncbi.nlm.nih.gov/29504537/">Amyloid-beta has positive, anti-microbial properties</a> for fighting off invaders. A <a href="https://pubmed.ncbi.nlm.nih.gov/29488144/">large study from Taiwan</a> found that HSV-1 infections increased the risk of developing dementia, but that treating these infections with antiviral medication lowered that risk.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-03-22-viruses2/itzhaki.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">An article by Dr.&nbsp;Ruth Itzhaki, Oxford University’s Institute of Population Ageing</figcaption>
</figure>
</div>
</section>
<section id="science-is-political" class="level2">
<h2 class="anchored" data-anchor-id="science-is-political">Science is political</h2>
<p>There have been many hurdles to pursuing the role of infection in contributing to Alzheimer’s: the siloed nature of science (virology and Alzheimer’s were seen as two very disparate areas); the failure of many to understand asymptomatic infection; and the political nature of medicine.</p>
<p>Science does not just progress inevitably. Instead, <a href="https://rachel.fast.ai/posts/2021-10-12-medicine-political/">politics, biases, and even trends</a> all impact which ideas receive the opportunities, funding, and support for progress to be made. A reluctance over decades to adequately fund post-viral research, to explore links between viruses and neurodegenerative diseases, or to take autoimmune diseases (which disproportionately impact women) seriously, has left us knowing far less than we could. Treating autoimmune diseases all in separate silos has limited progress, as has treating neurodegenerative diseases siloed away from virology.</p>
<p>In a <a href="https://rachel.fast.ai/posts/2021-10-12-medicine-political/">previous essay</a>, I wrote of the political nature of medicine, including several key case studies:</p>
<ul>
<li>Serious political battles and protests were needed to get AIDS taken seriously.</li>
<li>An ongoing lack of funding for ME/CFS research, spanning decades, even though ME/CFS patients have the lowest quality of life of pretty much any illness. Commensurate to disease burden, NIH funding for ME/CFS is at only 7%, depression and asthma are at 100%, and diseases like cancer and HIV are closer to 1000%.</li>
</ul>
<p>Our understanding of the wide-ranging, surprising, and sometimes devastating impacts of viruses is growing everyday, with new scientific discoveries and connections being made. If we can accelerate support for such research, as well as work to reduce transmission of viruses, we could significantly improve human well-being.</p>
<p><em>This is Part 2 in a 3-part series. Read <a href="https://rachel.fast.ai/posts/2023-03-07-viruses1/">Part 1 here</a> and stay tuned for Part 3.</em></p>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>science</category>
  <guid>https://rachel.fast.ai/posts/2023-03-22-viruses2/index.html</guid>
  <pubDate>Tue, 21 Mar 2023 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2023-03-22-viruses2/autoimmune.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Viruses are weirder, worse, &amp; more preventable than you realise</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2023-03-07-viruses1/index.html</link>
  <description><![CDATA[ 




<p>When I was 6, I caught chickenpox (this was before the chickenpox vaccine was widely available). I found the blisters quite itchy and painful, and I insisted that my parents take a picture of me so I could have a record of how many blisters I had. I stayed home from school for 2 weeks and was quite disappointed to miss being in the Amelia Bedelia school play (Amelia Bedelia was the protagonist of my favourite book series at the time, about a maid who takes everything literally). The only upside was getting to watch a VHS tape of the Pippi Longstocking movie on repeat. Once I recovered, I thought of chickenpox as annoying and unpleasant, but not a big deal in the scheme of things.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-03-07-viruses1/chickenpox-rachel.jpg" class="img-fluid figure-img" style="width:45.0%"></p>
<figcaption class="figure-caption">6-year old me really wanted to show how many blisters I had</figcaption>
</figure>
</div>
<section id="long-term-impacts-of-the-virus-behind-chickenpox" class="level2">
<h2 class="anchored" data-anchor-id="long-term-impacts-of-the-virus-behind-chickenpox">Long-term impacts of the virus behind chickenpox</h2>
<p>Only much later did I learn that chickenpox is caused by the varicella zoster virus (VZV), which remains latent in our neurons after infection, and for 30% of people, unless vaccinated, will reactivate as shingles decades later. People who have shingles are at an <a href="https://pubmed.ncbi.nlm.nih.gov/35025605/">80% higher risk of stroke</a> for up to a year afterwards, long after the acute symptoms of shingles have gone away. The stroke risk is particularly high for people who get shingles under the age of 40 (and this younger group is not eligible for the shingles vaccine).</p>
<p>The mechanisms by which VZV leads to this increased stroke risk are still being actively researched. In 2022, researchers discovered that <a href="https://theconversation.com/chickenpox-and-shingles-virus-lying-dormant-in-your-neurons-can-reactivate-and-increase-your-risk-of-stroke-new-research-identified-a-potential-culprit-194627">VZV causes the formation of small sacs full of proteins which promote blood clots</a>. (These small sacs are called exosomes and are used to transport various materials through our bloodstream.) These blood-clot-encouraging exosomes are still being produced 3 months after a shingles infection, and likely for longer (the study ended at 3 months).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-03-07-viruses1/exosomes.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">From an article covering the research on Varicella Zoster Virus, strokes, and exosomes</figcaption>
</figure>
</div>
<p>VZV is not just linked to strokes, but also linked to developing multiple sclerosis or vascular dementia, as was found in a <a href="https://www.cell.com/neuron/fulltext/S0896-6273(22)01147-3">recent study analysing</a> hundreds of thousands of medical records for associations between common viruses and diseases impacting the brain and nervous system. In the case of VZV, it is possible that the links to dementia and MS may occur through the reactivation of other viruses. That is another disturbing fact about viruses: they can quietly lie latent for years and then be reactivated by other viruses.</p>
</section>
<section id="but-arent-infections-inevitable" class="level2">
<h2 class="anchored" data-anchor-id="but-arent-infections-inevitable">But aren’t infections inevitable?</h2>
<p>I never gave much thought to how my brother and I had caught chicken pox, because for most of my life I assumed that viruses were a temporary discomfort, and that they were generally inevitable, just something that happens. However, in recent years, medical understanding of how pathogens spread has been upended, which in turn has profound implications for what we can do in response.</p>
<p>The flu, long believed to be spread through droplets from sneezes or through touching contaminated surfaces, <a href="https://www.pnas.org/doi/10.1073/pnas.1716561115">has been shown</a> to be released in small aerosols exhaled through ordinary breathing. These aerosols can remain suspended in the air, and others risk infection when they breathe them in. In work published in the prestigious PNAS, researchers found that neither sneezing nor coughing was necessary to spread flu, just ordinary breathing. This shift in understanding is important: it means that we have been relying on insufficient tools to stop viruses (e.g.&nbsp;hand washing and poorly fitting surgical masks alone will never be enough against airborne flu). Chickenpox, too, is spread through the air. As Professor Jonathan Gershoni of Tel Aviv University says in <a href="https://learning.edx.org/course/course-v1:IsraelX+Virus101x+2T2018/home">his course on viruses</a>, “<em>The most common direct route [of viral transmission] is when viruses become airborne and are subsequently inhaled. When people cough, sneeze, or simply exhale, they produce an aerosol of minute fluid droplets that are dispersed in the air around them.</em>”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-03-07-viruses1/edx-airborne2.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">From a course on viruses taught by Dr.&nbsp;Jonathan Gershoni</figcaption>
</figure>
</div>
<p>Fortunately, there are ways we can clean the air with improved ventilation (drawing in more outdoor air), filtration (removing harmful particles), and well-fitting masks in crowded public indoor spaces. For years, excellent ventilation and filtration systems have been used in pig farms, to avoid the spread of airborne porcine diseases, with some farms even <a href="https://twitter.com/LongDesertTrain/status/1494126639608909826?s=20">employing a worker whose sole duty</a> is the daily inspection and maintenance of the ventilation/filtration systems. Numerous studies document the effectiveness of hog farm filtration systems at reducing illness (see <a href="https://twitter.com/LongDesertTrain/status/1494126572625924098?s=20">this fascinating thread</a> for links), as well as the harms of poor ventilation for humans. Methods to clean the air have been implemented by wealthy elites at places including the <a href="https://slate.com/technology/2023/01/davos-covid-precaution-uv-lights-air-filters.html">World Economic Forum’s Davos Summit</a> (attended by politicians and billionaires), the <a href="https://www.purifiedair.com/case-studies/hm-government/">UK Parliament</a>, <a href="https://www.purifiedair.com/case-studies/palace-of-westminster/">Westminster Palace</a>, and an <a href="https://www.parliament.nsw.gov.au/tp/files/81592/Document%20-%20COVIDSafe%20plan%20-%20Sittings%2014%20%E2%80%93%2025%20February%202022%20%E2%80%93%20dated%2011%20February%202022.PDF">Australian state parliament</a>. However, unlike politicians and pigs, very few children or working class people have access to clean air in their schools or workplaces.</p>
<p>Rice University biochemistry and cell biology professor Alma Moon Novotny opened her <a href="https://www.coursera.org/specializations/immunology#courses">series of in-depth immunology courses</a> by singing the praises of not immunologists nor virologists, but of… engineers! Prof Novotny said, “<em>I want to emphasize that an ounce of prevention is worth a pound of cure, and I will be praising engineers, particularly civil engineers because what they provide for us is clean water and proper sewage disposal.</em>” She suggested that <a href="https://www.theguardian.com/society/2007/jan/19/health.medicineandhealth3">sanitation is the greatest medical advance of the last 150 years</a> and went on to list other important engineering improvements that improve health: mosquito nets, houses that don’t let in as many insects (which can often carry pathogens), and an infrastructure system to transport needed medical supplies. She also spoke of how expensive our immune systems are in terms of ATP (our bodies’ energy currency). Despite the amazing intricacies of the human immune system, it is better to avoid getting sick.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-03-07-viruses1/sanitation.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Headline from The Guardian and a lecture slide from Rice University Prof Alma Novotny</figcaption>
</figure>
</div>
<p>Experts have been highlighting the extensive infrastructure overhaul London used to tackle cholera in the 19th century, similar to how cleaning indoor air could be part of a <a href="https://www.theatlantic.com/health/archive/2021/09/coronavirus-pandemic-ventilation-rethinking-air/620000/">“plan to stop every respiratory virus at once”</a>. Clean air could be the next clean water, revolutionising global health.</p>
</section>
<section id="a-new-way-of-thinking" class="level2">
<h2 class="anchored" data-anchor-id="a-new-way-of-thinking">A New Way of Thinking</h2>
<p>The idea that a common childhood virus can quietly hang out unnoticed in our nervous system for decades, reactivate to cause the blisters and nerve pain of shingles, and then months after the shingles blisters clear up cause blood clotting and strokes is mind-boggling to me, and stands in stark contrast to how I thought about viruses when I was younger.</p>
<p>The trajectory of my growing understanding of VZV is similar to my understanding of many viruses: I have moved from thinking of common viruses as both inevitable and discretely contained events (e.g.&nbsp;you are sick for a week or two, but then it’s over) to recognizing that:</p>
<ul>
<li>even common viruses can have long-reaching, surprising, and devastating consequences</li>
<li>there is much more we can do to stop viral transmission than I previously realised</li>
</ul>
<p>VZV is just one of many viruses that have surprised me. Research has now shown that several <a href="https://www.cell.com/neuron/fulltext/S0896-6273(22)01147-3">common viruses raise the risk of dementia and Alzheimer’s disease</a>, and the <a href="https://pubmed.ncbi.nlm.nih.gov/35025605/">virus behind mono / glandular fever (Epstein-Barr virus) causes Multiple Sclerosis</a>. The fact that it is possible to reduce viral transmission makes it all the more urgent to understand the long-reaching consequences of viruses, since we have the power to act on what we learn.</p>
<p>Each risk on its own may not be that likely on the individual level: I am not suggesting that you should feel alarmed that you in particular will suffer a stroke after shingles, or that your elderly parent will catch the flu and then develop dementia, or that mono/glandular fever will lead to multiple sclerosis for you. However, it is important to think about this across the population, and across all these different virus-disease interactions. When you look at this research in aggregate, it suggests that many, many people are having their lives drastically impacted by diseases in which viruses play a role. Given what we know about both the risks of viruses and ways to reduce transmission, it is worthwhile to take effective measures like <a href="https://www.science.org/doi/10.1126/science.abg2025">increasing ventilation</a>, using <a href="https://theconversation.com/we-studied-how-to-reduce-airborne-covid-spread-in-hospitals-heres-what-we-learnt-166018">air purifiers</a>, and wearing <a href="https://theconversation.com/time-to-upgrade-from-cloth-and-surgical-masks-to-respirators-your-questions-answered-174877">N95/KF94/P2 masks in indoor public places</a> to make our schools, workplaces, and healthcare settings safer.</p>
<p><em>This post is part 1 in a 3-part series. Please stay tuned for future posts!</em></p>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>science</category>
  <guid>https://rachel.fast.ai/posts/2023-03-07-viruses1/index.html</guid>
  <pubDate>Mon, 06 Mar 2023 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2023-03-07-viruses1/exosomes.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>How to Remember Anything</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2023-02-21-anki/index.html</link>
  <description><![CDATA[ 




<section id="anki-is-a-learning-superpower" class="level2">
<h2 class="anchored" data-anchor-id="anki-is-a-learning-superpower">Anki is a learning superpower</h2>
<p>I have been using Anki flashcards to help me study. Anki is a free, open-source system based on the research of spaced repetition learning. I have been using this technique to study immunology, but it can be used for any subject. You make your own cards and they can include anything you like. Anki is an app available on Android, iPhone, and desktop, and it is easy to sync between your phone and computer (it is free on Android and desktop, although costs money for the iPhone). I want to explain the basics of the approach. This post is intended for people new to Anki– I will not cover power user features.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-02-21-anki/flashcard2.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">The front and back of one of my flashcards (the graphs are screenshots I took from one of my professor’s lectures)</figcaption>
</figure>
</div>
<p>Over 6 months ago, <a href="https://rachel.fast.ai/posts/2023-02-07-school-immunology/">I began studying immunology</a> every day. Every immunology professor I’ve watched lectures from has said that learning immunology is like learning a foreign language and that the amount of specialised jargon is intense. At first, I pulled out a notebook to write down what I wanted to remember. However, I soon decided to try out Anki flashcards instead.</p>
</section>
<section id="spaced-repetition-learning" class="level2">
<h2 class="anchored" data-anchor-id="spaced-repetition-learning">Spaced Repetition Learning</h2>
<p>In order to retain information, research shows that the best time to be quizzed about something you are learning is right before you otherwise would have forgotten it. For new information, this will be relatively soon. However, as you study a piece of information more times, you can go longer and longer before you need to be prompted about it. The other key factor in when you need to see a card again is how difficult a question is for you. If you find it easy, you can wait longer before you need to see it again, but if it’s hard, you should review it sooner. And if you got it wrong or didn’t know the answer, you should study it again in the same session. Anki handles the spacing of cards for you, keeping track of when you need to see each card again.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-02-21-anki/anki-streak2.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">My practice using Anki for the last 28 weeks (darker blue means more cards studied)</figcaption>
</figure>
</div>
<p>You create the cards. You can write with text, include images, and/or use a fill-in-the-blank format (called cloze). I usually make flashcards as I watch video lectures, pausing the video to screenshot images I want to use or to transcribe key points I want to remember. I make cards on my laptop as I watch videos and then study on my phone.</p>
</section>
<section id="again-hard-good-easy" class="level2">
<h2 class="anchored" data-anchor-id="again-hard-good-easy">Again, Hard, Good, Easy</h2>
<p>On the back of each card, at the bottom, Anki offers you 4 choices to rate whether you need to see the card again (choose this if you got it wrong) or whether you found it hard, good, or easy. For a new card, all the choices will lead to reviewing again soon, with “easy” corresponding to 4 days. However, over time, the choices for all options get longer as you answer the card correctly more times (except for “again”, which indicates you forgot and need to restart that card). This shows the options Anki gives on 3 different cards: a brand new one, one I’ve seen a few times, and one I’ve gotten correct many times (and likely won’t need to see again for many months).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-02-21-anki/anki-bottom.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">The lengths of time vary based on your history with the card</figcaption>
</figure>
</div>
<p>If you get a card wrong/need to see it again, Anki will reset to showing you the card with higher frequency again. Here is an old card that I missed. After I select “Again” (because I forgot an answer), these were the options the next time I see that card:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-02-21-anki/reset.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Resetting</figcaption>
</figure>
</div>
</section>
<section id="sustainable-over-time" class="level2">
<h2 class="anchored" data-anchor-id="sustainable-over-time">Sustainable over time</h2>
<p>Since you will see older cards less and less often (assuming you are getting them mostly correct), the number of Anki cards you need to do each day will decline with time if you don’t add more cards. This makes Anki feel very sustainable to pick up, and I have found a rhythm around how many new cards I can add each day, while keeping the time I spend on Anki relatively constant. <strong>It is reassuring to know that as long as I keep up on my daily cards, I will be able to retain the information I am learning.</strong></p>
<p>For instance, I can look at my stats on Anki and see that today I did 114 cards, but for each day going forward I will have less and less (this graph doesn’t take into account that I plan to continue adding new cards each day).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-02-21-anki/anki-stats.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">How many cards I will have each day going forward if I stop adding new cards</figcaption>
</figure>
</div>
</section>
<section id="for-all-ages-and-all-subjects" class="level2">
<h2 class="anchored" data-anchor-id="for-all-ages-and-all-subjects">For all ages and all subjects</h2>
<p>My daughter is currently taking <a href="https://biochemistryliteracyforkids.com/">Biochemistry Literacy for Kids</a>, a biochem course aimed at elementary aged children. The teacher suggested that the kids should memorise the 20 basic amino acids. While my daughter was initially unsure if she’d be able to do it, she had fun making up silly stories about each one (based on their structure and name), only spends a few minutes on Anki each day, and now has a strong sense of pride that she knows the amino acids (and her parents don’t).</p>
<p>My partner Jeremy used Anki <a href="https://vimeo.com/40265872">to study Chinese characters</a>. After 6 months of study, when he went to Beijing to attend an in-person Chinese school, he tested into a class where the other students had years of practice.</p>
</section>
<section id="combining-with-other-techniques" class="level2">
<h2 class="anchored" data-anchor-id="combining-with-other-techniques">Combining with other techniques</h2>
<p>Anki can (and should) be combined with other memory techniques, such as creating short stories that are funny, surprising, sexy, violent, unexpected, or related to family, friends, and celebrities (all these are attributes proven to make things more memorable).</p>
</section>
<section id="other-resources-on-effective-learning-and-memory" class="level2">
<h2 class="anchored" data-anchor-id="other-resources-on-effective-learning-and-memory">Other Resources on Effective Learning and Memory</h2>
<p>Many people incorrectly believe that memory is purely a fixed talent that you either have or you don’t, but there are a number of techniques proven to help make both memory and learning more effective. For more on how to learn effectively, here are several books, videos, and courses:</p>
<ul>
<li><a href="https://www.booktopia.com.au/moonwalking-with-einstein-joshua-foer/book/9780143120537.html">Moonwalking with Einstein: The Art and Science of Remembering Everything</a>, by Joshua Foer</li>
<li><a href="https://www.penguin.com.au/books/remember-remember-9780141903545">Remember, Remember</a>, by world memory champion Ed Cooke</li>
<li><a href="https://barbaraoakley.com/books/a-mind-for-numbers/">A Mind For Numbers: How to Excel at Math and Science (Even If You Flunked Algebra), by Barbara Oakley</a></li>
<li><a href="https://vimeo.com/40265872">Jeremy Howard’s talk on techniques for learning Chinese</a></li>
<li><a href="https://www.coursera.org/learn/learning-how-to-learn">Coursera class on Learning How to Learn</a>, taught by Barbara Oakley. This is one of the most popular Coursera courses of all time.</li>
<li><a href="https://rachel.fast.ai/posts/2022-03-15-math-person/">There’s no such thing as not a math person</a>: my post about learning math and myths of innate ability</li>
</ul>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>advice</category>
  <category>education</category>
  <guid>https://rachel.fast.ai/posts/2023-02-21-anki/index.html</guid>
  <pubDate>Mon, 20 Feb 2023 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2023-02-21-anki/stats.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>I was an AI researcher. Now, I am an immunology student.</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2023-02-07-school-immunology/index.html</link>
  <description><![CDATA[ 




<p>I like complexity, and I like challenges. When a new topic fascinates me, I want to devote all of my time to it. In 2012, I was working as a quant in energy trading when I became so captivated by the topic of machine learning that I abruptly moved cross-country to San Francisco and spent a decade learning as much as I could about machine learning, AI, data ethics, and algorithmic harms. In 2022, I became fascinated by a new topic: immunology. I completed 7 online courses last year, am currently taking 4 more courses, and have created over 2,000 immunology-related flashcards for myself, which I spend time on daily. (I will write more about how I use Anki flashcards in a future post.)</p>
<p>I found immunology to be both overwhelming and fascinating. The field is full of jargon, and there is a steep curve just to learn the language: IL-2, IL-4, IL-5, IL-12, IL-13, IL-18, CD-3, CD-22, CD-34, CD-47, CD-155, C3, C5, C8, and so on (lots of letter/number combinations, abbreviations, and acronyms! But underneath them, the mechanisms are fascinating). The more I studied, the more I wanted to learn. It became clear that I needed a formal program to go deeper and to provide appropriate context, so I started applying to graduate school.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-02-07-school-immunology/anki-streak.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">My daily study practice using Anki flashcards for the last 27 weeks (darker blue means more cards studied)</figcaption>
</figure>
</div>
<section id="back-to-school" class="level2">
<h2 class="anchored" data-anchor-id="back-to-school">Back to School</h2>
<p>I was delighted to be accepted to a Masters in Immunology graduate program, and after eager anticipation, last month I officially began my formal degree. While my ultimate goal is to apply my machine learning and data ethics expertise to the field, I want to make sure I fully understand the relevant immunology first. Too often machine learning practitioners unthinkingly grasp for a nail to use their hammer on, without first having the necessary in-depth knowledge of the underlying domain, its data, its context, and its actual challenges.</p>
<p>The more I learn about immunology, the more I realise how complex, vast, and full of open questions and not-yet-understood phenomena the field is. It was only in 2021 that researchers proved <a href="https://www.science.org/doi/10.1126/science.abj8222">Epstein-Barr virus causes multiple sclerosis</a>. Researchers are making new discoveries about <a href="https://www.cell.com/neuron/fulltext/S0896-6273(22)01147-3">links between viral infections and neurodegenerative diseases</a>, such as Alzheimer’s. A study in late 2022 found a possible mechanism to explain the fact that <a href="https://academic.oup.com/jid/advance-article/doi/10.1093/infdis/jiac405/6749009">varicella zoster virus significantly increases risk of stroke</a>. Unusually severe outbreaks of RSV and Group A Strep (a bacteria that can often follow as a secondary infection after a virus) made headlines in the past few months. A variety of viruses have long been known to sometimes trigger autoimmune diseases or cancer, yet there is still much to discover about these relationships.</p>
</section>
<section id="living-in-the-pandemicene" class="level2">
<h2 class="anchored" data-anchor-id="living-in-the-pandemicene">Living in the Pandemicene</h2>
<p>Even as the ongoing covid pandemic continues to cause death and disability, science journalist Ed Yong warned that <a href="https://www.theatlantic.com/science/archive/2022/04/how-climate-change-impacts-pandemics/629699/">we are now living in the <em>pandemicene</em></a>, a period with increasingly likely pandemics. Climate change is crowding species into new habitats, <a href="https://www.nature.com/articles/s41586-022-04788-w">raising the risks of viral spillover</a> from the estimated 40,000 viruses that inhabit mammals. Immunology, virology, and microbiology will become even more important in the coming decades.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-02-07-school-immunology/pandemicene.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Ed Yong’s article in The Atlantic</figcaption>
</figure>
</div>
</section>
<section id="mathematical-biology-and-ai-in-medicine" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-biology-and-ai-in-medicine">Mathematical Biology and AI in Medicine</h2>
<p>For over 20 years, my focus has been on mathematics, computer science, and data ethics. I studied mathematics, computer science, and linguistics as an undergraduate; earned a PhD in mathematics; and then spent 12 years working in a mix of industry and academia as a data scientist, teacher, and researcher. I am best known for my work as cofounder of fast.ai, creator of the most popular deep learning courses in the world, and for previously serving as the founding director of the University of San Francisco Center for Applied Data Ethics. Over the years, I have had a recurring interest in medicine, doing mathematical modelling of cell processes as part of a Howard Hughes Medical Institute fellowship while I was in graduate school, publishing about <a href="https://www.bostonreview.net/articles/rachel-thomas-medicines-machine-learning-problem">machine learning in medicine</a> for The Boston Review, and being an invited keynote speaker for <a href="https://www.youtube.com/watch?v=vVRWeGlMkGk&amp;list=PLtmWHNX-gukLQlMvtRJ19s7-8MrnRV6h6&amp;index=3">Stanford’s AI in Medicine</a> symposium.</p>
</section>
<section id="the-value-of-domain-expertise" class="level2">
<h2 class="anchored" data-anchor-id="the-value-of-domain-expertise">The value of domain expertise</h2>
<p>Core to the mission of fast.ai is the idea that domain expertise is crucial. In our very first post <a href="https://www.fast.ai/posts/2016-10-07-fastai-launch.html">announcing the launch of fast.ai</a> in 2016, my cofounder Jeremy Howard wrote, <em>“Only domain experts: fully understand and appreciate what are the most important problems in their field; have access to the data necessary to solve those problems; and understand the opportunities and constraints to implementing data driven solutions.”</em> It is dangerous for machine learning practitioners to apply machine learning to fields in which they have only superficial knowledge (unless working closely with domain experts from end-to-end). Collaborative, interdisciplinary, and career changing work has always fascinated me. I have written about how <a href="https://rachel.fast.ai/posts/2022-06-01-qualitative/">necessary qualitative humanities research</a> is to the field of AI. I previously taught software engineering to adult women changing careers, and long-believed that career changers have something special to offer. I am now taking my own advice, and delving into immunology, <strong>with the long-term goal of integrating this new knowledge with my data ethics and machine learning skills.</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2023-02-07-school-immunology/textbooks.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Excited to be back in school</figcaption>
</figure>
</div>
<p>After having been in a more “established” place in my career for a while, it is intimidating to publicly start off on a new branch like this. However, it’s also exciting, and I hope to share some of my journey as an immunology student along the way through blog posts and essays, just as <a href="https://rachel.fast.ai/posts/2019-05-13-blogging-advice/">I’ve always encouraged fast.ai students</a> to do.</p>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>education</category>
  <category>science</category>
  <guid>https://rachel.fast.ai/posts/2023-02-07-school-immunology/index.html</guid>
  <pubDate>Mon, 06 Feb 2023 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2023-02-07-school-immunology/textbooks.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>My family’s unlikely homeschooling journey</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2022-09-06-homeschooling/index.html</link>
  <description><![CDATA[ 




<p>My husband Jeremy and I never intended to homeschool, and yet we have now, unexpectedly, committed to homeschooling long-term. Prior to the pandemic, we both worked full-time in careers that we loved and found meaningful, and we sent our daughter to a full-day Montessori school. Although I struggled with significant health issues, I felt unbelievably lucky and fulfilled in both my family life and my professional life. The pandemic upended my careful balance. Every family is different, with different needs, circumstances, and constraints, and what works for one may not work for others. My intention here is primarily to share the journey of my own (very privileged) family.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-09-06-homeschooling/homeschool-headlines.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">We were not alone in discovering that homeschooling worked better for our child</figcaption>
</figure>
</div>
<section id="our-unplanned-introduction-to-homeschooling" class="level2">
<h2 class="anchored" data-anchor-id="our-unplanned-introduction-to-homeschooling">Our unplanned introduction to homeschooling</h2>
<p>For the first year of the pandemic, most schools in California, where we lived at the time, were closed. Like countless other families, we were unexpectedly thrust into the world of virtual-school and home-school. We ended up participating in an <a href="https://www.modulo.app/">innovative online program</a> that did NOT try to replicate in-person school. A few key differences:</p>
<ul>
<li>Each child could <strong>work at their own pace</strong>, largely through playing educational games and apps that adapted to where they were. There was no particular endpoint that the kids needed to get to at the end of the semester.</li>
<li>Group video calls were <strong>limited in size</strong> to no more than 6 kids (and often smaller), so kids got lots of personal interaction with their tutors and each other. Even as an adult, I find video calls larger than 6 people overwhelming.</li>
<li><strong>Regular movement breaks</strong>, where the kids had jumping jack competitions, did <a href="https://www.youtube.com/c/CosmicKidsYoga">Cosmic Kids yoga videos</a>, held dance parties, and ran around the house for scavenger hunts.</li>
<li><strong>Took advantage of existing materials</strong>: the program did not reinvent the wheel, but instead made use of excellent, existing online videos and educational apps.</li>
</ul>
<p>From August 2020 - March 2021, our daughter was with a small group online, where daily she would spend 1 hour on socio-emotional development (including games, getting to know each other, and discussing feelings), 1 hour on reading, and 1 hour on math. For reading and math, the children each worked at their own pace through engaging games, and could ask the teacher and each other questions whenever they needed help. At the end of these 8 months, our daughter, along with several other kids in her small group, were several years beyond their age levels in both math and reading. It had never been our goal for her to end up accelerated; Jeremy and I were mostly trying to keep her happy and busy for a few hours so we could get some of our own work done. She also had fun and made close friends, who she continues to have video calls and Minecraft virtual playdates with regularly.</p>
</section>
<section id="our-unconventional-views" class="level2">
<h2 class="anchored" data-anchor-id="our-unconventional-views">Our unconventional views</h2>
<p>Although there are plenty of ways to homeschool that don’t involve any screens or technology, Jeremy and I have made use of online tutors, long-distance friendships, educational apps, videos, and web-based games, as key parts of our approach. One thing that helped us going into the pandemic is that we have never treated online/long-distance relationships as inferior to in-person relationships. We both have meaningful friendships that occur primarily, or even entirely, through phone calls, video chats, texts, and online interactions. I have made several big moves since I graduated from high school (moving from Texas to Pennsylvania to North Carolina back to Pennsylvania again and then to California) and I was used to family and close friends being long distance. We live far from our families, and our daughter was already accustomed to chatting with her grandparents on both sides via video calls. My daughter’s best friend is now a child she has never met in person, but has been skyping with almost daily for the last 2 years.</p>
<p>Another thing that made this transition easier is that Jeremy and I have never been anti-screen time. In fact, we don’t consider “screen time” a useful category, since a child passively watching a movie alone is different than skyping with their grandparent is different than playing an educational game interactively with their parent beside them. While we almost never let our daughter do things passively and alone with screens, we enjoy relational and educational screen time. Furthermore, we focus on including other positive life elements (e.g.&nbsp;making sure she is getting enough time outside, being physically active, reading, getting enough sleep, etc) rather than emphasising limits.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-09-06-homeschooling/venndiagram.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">A Venn Diagram showing how I think about screentime. We avoid the outside (white) region and mostly stick to the intersections.</figcaption>
</figure>
</div>
</section>
<section id="a-return-to-in-person-school" class="level2">
<h2 class="anchored" data-anchor-id="a-return-to-in-person-school">A return to in-person school</h2>
<p>In 2021, our family immigrated from the USA to my husband’s home country of Australia, and we enrolled our daughter at an in-person school, which she attended from late April - early Dec 2021. Our state had closed borders and almost no cases of covid transmission during this time. By all measures, the school she attended is great: friendly families, kind staff, and a fun performing arts program. While our daughter adjusted quickly to the new environment and made friends, she was quite bored. She lost her previous curiosity and enthusiasm, became more passive, and started to spend a lot of time zoning out. The school tried to accommodate her, letting her join an older grade level for math each day. While the material was initially new, she still found the pace too slow. She started to get very upset at home practising piano or playing chess (activities she previously loved, but where mistakes are inevitable), because she had grown accustomed to getting everything right without trying. At one point, all schools in our region closed <a href="https://www.nytimes.com/live/2021/07/31/world/covid-delta-variant-vaccine/brisbane-australias-third-largest-city-joins-sydney-in-lockdown">during an 8-day snap lockdown.</a> Our daughter was disappointed when the lockdown ended and she had to return to school.</p>
</section>
<section id="when-homeschooling-works-well-and-when-it-doesnt" class="level2">
<h2 class="anchored" data-anchor-id="when-homeschooling-works-well-and-when-it-doesnt">When homeschooling works well (and when it doesn’t)</h2>
<p>Over the summer holidays (Dec 2021-Jan 2022), our state pivoted from zero covid to <a href="https://medium.com/@ColinKinner/lethal-stupidity-how-the-palaszczuk-governments-covid-response-has-thrown-queenslanders-under-52a127d67724">promoting mass infection as “necessary”</a>. We pulled our daughter out of school, initially intending that it would just be a temporary measure until her age group could be fully vaccinated (vaccine rollout was later in Australia than in the USA). However, we immediately saw positive changes, with her regaining her old curiosity, enthusiasm, and proactive nature, all of which she had lost being in school. Her perfectionism disappeared and she began to enjoy challenges again. We supplemented her online classes with in-person playdates, extracurriculars, and sports (due to covid risks, we wear masks and stay outdoors for all of these). We are fortunate to live in a beautiful part of the world, where we can spend most of the year outside. We enjoy visiting the beaches, forests, and parks in our region. Our daughter is happy: playing Minecraft with friends online, learning tennis with other local children, riding bikes as a family, spending hours absorbed in books of her own choosing, enjoying piano and chess again, running around in nature, and learning at her own pace.</p>
<p>Homeschooled kids typically score <a href="https://www.nheri.org/research-facts-on-homeschooling/">15 to 30 percentile points</a> above public-school students on standardised academic achievement tests, and <a href="https://www.nheri.org/research-facts-on-homeschooling/">87% of studies on social development</a> “showed clearly positive outcomes for the homeschooled compared to those in conventional schools”. However, it is understandable that many children had negative experiences with virtual learning in the past 2 years, given that programs were often hastily thrown together with inadequate resources and inappropriately structured to try to mimic in-person school, against the stressful backdrop of a global pandemic. Many parents faced the impossible task of simultaneously needing to work full-time and help their children full-time (and many other parents did not even have the option to stay home). Every family is different, and virtual learning or homeschooling will not suit everyone. There are children who need in-person services only offered within schools; parents whose work constraints don’t allow for it; and kids who thrive being with tons of other kids.</p>
<p>Despite the difficulty of the pandemic, there are a variety of families who found that virtual or homeschooling was better for their particular kids. Some parents have shared about children with <a href="https://www.nytimes.com/2020/08/10/opinion/coronavirus-school-closures.html">ADHD who found in-person school too distracting; children who were facing bullying or violence at school; kids who couldn’t get enough sleep on a traditional school schedule</a>; <a href="https://www.wired.com/story/pandemic-homeschoolers-who-are-not-going-back/">Black and Latino families whose cultural heritages were not being reflected in curriculums</a>. I enjoyed these article featuring a few such families:</p>
<ul>
<li><a href="https://www.nytimes.com/2020/08/10/opinion/coronavirus-school-closures.html">What if Some Kids Are Better Off at Home? | The New York Times</a> <em>For parents like me, the pandemic has come with a revelation: For our children, school was torture.</em></li>
<li><a href="https://www.wired.com/story/pandemic-homeschoolers-who-are-not-going-back/">They Rage-Quit the School System—and They’re Not Going Back | WIRED</a> <em>The pandemic created a new, more diverse, more connected crop of homeschoolers. They could help shape what learning looks like for everyone.</em></li>
</ul>
</section>
<section id="covid-risks" class="level2">
<h2 class="anchored" data-anchor-id="covid-risks">Covid Risks</h2>
<p>I have had brain surgery twice, was hospitalised in the ICU with a life-threatening brain infection, and have a number of chronic health issues. I am both at higher risk for negative outcomes from covid AND acutely aware of how losing your health can destroy your life. It is lonely and difficult being high-risk in a society that has given up on protecting others. While I am nervous about the long-term impact that homeschooling will have on my career (on top of how <a href="https://medium.com/@racheltho/techs-long-hours-are-discriminatory-and-counterproductive-3676e649a601">my existing health issues already hinder it</a>), acquiring additional disabilities would be far, far worse.</p>
<p>I have been disturbed to follow the ever-accumulating research on <a href="https://www.nature.com/articles/d41586-022-00403-0">cardiovascular</a>, <a href="https://www1.racgp.org.au/newsgp/clinical/research-suggests-covid-affects-brain-even-in-mild">neurological</a>, and <a href="https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-021-02228-6">immune system</a> harms that can be caused by covid, even in <a href="https://missoulian.com/news/local/missed-risk-long-covid-threat-extends-far-beyond-pandemic/article_70311453-1f78-5068-b1ea-02886b41741a.html#tracking-source=most-popular-homepage">previously healthy people</a>, even in <a href="https://www.nature.com/articles/d41586-022-01453-0">the vaccinated</a>, and <a href="https://fortune.com/2022/08/04/covid-creates-higher-risk-kids-children-pediatric-blood-clots-kidney-failure-heart-problems-type-1-diabetes/">even in children</a>. While vaccines significantly reduce risk of death, unfortunately they provide <a href="https://www.nature.com/articles/d41586-022-01453-0">only a limited reduction in Long Covid risk</a>. Immunity wanes, and people face <a href="https://www.abc.net.au/news/2022-06-24/reinfection-covid-more-severe-new-variants/101178246">cumulative risks with each new covid infection</a> (so even if you’ve had covid once or twice, it is best to try to avoid reinfections). I am alarmed that <a href="https://twitter.com/ColinKinner/status/1557257474235076608?s=20&amp;t=hjlgmHIe24111OVNRCDk_Q">leaders are encouraging</a> mass, repeated infections of a generation of children.</p>
<p>Given all this, I am relieved that our decision to continue homeschooling was relatively clear. It much better suits our daughter’s needs AND drastically reduces our family’s covid risk. We can nurture her innate curiosity, protect her intrinsic motivation, and provide in-person social options that are entirely outdoors and safer than being indoors all day at school. Most families are not so fortunate and many face difficult choices, with no good options.</p>
</section>
<section id="the-broader-picture" class="level2">
<h2 class="anchored" data-anchor-id="the-broader-picture">The Broader Picture</h2>
<p>I believe that high-quality, equitable, and safe public education is important for a healthy democracy, and I worry about the various ongoing ways in which education is being undermined and attacked. Furthermore, due to a lack of covid protections in communities, high-risk children and children with high-risk families are being shut out of in-person school options in the USA, Australia, and many other places. While the <a href="https://twitter.com/math_rachel/status/1464827214298443780?s=20&amp;t=sRWCS-xGf3G57R4LVWcDdQ">workplaces of politicians</a> and a handful of <a href="https://twitter.com/myrabatchelder/status/1485870339368366083?s=20&amp;t=sRWCS-xGf3G57R4LVWcDdQ">schools in ultra-wealthy areas</a> installed expensive ventilation upgrades, the majority of schools in the USA and Australia have not had any ventilation upgrades, nor received air purifiers. All children deserve access to an education that is safe, fits their needs, and will allow them to thrive. Even when homeschooling does work, it is often still just an individual solution to systemic problems.</p>
</section>
<section id="related-posts" class="level2">
<h2 class="anchored" data-anchor-id="related-posts">Related Posts</h2>
<p>A few other posts that you may be interested in, related to my views on education and teaching:</p>
<ul>
<li><a href="https://www.fast.ai/2022/03/15/math-person/">There’s No Such Thing as Not A Math Person</a>: based on a webinar I gave to parents addressing cultural myths about math and how to support your kids in their math education, even if you don’t see yourself as a “math person”</li>
<li><a href="https://www.fast.ai/2016/10/08/teaching-philosophy/">The Qualities of a Good Education</a>: common pitfalls in traditional technical education and ideas towards doing better</li>
<li><a href="https://www.fast.ai/2018/08/27/grad-school/">What You Need to Know Before Considering a PhD</a>: includes a reflection on how my own success in traditional academic environments was actually a weakness, because I’d learned how to solve problems I was given, but not how to how to find and scope interesting problems on my own</li>
</ul>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>education</category>
  <guid>https://rachel.fast.ai/posts/2022-09-06-homeschooling/index.html</guid>
  <pubDate>Mon, 05 Sep 2022 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2022-09-06-homeschooling/homeschool-headlines.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Qualitative humanities research is crucial to AI</title>
  <dc:creator>Louisa Bartolo and Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2022-06-01-qualitative/index.html</link>
  <description><![CDATA[ 




<center>
<em>“All research is qualitative; some is also quantitative”</em> <br>– Harvard Social Scientist and Statistician Gary King
</center>
<p><br> Suppose you wanted to find out whether a machine learning system being adopted - to <a href="https://hbr.org/2019/05/all-the-ways-hiring-algorithms-can-introduce-bias">recruit candidates</a>, <a href="https://mitibmwatsonailab.mit.edu/research/blog/black-loans-matter-fighting-bias-for-ai-fairness-in-lending/">lend money</a>, or <a href="https://www.propublica.org/podcast/how-we-decided-to-test-racial-bias-in-algorithms">predict future criminality</a> - exhibited racial bias. You might calculate model performance across groups with different races. But <a href="https://dl.acm.org/doi/10.1145/3351095.3372826">how was race categorised</a>– through a census record, a <a href="https://www.youtube.com/watch?v=s24vksJRJeE&amp;list=PLgdVmcMc8gy4sVLlgM0GUnnVZ1Fu0et05&amp;index=6">police officer’s guess</a>, or by an annotator? Each possible answer raises another set of questions. Following the thread of any seemingly quantitative issue around AI ethics quickly leads to a host of qualitative questions. Throughout AI, qualitative decisions are made about what metrics to optimise for, which categories to use, how to define their bounds, who applies the labels. Similarly, qualitative research is necessary to understand AI systems operating in society: evaluating system performance beyond what can be captured in short term metrics, understanding what is missed by large-scale studies (which can elide details and overlook outliers), and shedding light on the circumstances in which data is produced (often by crowd-sourced or poorly paid workers).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-06-01-qualitative/biasheadlines.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Attempting to measure racial bias leads to qualitative questions</figcaption>
</figure>
</div>
<p>Unfortunately, there is often a <a href="https://journals.sagepub.com/doi/full/10.1177/2053951719833404">large divide between</a> computer scientists and social scientists, with over-simplified assumptions and fundamental misunderstandings of one another. Even when cross-disciplinary partnerships occur, <a href="https://journals.sagepub.com/doi/full/10.1177/2053951719833404">they often fall</a> into “normal disciplinary divisions of labour: social scientists observe, data scientists make; social scientists do ethics, data scientists do science; social scientists do the incalculable, data scientists do the calculable.” The solution is not for computer scientists to absorb a shallow understanding of the social sciences, but for deeper collaborations. In a paper on <a href="https://dl.acm.org/doi/10.1145/3442188.3445914">exclusionary practices in AI ethics</a>, an interdisciplinary team wrote of the “indifference, devaluation, and lack of mutual support between CS and humanistic social science (HSS), [which elevates] the myth of technologists as ‘ethical unicorns’ that can do it all, though their disciplinary tools are ultimately limited.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-06-01-qualitative/Abstract-art-britto-qb140.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">There are challenges when mixing computer scientsits with social scientists. (Gallery Britto image under Creative Commons Attribution-Share Alike 4.0 International)</figcaption>
</figure>
</div>
<p>This is further reflected in an increasing number of <a href="https://twitter.com/cfiesler/status/1427341587613376514?s=20&amp;t=_5Ud6jmEELMulK5LSha9gA">job ads</a> for AI ethicists that list a <a href="https://www.businessinsider.com/ai-ethics-jobs-catherine-hicks-algorithms">computer science degree as a requirement</a>, “prioritising technical computer science infrastructure over the social science skills that can evaluate AI’s social impact. In doing so, we are building the field of AI Ethics to replicate the very flaws this field is trying to fix.” <a href="https://arxiv.org/abs/2006.12358">Interviews with 26 responsible AI practitioners</a> working in industry highlighted a number of challenges, including that qualitative work was not prioritised. Not only is it impossible to fully understand ethics issues solely through quantitative metrics, inappropriate and misleading quantitative metrics are used to evaluate the responsible AI practitioners themselves. Interviewees reported that their fairness work was evaluated on metrics related to generating revenue, in a stark misalignment of goals.</p>
<section id="qualitative-research-helps-us-evaluate-ai-systems-beyond-short-term-metrics" class="level2">
<h2 class="anchored" data-anchor-id="qualitative-research-helps-us-evaluate-ai-systems-beyond-short-term-metrics">Qualitative research helps us evaluate AI systems beyond short term metrics</h2>
<p>When companies like Google and YouTube want to test whether the recommendations they are making (in the form of search engine results or YouTube videos, for example) are “good” - they will often focus quite heavily on “engagement” or “dwell time” - the time a user spent looking at or watching the item recommended to them. But it turns out, unsurprisingly, that a focus on engagement and dwell time, narrowly understood, <a href="https://arxiv.org/abs/2006.12358">raises all sorts of problems</a>. <a href="https://dl.acm.org/doi/abs/10.1145/3041021.3054197?casa_token=BxsZ44gFqdQAAAAA:uMs35O3Qn8oFsHM8LBYo2XJ5jnQGPD4L2NWhxa7iVa5MMwovG-zd3hoEixb9F5_up1LM0kNSG9Krew">Demographics can impact dwell time</a> (e.g.&nbsp;older users may spend longer on websites than younger users, just as part of the way they use the internet). A system that ‘learns’ from a user’s behavioural cues (rather than their ‘stated preferences’) might lock them into a limiting feedback loop, <a href="https://dl.acm.org/doi/10.1145/2959100.2959179">appealing to that user’s short term interests rather than those of their ‘Better Selves.’</a> Scholars have called for <a href="https://datascience.columbia.edu/news/2018/ethical-principles-okrs-and-kpis-what-youtube-and-facebook-could-learn-from-tukey/">more qualitative research</a> to understand user experience and build this into <a href="https://www.cell.com/patterns/fulltext/S2666-3899(22)00056-3">the development of metrics</a>.</p>
<p>This is the part where people will point out, rightly, that companies like Google and YouTube rely on a complex range of metrics and signals in their machine learning systems - and that where a website ranks on Google, or how a YouTube video performs in recommendation does not boil down to simple popularity metrics, like engagement. Google employs an extensive process to determine <a href="https://www.google.com/search/howsearchworks/mission/users/">“relevance” and “usefulness” for search results</a>. In its <a href="https://support.google.com/websearch/answer/9281931?hl=en">172-page manual for search result ‘Quality’ evaluation</a>, for example, the company explains how evaluators should assess a website’s ‘Expertise/ Authoritativeness/ Trustworthiness’ or ‘E-A-T’; and what types of content, by virtue of its harmful nature (e.g., to protected groups), should be given a ‘low’ ranking. YouTube has identified specific categories of content (such as news, scientific subjects, and historical information) for which ‘authoritativeness’ should be considered especially important. It has also determined that dubious-but-not-quite-rule-breaking information (what it calls ‘borderline content’) should not be recommended, <a href="https://blog.youtube/inside-youtube/the-four-rs-of-responsibility-raise-and-reduce/">regardless of the video’s engagement levels</a>.</p>
<p>Irrespective of how successful we consider the existing approaches of Google Search and YouTube to be (and partly, the issue is that evaluating their implementation from the outside is frustratingly difficult), the point here is that there are constant qualitative judgments being made, about what makes a search result or recommendation “good” and of how to define and quantify expertise, authoritativeness, trustworthiness, borderline content, and other values. This is true of all machine learning evaluation, even when it isn’t explicit. In a paper guiding companies about <a href="https://dl.acm.org/doi/10.1145/3351095.3372873">how to carry out internal audits of their AI systems</a>, Inioluwa Deborah Raji and colleagues emphasise the importance of interviews with management and engineering teams to “capture and pay attention to what falls outside the measurements and metrics, and to render explicit the assumptions and values the metrics apprehend.” (p.40).</p>
<p>The importance of thoughtful humanities research is heightened if we are serious about grappling with the potential broader social effects of machine learning systems (both good and bad), which are often <a href="https://policyreview.info/articles/analysis/beyond-individual-governing-ais-societal-harm">delayed, distributed and cumulative</a>.</p>
</section>
<section id="small-scale-qualitative-studies-tell-an-important-story" class="level2">
<h2 class="anchored" data-anchor-id="small-scale-qualitative-studies-tell-an-important-story">Small-scale qualitative studies tell an important story</h2>
<p>Hypothetically, let’s say you wanted to find out whether the use of AI technologies by doctors during a medical appointment would make doctors less attentive to patients - what do you think the best way of doing it would be? You could find some criteria and method for measuring ‘attentiveness’, say tracking the amount of eye contact between the doctor and patient, and analyse this across a representative sample of medical appointments where AI technologies were being used, compared to a control group of medical appointments where AI technologies weren’t being used. Or would you interview doctors about their experiences using the technology during appointments? Or talk to patients about how they felt the technology did, or didn’t, impact their experience?</p>
<p>In research circles, we describe these as ‘epistemological’ choices - your judgement of what constitutes the ‘best’ approach is inextricably linked to your judgement about <a href="https://theconversation.com/how-do-you-know-that-what-you-know-is-true-thats-epistemology-63884"><em>how</em> we can claim to ‘know’ something</a>. These are all valid methods for approaching the question, but you can imagine how they might result in different, even conflicting, insights. For example, you might end up with the following results: - The eye contact tracking experiment suggests that overall, there is no significant difference in doctors’ attentiveness to the patient when the AI tech is introduced. - The interviews with doctors and patients reveal that some doctors and patients feel that the AI technology reduces doctors’ attentiveness to patients, and others feel that it makes no difference or even increases doctors’ attention to the patient.</p>
<p>Even if people are not negatively impacted by something ‘on average’ (e.g., in our hypothetical eye contact tracking experiment above), there will remain groups of people who will experience negative impacts, perhaps acutely so. “Many of people’s most pressing questions are about effects that vary for different people,” write Matias, Pennington and Chan in a recent paper on the <a href="https://osf.io/tn6x4/">idea of N-of-one trials</a>. To tell people that their experiences aren’t real or valid because they don’t meet some threshold for statistical significance across a large population doesn’t help us account for the breadth and nature of AI’s impacts on the world.</p>
<p>Examples of this tension between competing claims to knowledge about AI systems’ impacts abound. Influencers who believe they are being systematically downranked (‘shadowbanned’) by Instagram’s algorithmic systems are told by Instagram that this simply isn’t true. Given the inscrutability of these proprietary algorithmic systems, it is impossible for influencers to convincingly dispute Instagram’s claims. Kelley Cotter refers to this as a form of <a href="https://www.tandfonline.com/doi/full/10.1080/1369118X.2021.1994624">“black box gaslighting”</a>: platforms can “leverage perceptions of their epistemic authority on their algorithms to undermine users’ confidence in what they know about algorithms and destabilise credible criticism.” Her interviews with influencers give voice to stakeholder concerns and perspectives that are elided in Instagram’s official narrative about its systems. The mismatch between different stakeholders’ accounts of ‘reality’ is instructive. For example, a widely-cited paper by Netflix employees claims that Netflix recommendation <a href="https://dl.acm.org/doi/10.1145/2843948">“influences choice for about 80% of hours streamed at Netflix.”</a> But this claim stands in stark contrast to Mattias Frey’s mixed-methods research (representative survey plus small sample for interviews) run with UK and US adults, in which <a href="https://www.ucpress.edu/book/9780520382046/netflix-recommends#:~:text=Netflix%20Recommends%20brings%20to%20light,critics%20is%20stronger%20than%20ever.">less than 1 in 5 adults said they primarily relied on Netflix recommendations</a> when deciding what films to watch. Even if this is because users underestimate their reliance on recommender systems, that’s a critically important finding - particularly when we’re trying to regulate recommendation and so many are advocating providing better user-level controls as a check on platform power. Are people really going to go to the trouble of changing their settings if they don’t think they rely on algorithmic suggestions that much anyway?</p>
</section>
<section id="qualitative-research-sheds-light-on-the-context-of-data-annotation" class="level2">
<h2 class="anchored" data-anchor-id="qualitative-research-sheds-light-on-the-context-of-data-annotation">Qualitative research sheds light on the context of data annotation</h2>
<p>Machine learning systems rely on vast amounts of data. In many cases, for that data to be useful, it needs to be labelled/ annotated. For example, a hate speech classifier (an AI-enabled tool used to identify and flag potential cases of hate speech on a website) relies on huge datasets of text labelled as ‘hate speech’ or ‘not hate speech’ to ‘learn’ how to spot hate speech. But it turns out that <a href="https://arxiv.org/abs/2112.04554"><em>who</em> is doing the annotating and in <em>what context</em> they’re doing it, matters</a>. AI-powered content moderation is often held up as the solution to harmful content online. What has continued to be underplayed is the extent to which those automated systems are and most likely will remain dependent on the manual work of human content moderators sifting through some of the worst and most traumatic online material to power the machine learning datasets on which automated content moderation depends. Emily Denton and her colleagues highlight the significance of annotators’ social identity (e.g., race, gender) and their expertise when it comes to annotation tasks, and they point out the risks associated with overlooking these factors and simply ‘aggregating’ results as ‘ground truth’ rather than properly exploring disagreements between annotators and the important insights that this kind of disagreement might offer.</p>
<p>Human commercial content moderators (such as the people that identify and remove violent and traumatic imagery on Facebook) often labour in terrible conditions, lacking psychological support or appropriate financial compensation. The <a href="https://yalebooks.yale.edu/book/9780300261479/behind-the-screen/">interview-based research of Sarah T. Roberts</a> has been pioneering in highlighting these conditions. Most demand for crowdsourced digital labour comes from the Global North, <a href="https://journals.sagepub.com/doi/full/10.1177/1024258916687250">yet the majority of these workers</a> are based in the Global South and receive low wages. Semi-structured interviews reveal the extent to which workers feel unable to bargain effectively for better pay in the current regulatory environment. As Mark Graham and his colleagues point out, these findings are hugely important in a context where several governments and supranational development organisations like the World Bank are holding up digital work as a promising tool to fight poverty.</p>
<p>The decision of how to measure ‘race’ in machine learning systems is highly consequential, especially in the context of existing efforts to evaluate these systems for their “fairness.” Alex Hanna, Emily Denton, Andrew Smart and Jamila Smith-Loud have done <a href="https://dl.acm.org/doi/10.1145/3351095.3372826">crucial work highlighting the limitation</a> of machine learning systems that rely on official records of race or their proxies (e.g.&nbsp;census records), noting that the racial categories provided by such records are “unstable, contingent, and rooted in racial inequality.” The authors emphasise the importance of conducting research in ways that prioritise the perspectives of the marginalised racial communities that fairness metrics are supposed to protect. Qualitative research is ideally placed to contribute to a consideration of “race” in machine learning systems that is grounded in the lived experiences and needs of the racially subjugated.</p>
</section>
<section id="what-next" class="level2">
<h2 class="anchored" data-anchor-id="what-next">What next?</h2>
<p>Collaborations between quantitative and qualitative researchers are valuable in understanding AI ethics from all angles.</p>
<p>Consider reading more broadly, outside your particular area. Perhaps using the links and researchers listed here as starting points. They’re just a sliver of the wealth that’s out there. You could also check out the <a href="https://socialmediacollective.org/reading-lists/critical-algorithm-studies/">Social Media Collective’s Critical Algorithm Studies reading list</a>, the reading list provided by the <a href="https://zoeglatt.com/?page_id=545">LSE Digital Ethnography Collective</a>, and <a href="https://medium.com/fair-bytes/reading-list-for-fairness-in-ai-topics-337e8606fd8d">Catherine Yeo’s suggestions</a>.</p>
<p>Strike up conversations with researchers in other fields, and consider the possibility of collaborations. Find a researcher slightly outside your field but whose work you broadly understand and like, and follow them on Twitter. With any luck, they will share more of their work and help you identify other researchers to follow. Collaboration can be an incremental process: Consider inviting the researcher to form part of a discussion panel, reach out to say what you liked and appreciated about their work and why, and share your own work with them if you think it’s aligned with their interests.</p>
<p>Within your university or company, is there anything you could do to better reward or facilitate interdisciplinary work? As Humanities Computing Professor <a href="https://www.tandfonline.com/doi/full/10.1080/03080188.2022.2031659">Willard McCarty notes</a>, somewhat discouragingly, “professional reward for genuinely interdisciplinary research is rare.” To be sure, individual researchers and practitioners have to be prepared <a href="https://sciencetechnologystudies.journal.fi/article/view/97321/56310">to put themselves out there, compromise</a> and <a href="https://www.mccarty.org.uk/essays/McCarty,%20Becoming%20interdisciplinary.pdf">challenge themselves</a> - but carefully tailored <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/ijmr.12016?casa_token=9f4Qosl_MLEAAAAA%3AMFozyMi171KgZ-BYQrpS-1bK71gt70I4ecjy8lLId54-2zvTobqCGKIK_-9_hEk8-wI5vMR0Em5-">institutional incentives and enablers matter</a>.</p>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>ethics</category>
  <category>machine learning</category>
  <guid>https://rachel.fast.ai/posts/2022-06-01-qualitative/index.html</guid>
  <pubDate>Tue, 31 May 2022 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2022-06-01-qualitative/Abstract-art-britto-qb140.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI Harms are Societal, Not Just Individual</title>
  <dc:creator>Rachel Thomas and Louisa Bartolo</dc:creator>
  <link>https://rachel.fast.ai/posts/2022-05-17-societal-harms/index.html</link>
  <description><![CDATA[ 




<section id="not-just-individual-but-societal-harms" class="level2">
<h2 class="anchored" data-anchor-id="not-just-individual-but-societal-harms">Not just Individual, but Societal Harms</h2>
<p>When the USA government switched to facial identification service ID.me for unemployment benefits, the software <a href="https://www.cpr.org/2021/07/07/colorado-unemployment-idme-glitch-internet-access/">failed to recognize Bill Baine’s face</a>. While the app said that he could have a virtual appointment to be verified instead, he was unable to get through. The screen had a wait time of 2 hours and 47 minutes that never updated, even over the course of weeks. He tried calling various offices, his daughter drove in from out of town to spend a day helping him, and yet he was never able to get a useful human answer on what he was supposed to do, as he went for months without unemployment benefits. In Baine’s case, it was eventually resolved when a journalist hypothesized that the issue was a spotty internet connection, and that Baine would be better off traveling to another town to use a public library computer and internet. Even then, it still took hours for Baine to get his approval.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-05-17-societal-harms/cpr-news-bill-blaine.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Journalist Andrew Kenney of Colorado Public Radio has covered the issues with ID.me</figcaption>
</figure>
</div>
<p>Baine was not alone. The number of people receiving unemployment benefits plummeted by 40% in the 3 weeks after ID.me was introduced. Some of these were presumed to be fraudsters, but it is unclear how many genuine people in need of benefits were wrongly harmed by this. These are individual harms, but there are broader, societal harms as well: the cumulative costs of the public having to spend ever more time on hold, trying to navigate user-hostile automated bureaucracies where they can’t get the answers they need. There is the societal cost of greater inequality and greater desperation, as more people are plunged into poverty through erroneous denial of benefits. And there is the undermining of trust in public services, which can be difficult to restore.</p>
<p><a href="https://fpf.org/wp-content/uploads/2017/12/FPF-Automated-Decision-Making-Harms-and-Mitigation-Charts.pdf">Potential for algorithmic harm</a> takes many forms: loss of opportunity (employment or housing discrimination), economic cost (credit discrimination, narrowed choices), social detriment (stereotype confirmation, dignitary harms), and loss of liberty (increased surveillance, disproportionate incarceration). And each of these four categories manifests in both individual and societal harms.</p>
<p>It should come as no surprise that algorithmic systems can give rise to societal harm. These systems are sociotechnical: they are designed by humans and teams that bring their values to the design process, and <a href="https://www.sciencedirect.com/science/article/pii/S2666389921000155">algorithmic systems continually draw information from, and inevitably bear the marks of, fundamentally unequal, unjust societies</a>. In the context of COVID-19, for example, <a href="https://www.bmj.com/content/372/bmj.n304">policy experts warned</a> that historical healthcare inequities risked making their way into the datasets and models being used to predict and respond to the pandemic. And while it’s intuitively appealing to think of large-scale systems as creating the greatest risk of societal harm, algorithmic systems can create societal harm because of the <a href="https://cerre.eu/publications/what-is-the-harm-in-size/">dynamics set off by their interconnection with other systems/ players</a>, like <a href="https://www.nature.com/articles/s42256-021-00358-3">advertisers</a>, or commercially-driven media, and the ways in which they touch on sectors or spaces of public importance.</p>
<p>Still, in the west, our ideas of harm are often anchored to an individual being harmed <a href="https://policyreview.info/articles/analysis/beyond-individual-governing-ais-societal-harm">by a particular action at a discrete moment in time</a>. As law scholar Natalie Smuha has powerfully argued, legislation (both proposed and passed) in Western countries to address algorithmic risks and harms often focuses on individual rights: regarding how an individual’s data is collected or stored, to not be discriminated against, or to know when AI is being used. Even metrics used to evaluate the fairness of algorithms are often aggregating across individual impacts, but unable to capture longer-term, more complex, or second- and third-order societal impacts.</p>
</section>
<section id="case-study-privacy-and-surveillance" class="level2">
<h2 class="anchored" data-anchor-id="case-study-privacy-and-surveillance">Case Study: Privacy and surveillance</h2>
<p>Consider the over-reliance on individual harms in discussing privacy: so often focused on whether individual users have the ability to opt in or out of sharing their data, notions of individual consent, or proposals that individuals be paid for their personal data. Yet widespread surveillance fundamentally changes society: people may begin to self-censor and to be less willing (or able) to advocate for justice or social change. Professor Alvaro Bedoya, director of the Center on Privacy and Technology at the Georgetown University Law Center, <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3599201">traces a history</a> of how surveillance has been used by the state to try to shut down movements for progress– targeting religious minorities, poor people, people of color, immigrants, sex workers and those considered “other”. <a href="https://idlewords.com/2019/06/the_new_wilderness.htm">As Maciej Ceglowski</a> writes, “Ambient privacy is not a property of people, or of their data, but of the world around us… Because our laws frame privacy as an individual right, we don’t have a mechanism for deciding whether we want to live in a surveillance society.”</p>
<p><a href="https://arxiv.org/abs/2103.01168">Drawing on interviews with African data experts</a>, Birhane et al write that even when data is anonymized and aggregated, it “can reveal information on the community as a whole. While notions of privacy often focus on the individual, there is growing awareness that collective identity is also important within many African communities, and that sharing aggregate information about communities can also be regarded as a privacy violation.” Recent US-based scholarship has also highlighted the importance of thinking about <a href="https://link.springer.com/chapter/10.1007/978-3-030-82786-1_6">group level privacy</a> (whether that group is made up of individuals who identify as members of that group, or whether it’s a ‘group’ that is algorithmically determined - like individuals with similar shopping habits on Amazon). Because even aggregated anonymised data can reveal important group-level information (e.g., the location of military personnel training via exercise tracking apps) “managing privacy”, these authors argue “is often not intrapersonal but interpersonal.” And yet legal and tech design privacy solutions are often better geared towards assuring individual-level privacy than negotiating group privacy.</p>
</section>
<section id="case-study-disinformation-and-erosion-of-trust" class="level2">
<h2 class="anchored" data-anchor-id="case-study-disinformation-and-erosion-of-trust">Case Study: Disinformation and erosion of trust</h2>
<p>Another example of a collective societal harm comes from how technology platforms such as Facebook have played a significant role in elections ranging from the Philippines to Brazil, yet it can be difficult (and not necessarily possible or useful) to quantify exactly how much: something as complex as a country’s political system and participation involves many interlinking factors. But when ‘deep fakes’ make it <a href="https://heinonline.org/HOL/P?h=hein.journals/calr107&amp;i=1789">“possible to create audio and video of real people saying and doing things they never said or did”</a> or when motivated actors successfully <a href="https://policyreview.info/articles/analysis/disinformation-optimised-gaming-search-engine-algorithms-amplify-junk-news">game search engines to amplify disinformation</a>, the (potential) harm that is generated is societal, not just individual. Disinformation and the undermining of trust in institutions and fellow citizens have broad impacts, including on individuals who never use social media.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-05-17-societal-harms/disinfo-headlines.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Reports and Events on Regulatory Approaches to Disinformation</figcaption>
</figure>
</div>
<p>Efforts by national governments to deal with the problem through regulation have not gone down well with everyone. ‘Disinformation’ has repeatedly been highlighted as one of the tech-enabled ‘societal harms’ that the UK’s Online Safety Bill or the EU’s Digital Services Act should address, and a range of governments are taking aim at the problem by proposing or passing a slew of (in certain cases ill-advised) <a href="https://www.poynter.org/ifcn/anti-misinformation-actions/">‘anti-misinformation’ laws</a>. But there’s widespread unease around handing power to governments to set standards for what counts as ‘disinformation’. Does reifying ‘disinformation’ as a societal harm become a legitimizing tool for governments looking to silence political dissent or undermine their weaker opponents? It’s a fair and important concern - and yet simply leaving that power in the hands of mostly US-based, unaccountable tech companies is hardly a solution. What are the <a href="https://www.adalovelaceinstitute.org/event/national-approaches-online-harms-regulation/">legitimacy implications if a US company like Twitter were to ban</a> democratically elected Brazilian President Jair Bolsonaro for spreading disinformation, for example? How do we ensure that tech companies are investing sufficiently in <a href="https://law.yale.edu/isp/initiatives/wikimedia-initiative-intermediaries-and-information/wiii-blog/moderate-globally-impact-locally-series-content-moderation-global-south">governance efforts across the globe</a>, rather than responding in an ad hoc manner to proximal (i.e.&nbsp;mostly US-based) concerns about disinformation? Taking a hands off approach to platform regulation doesn’t make platforms’ efforts to deal with disinformation any less politically fraught.</p>
</section>
<section id="individual-harms-individual-solutions" class="level2">
<h2 class="anchored" data-anchor-id="individual-harms-individual-solutions">Individual Harms, Individual Solutions</h2>
<p>If we consider individual solutions our only option (in terms of policy, law, or behavior), we often limit the scope of the harms we can recognize or the nature of the problems we face. To take an example not related to AI: Oxford professor Trish Greenhalgh et al <a href="https://www.authorea.com/users/316109/articles/545687-how-covid-19-spreads-narratives-counter-narratives-and-social-dramas">analyzed the slow reluctance</a> of leaders in the West to accept that covid is airborne (e.g.&nbsp;it can linger and float in the air, similar to cigarette smoke, requiring masks and ventilation to address), rather than droplet dogma (e.g.&nbsp;washing your hands is a key precaution). One reason they highlight is the Western framing of individual responsibility as the solution to most problems. Hand-washing is a solution that fits the idea of individual responsibility, whereas collective responsibility for the quality of shared indoor air does not. The allowable set of solutions helps shape what we identify as a problem. Additionally, the fact that recent research suggests that “the level of interpersonal trust in a society” was a strong predictor of which countries managed COVID-19 most successfully should give us pause. Individualistic framings can limit our imagination about the problems we face and which solutions are likely to be most impactful.</p>
</section>
<section id="parallels-with-environmental-harms" class="level2">
<h2 class="anchored" data-anchor-id="parallels-with-environmental-harms">Parallels with Environmental Harms</h2>
<p>Before the passage of environmental laws, many existing legal frameworks were not well-suited to address environmental harms. Perhaps a chemical plant releases waste emissions into the air once per week. Many people in surrounding areas may not be aware that they are breathing polluted air, or may not be able to directly link air pollution to a new medical condition, such as asthma, (which could be related to a variety of environmental and genetic factors).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-05-17-societal-harms/air-pollution.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">There are parallels between air polllution and algorithmic harms</figcaption>
</figure>
</div>
<p>There are many parallels between environmental issues and AI ethics. Environmental harms include individual harms for people who develop discrete health issues from drinking contaminated water or breathing polluted air. Yet, environmental harms are also societal: the societal costs of contaminated water and polluted air can reverberate in subtle, surprising, and far-reaching ways. As law professor Nathalie Smuha writes, <a href="https://policyreview.info/articles/analysis/beyond-individual-governing-ais-societal-harm">environmental harms are often accumulative and build over time</a>. Perhaps each individual release of waste chemicals from a refinery has little impact on its own, but adds up to be significant. In the EU, environmental law allows for mechanisms to show societal harm, as it would be difficult to challenge many environmental harms on the basis of individual rights. Smuha argues that there are many similarities with AI ethics: for opaque AI systems, spanning over time, it can be difficult to prove a direct causal relationship to societal harm.</p>
</section>
<section id="directions-forward" class="level2">
<h2 class="anchored" data-anchor-id="directions-forward">Directions Forward</h2>
<p>To a large extent our message is to tech companies and policymakers. It’s not enough to focus on the potential individual harms generated by tech and AI: the broader societal costs of tech and AI matter.</p>
<p>But those of us outside tech policy circles have a crucial role to play. One way in which we can guard against the risks of the ‘societal harm’ discourse being co-opted by those with political power to legitimise undue interference and further entrench their power is by claiming the language of ‘societal harm’ as the democratic and democratising tool it can be. We all lose when we pretend societal harms don’t exist, or when we acknowledge they exist but throw our hands up. And those with the least power, like Bill Baine, are likely to suffer a disproportionate loss.</p>
<p>In his newsletter on Tech and Society, L.M. Sacasas encourages people to ask themselves <a href="https://theconvivialsociety.substack.com/p/the-questions-concerning-technology?">41 questions before using a particular technology</a>. They’re all worth reading and thinking about - but we’re listing a few especially relevant ones to get you started. Next time you sit down to log onto social media, order food online, swipe right on a dating app or consider buying a VR headset, ask yourself:</p>
<ul>
<li>How does this technology empower me? At whose expense? (Q16)</li>
<li>What feelings does the use of this technology generate in me toward others? (Q17)</li>
<li>What limits does my use of this technology impose upon others? (Q28)</li>
<li>What would the world be like if everyone used this technology exactly as I use it? (Q37)</li>
<li>Does my use of this technology make it easier to live as if I had no responsibilities toward my neighbor? (Q40)</li>
<li>Can I be held responsible for the actions which this technology empowers? Would I feel better if I couldn’t? (Q41)</li>
</ul>
<p>It’s on all of us to sensitise ourselves to the societal implications of the tech we use.</p>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>ethics</category>
  <category>machine learning</category>
  <guid>https://rachel.fast.ai/posts/2022-05-17-societal-harms/index.html</guid>
  <pubDate>Mon, 16 May 2022 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2022-05-17-societal-harms/air-pollution.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>There’s no such thing as not a math person</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2022-03-15-math-person/index.html</link>
  <description><![CDATA[ 




<p>On the surface, I may seem into math: I have a math PhD, taught a graduate <a href="https://www.fast.ai/2017/07/17/num-lin-alg/">computational linear algebra</a> course, co-founded AI research lab <a href="https://www.fast.ai/about/">fast.ai</a>, and even go by the twitter handle <a href="https://twitter.com/math_rachel"><span class="citation" data-cites="math_rachel">@math_rachel</span></a>.</p>
<p>Yet many of my experiences of academic math culture have been toxic, sexist, and deeply alienating. At my lowest points, I felt like there was <a href="https://www.youtube.com/watch?v=LqjP7O9SxOM&amp;list=PLtmWHNX-gukLQlMvtRJ19s7-8MrnRV6h6">no place for me</a> in math academia or math-heavy tech culture.</p>
<p>It is not just mathematicians or math majors who are impacted by this: Western culture is awash in negative feelings and experiences regarding math, which permate from many sources and impact students of all ages. In this post, I will explore the cultural factors, misconceptions, stereotypes, and relevant studies on obstacles that turn people off to math. If you (or your child) doesn’t like math or feels anxious about your own capabilities, you’re not alone, and this isn’t just a personal challenge. The below essay is based on part of <a href="https://www.youtube.com/watch?v=VmA8-vYwjM0&amp;list=PLtmWHNX-gukLQlMvtRJ19s7-8MrnRV6h6&amp;index=8">a talk</a> I recently gave.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-03-15-math-person/teaching.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">me, teaching sorting algorithms, at an all-women coding academy in 2015</figcaption>
</figure>
</div>
<section id="myth-of-innate-ability-myth-of-the-lone-genius" class="level2">
<h2 class="anchored" data-anchor-id="myth-of-innate-ability-myth-of-the-lone-genius">Myth of Innate Ability, Myth of the Lone Genius</h2>
<p>One common myth is the idea that certain people’s brains aren’t “wired” the right way to do math, tech, or AI, that your brain either “works that way” or not. None of the evidence supports this viewpoint, yet when people believe this, it can become a self-fulfilling prophecy. Dr.&nbsp;Omoju Miller, who earned her PhD at UC Berkeley and was a senior machine learning engineer and technical advisor to the CEO at Github, shares some of the research debunking the myth of innate ability in <a href="http://omojumiller.com/articles/The-Myth-Of-Innate-Ability-In-">this essay</a> and in <a href="https://www.youtube.com/watch?v=BFWVHSeakkg">her TEDx talk</a>. In reality, there is no such thing as “not a math person.”</p>
<p>Dr.&nbsp;Cathy O’Neil, a Harvard Math PhD and author of <a href="https://www.penguin.com.au/books/weapons-of-math-destruction-9780141985411">Weapons of Math Destruction</a>, wrote about the <a href="https://www.bloomberg.com/opinion/articles/2017-06-07/a-mathematician-s-secret-we-re-not-all-geniuses">myth of the lone genius mathematician</a>, <em>“You don’t have to be a genius to become a mathematician. If you find this statement at all surprising, you’re an example of what’s wrong with the way our society identifies, encourages and rewards talent… For each certified genius, there are at least a hundred great people who helped achieve such outstanding results.”</em></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-03-15-math-person/miller-oneil.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Dr.&nbsp;Miller debunking the myth of innate ability, and Dr.&nbsp;O’Neil debunking the myth of the lone genius mathematician</figcaption>
</figure>
</div>
</section>
<section id="music-without-singing-or-instruments" class="level2">
<h2 class="anchored" data-anchor-id="music-without-singing-or-instruments">Music without singing or instruments</h2>
<p>Imagine a world where children are not allowed to sing songs or play instruments until they reach adulthood, after spending a decade or two transcribing sheet music by hand. This scenario is absurd and nightmarish, yet it is analogous to how math is often taught, with the most creative and interesting parts saved until almost everyone has dropped out. Dr.&nbsp;Paul Lockhart eloquently describes this metaphor in his essay, <a href="https://www.maa.org/sites/default/files/pdf/devlin/LockhartsLament.pdf">A Mathematician’s Lament</a>, on <em>“how school cheats us out of our most fascinating and imaginative art form.”</em> Dr.&nbsp;Lockhart left his role as a university math professor to teach K-12 math, as he felt that so much reform was needed in how math is taught.</p>
<p>Dr.&nbsp;David Perkins uses the analogy of how children can play baseball wthout knowing all the technical details, without having a full team or playing a full 9 innings, yet still gain a sense of the <a href="https://books.google.com.au/books/about/Making_Learning_Whole.html?id=0DF9WxgGgNsC">“whole game.”</a> Math is usually taught with an overemphasis on dry, technical details, without giving students a concept of the “whole game.” It can take years and years before enough technical details are accumulated to build something interesting. There is an overemphasis on techniques rather than meaning.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-03-15-math-person/musicbaseball.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">What if math was taught more like how music or sports are taught?</figcaption>
</figure>
</div>
<p>Math curriculums are usually arranged in a vertical manner, with each year building tightly on the previous, such that one bad year can ruin everything that comes after. Many people I talk to can pinpoint the year that math went bad for them: <em>“I used to like math until 6th grade, when I had a bad teacher/was dealing with peer pressure/my undiagnosed ADHD was out of control. After that, I was never able to succeed in future years.”</em> This is less true in other subjects, where one bad history teacher/one bad year doesn’t mean that you can’t succeed at history the following year.</p>
</section>
<section id="gender-race-and-stereotypes" class="level2">
<h2 class="anchored" data-anchor-id="gender-race-and-stereotypes">Gender, race, and stereotypes</h2>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2836676/">Female teachers’ math anxiety affects girls’ math achievement</a>: In the USA, over 90% of primary school teachers are female, and research has found <em>“the more anxious teachers were about math, the more likely girls (but not boys) were to endorse the commonly held stereotype that ‘boys are good at math, and girls are good at reading’ and the lower these girls’ math achievement… People’s fear and anxiety about doing math—over and above actual math ability—can be an impediment to their math achievement.”</em></p>
<p><a href="https://www.nytimes.com/2015/04/27/opinion/how-to-attract-female-engineers.html">Research</a> across a number of universities has found that more women go into engineering when courses focus on problems with positive social impact.</p>
<p>Structural racism also impacts what messages teachers impart to students. An Atlantic article <a href="https://www.theatlantic.com/education/archive/2017/04/racist-math-education/524199/">How Does Race Affect a Student’s Math Education?</a> covered the research paper <a href="https://journals.tdl.org/jume/index.php/JUME/article/view/294">A Framework for Understanding Whiteness in Mathematics Education</a>, noting that <em>“Constantly reading and hearing about underperforming Black, Latino, and Indigenous students begins to embed itself into how math teachers view these students, attributing achievement differences to their innate ability to succeed in math… teachers start to expect worse performance from certain students, start to teach lower content, and start to use lower-level math instructional practices. By contrast, white and Asian students are given the benefit of the doubt and automatically afforded the opportunity to do more sophisticated and substantive mathematics.”</em></p>
</section>
<section id="the-mathematics-community-is-an-absolute-mess-which-actively-pushes-out-the-sort-of-people-who-might-make-it-better" class="level2">
<h2 class="anchored" data-anchor-id="the-mathematics-community-is-an-absolute-mess-which-actively-pushes-out-the-sort-of-people-who-might-make-it-better">The mathematics community is “an absolute mess which actively pushes out the sort of people who might make it better”</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2022-03-15-math-person/piperharron.jpg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Dr.&nbsp;Harron’s website, and some of the coverage of her number theory thesis, including on the Scientific American blog</figcaption>
</figure>
</div>
<p>Dr.&nbsp;Piper Harron made waves with her <a href="http://www.theliberatedmathematician.com/thesis/">Princeton PhD thesis</a>, utilizing humor, analogies, sarcasm, and genuine efforts to be accessible as she described advanced concepts in a ground-breaking way, very atypical for a mathematics PhD thesis. Dr.&nbsp;Harron wrote openly in the prologue of her thesis on how alienating the culture of mathematics is, <em>“As any good grad student would do, I tried to fit in, mathematically. I absorbed the atmosphere and took attitudes to heart. I was miserable, and on the verge of failure. The problem was not individuals, but a system of self-preservation that, from the outside, feels like a long string of betrayals, some big, some small, perpetrated by your only support system.”</em> At her blog, the Liberated Mathematician, <a href="http://www.theliberatedmathematician.com/">she writes</a>, <em>“My view of mathematics is that it is an absolute mess which actively pushes out the sort of people who might make it better.”</em></p>
<p>These descriptions resonate with my own experiences obtaining a math PhD (as well as the experiences of many friends, at a variety of universities). The toxicity of academic math departments is self-perpetuating, pushing out the people who could make them better.</p>
</section>
<section id="the-full-talk" class="level2">
<h2 class="anchored" data-anchor-id="the-full-talk">The full talk</h2>
<p>This post is based on the first part of the talk I gave in the below video, which includes more detail and a Q&amp;A. The talk also includes recommendations about math apps and resources, as well as a framework for how to consider screentime. Stay tuned for a future fast.ai blog post covering math apps and screentime.</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/VmA8-vYwjM0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</center>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>advice</category>
  <category>education</category>
  <guid>https://rachel.fast.ai/posts/2022-03-15-math-person/index.html</guid>
  <pubDate>Mon, 14 Mar 2022 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2022-03-15-math-person/teaching.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Avoiding Data Disasters</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2021-11-04-data-disasters/index.html</link>
  <description><![CDATA[ 




<p>Things can go disastrously wrong in data science and machine learning projects when we undervalue data work, use data in contexts that it wasn’t gathered for, or ignore the crucial role that humans play in the data science pipeline. A new multi-university <a href="https://cires.org.au/">centre focused on Information Resilience</a>, funded by the Australian government’s top scientific funding body (ARC), has recently launched. <strong>Information Resilience</strong> is the capacity to detect and respond to failures and risks across the information chain in which data is sourced, shared, transformed, analysed, and consumed. I’m honored to be a member of the strategy board, and I have been thinking about what information resilience means with respect to data practices. Through a series of case studies and relevant research papers, I will highlight these risks and point towards more resilient practices.</p>
<section id="case-study-uk-covid-tracking-app" class="level2">
<h2 class="anchored" data-anchor-id="case-study-uk-covid-tracking-app">Case study: UK covid tracking app</h2>
<p>Data from a covid-symptom tracking app was used in a research paper to draw <a href="https://twitter.com/ahandvanish/status/1313973286364229638?s=20">wildly inaccurate conclusions</a> about the prevalence of Long Covid, the often debilitating neurological, vascular, and immune disease that can last for months or longer (some patients have been sick for 20 months and counting). The app suggested that only 1.5% of patients still experience symptoms after 3 months, an order of magnitude smaller than estimates of 10-35% being found by other studies.</p>
<p>How could this research project have gone so wrong? Well, the app had been designed for a completely different purpose (tracking 1-2 week long respiratory infections), didn’t include the most common Long Covid symptoms (such as neurological dysfunction), had a frustrating user-interface that led many patients to quit using it, and made the erroneous assumption that those who stopped logging must be fully recovered. The results from this faulty research paper were widely shared, including in a BBC article, offering false reassurance than Long Covid prevalence is much rarer than it is. Patients had been voicing their frustrations with the app all along, and if researchers had listened sooner, they could have collected a much higher quality and more accurate data set.</p>
<p>This research failure illustrates a few common issues in data projects:</p>
<ul>
<li>The <strong>context of the data</strong> was not taken into account. The user-interface, the categories listed, the included features– these were all designed to record data about a short-term mild respiratory infection. However, when it was used for a different purpose (long covid patients suffering for months with vascular and neurological symptoms), it did a poor job, and led to missing and incomplete data. This happens all too often, in which data gathered for one context is used for another</li>
<li>The <strong>people most impacted</strong> (long covid patients) were ignored. They had the most accurate expertise on what long covid actually entailed, yet were not listened to. Ignoring this expertise led to lower quality data and erroneous research conclusions. Patients have <a href="https://bostonreview.net/science-nature/rachel-thomas-medicines-machine-learning-problem">crucial domain expertise</a>, which is distinct from that of doctors, and must be included in medical data science projects. From the start of the pandemic, patients who had suffered from other debilitating post-viral illnesses warned that we should be on the lookout for long-term illness, even in initially “mild” cases.</li>
</ul>
</section>
<section id="data-is-crucial" class="level2">
<h2 class="anchored" data-anchor-id="data-is-crucial">Data is Crucial</h2>
<p>Collecting data about covid and its long-term effects directly from patients was a good idea, but poorly executed in this case. Due to <a href="https://www.fast.ai/2019/08/07/surveillance/">privacy and surveillance risks</a>, I frequently remind people not to record data that they don’t need. However, the pandemic has been a good reminder of how much data we really do need, and how tough it is when it’s missing.</p>
<p>At the start of the pandemic in the United States, we had very little data about what was happening– the government was not tabulating information on cases, testing, or hospitalization. How could we know how to react when we didn’t understand how many cases there were, what death rates were, how transmissible the disease was, and other crucial information? How could we make policy decisions in the absence of a basic understanding of the facts.</p>
<p>In early March 2020, two journalists and a data scientist from a medication-discovery platform began <a href="https://www.cjr.org/the_profile/covid-tracking-project.php">pulling covid data together</a> into a spreadsheet to understand the situation in the USA. This launched into a <a href="https://covidtracking.com/analysis-updates/why-we-didnt-automate-our-data-collection">15-month long project in which 500 volunteers</a> compiled and published data on COVID-19 testing, cases, hospitalizations, and deaths in the USA. During those 15 months, the Covid Tracking Project was the most comprehensive source of covid data in the USA, even more comprehensive than what the CDC had, and it was used by the CDC, numerous government agencies, and both the Trump and Biden Administrations. It was cited in academic studies and in thousands of news articles.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2021-11-04-data-disasters/covid-track.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">A reflection on the covid tracking project from a core data infrastructure engineer</figcaption>
</figure>
</div>
<p>A data infrastructure engineer and contributor for the project <a href="https://covidtracking.com/analysis-updates/why-we-didnt-automate-our-data-collection">later recounted</a>, “It quickly became apparent that daily, close contact with the data was necessary to understand what states were reporting. States frequently changed how, what, and where they reported data. Had we set up a fully automated data capture system in March 2020, it would have failed within days.” The project used automation as a way to support and supplement manual work, not to replace it. At numerous points, errors in state reporting mechanisms were caught by eagle-eyed data scientists notifying discrepancies.</p>
<p>This vision of using automation to support human work resonates with our interest at fast.ai in “augmentedML”, not “autoML”. I have <a href="https://www.fast.ai/2018/07/16/auto-ml2/">written previously</a> and <a href="https://slideslive.com/38917533/lessons-learned-from-helping-200000-nonml-experts-use-ml">gave an AutoML workshop keynote</a> on how too often automation ignores the important role of human input. Rather than try to automate everything (which often fails), we should focus on how humans and machines can best work together to take advantage of their different strengths.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2021-11-04-data-disasters/augmentedML.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Speaking about AugmentedML vs.&nbsp;AutoML at ICML 2019</figcaption>
</figure>
</div>
</section>
<section id="data-work-is-undervalued" class="level2">
<h2 class="anchored" data-anchor-id="data-work-is-undervalued">Data Work is Undervalued</h2>
<p>Interviews of 53 AI practitioners across 6 countries on 3 continents found a pattern that is very familiar to many of us (including me) who work in machine learning: <a href="https://research.google/pubs/pub49953/">“Everyone wants to do the model work, not the data work.”</a> Missing meta-data leads to faulty assumptions. Data collection practices often conflict with the workflows of on-the-ground partners, such as nurses or farmers, who are usually not compensated for this extraneous effort. Too often data work is arduous, invisible, and taken for granted. Undervaluing of data work leads to poor practices and often results in negative, downstream events, including dangerously inaccurate models and months of lost work.</p>
<p>Throughout the pandemic, data about covid (both initial cases and long covid) has often been lacking. Many countries have experienced testing shortages, leading to undercounts of how many people have covid. The <a href="https://www.propublica.org/article/the-cdc-only-tracks-a-fraction-of-breakthrough-covid-19-infections-even-as-cases-surge">CDC decision not to track breakthrough cases</a> unless they resulted in hospitalization made it harder to understand prevalence of break-throughs (a particularly concerning decision since break-throughs can still lead to long covid). In September, it was revealed that British Columbia, Canada was <a href="https://bc.ctvnews.ca/secrecy-over-b-c-s-true-number-of-hospitalized-covid-19-patients-1.5595394">not including covid patients in their ICU counts</a> once the patients were no longer infectious, a secretive decision that obscured how full ICUs were. Some studies of Long Covid have failed to include common symptoms, such as neurological ones, making it harder to understand the prevalence or nature.</p>
</section>
<section id="data-has-context" class="level2">
<h2 class="anchored" data-anchor-id="data-has-context">Data has Context</h2>
<p>Covid is giving us a first-hand view of how data, which we may sometimes want to think of as “objective”, are shaped by countless human decisions and factors. In the example of the symptom tracking app, decisions about which symptoms were included had a significant impact on the prevalence rate calculated. Design decisions that influenced the ease of use impacted how much data was gathered. Lack of understanding of how the app was being used (and why people quit using it) led to erroneous decisions about which cases should be considered “recovered”. These are all examples of the context for data. Here, the data gathered was reasonably appropriate for understanding initial covid infections (a week or two of respiratory symptoms), but not for patients experiencing months of neurological and vascular symptoms. Numbers can not stand alone, we need to understand how they were measured, who was included and excluded, relevant design decisions, under what situations a dataset is appropriate to use vs.&nbsp;not.</p>
<p>As another example, consider covid testing counts: Who has access to testing (this involves health inequities, due to race or urban vs.&nbsp;rural), who is encouraged to get tested (at various times, people without symptoms, children, or other groups have been discouraged from doing so), varying accuracies (e.g.&nbsp;PCR tests are less accurate on children, missing almost half of cases that later go on to seroconvert), and making decisions about what counts as a “case” (I know multiple people who had alternating test results: positive, negative, positive, or the reverse– what counts as a positive case?)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2021-11-04-data-disasters/datasheet.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Datasheet for an electrical component. Image from ‘Datasheets for Datasets’</figcaption>
</figure>
</div>
<p>One proposal for capturing this context is <a href="https://arxiv.org/abs/1803.09010">Datasheets for Datasets</a>. Prior to doing her PhD at Stanford in computer vision and then co-leading Google’s AI ethics team, <a href="https://thegradient.pub/the-far-reaching-impacts-of-timnit-gebru/">Dr.&nbsp;Timnit Gebru</a> worked at Apple in circuit design and electrical engineering. In electronics, each component (such as a circuit or transistor) comes with a datasheet that lists when and where it was manufactured, under what conditions it is safe to use, and other specifications. Dr.&nbsp;Gebru drew on this background to propose a similar idea for datasets: listing the context of when and how it was created, what data was included/excluded, recommended uses, potential biases and ethical risks, work needed to maintain it, and so on. This is a valuable proposal towards making the context of data more explicit.</p>
</section>
<section id="the-people-most-impacted" class="level2">
<h2 class="anchored" data-anchor-id="the-people-most-impacted">The People Most Impacted</h2>
<p>The inaccurate research and incomplete data from the covid tracking app could have been avoided by drawing on the expertise of patients. Higher quality data could have been collected sooner and more thoroughly, if patients were consulted in the app design and in the related research studies. Participatory approaches to machine learning is an exciting and growing area of research. In any domain, the people who would be most impacted by errors or mistakes need to be included as partners in the design of the project.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2021-11-04-data-disasters/diverse-voices.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">The Diverse Voices project from University of Washington Tech Policy Lab involves academic papers and practical how-to guides.</figcaption>
</figure>
</div>
<p>Often, our approaches to addressing fairness or other ethics issues, further centralize the power of system designers and operators. The organizers of an ICML workshop on the topic called <a href="https://participatoryml.github.io/">for more cooperative, democratic, and participatory</a> approaches instead. We need to think not just about <strong>explainability</strong>, but about giving people <strong>actionable recourse</strong>. As <a href="https://slideslive.com/38930604/actionable-recourse-in-machine-learning">Professor Berk Ustun highlights</a>, when someone asks why their loan was denied, usually what they want is not just an explanation but to know what they could change in order to get a loan. We need to design systems with <a href="http://contestability.org/"><strong>contestability</strong></a> in mind, to include from the start the idea that people should be able to challenge system outputs. We need to include <a href="https://techpolicylab.uw.edu/project/diverse-voices/">expert panels of perspectives</a> that are often overlooked, depending on the application, this could mean formerly or currently incarcerated people, people who don’t drive, people with very low incomes, disabled people, and many others. <a href="https://techpolicylab.uw.edu/project/diverse-voices/">The Diverse Voices project</a> from University of Washington Tech Lab provides guidance on how to do this. And it is crucial that this not just be tokenistic <a href="https://www.technologyreview.com/2020/08/25/1007589/participation-washing-ai-trends-opinion-machine-learning/">participation-washing</a>, but a meaningful, appropriately compensated, and ongoing role in their design and operation.</p>
</section>
<section id="towards-greater-data-resilience" class="level2">
<h2 class="anchored" data-anchor-id="towards-greater-data-resilience">Towards Greater Data Resilience</h2>
<p>I hope that we can improve data resilience through: - Valuing data work - Documenting context of data - Close contact with the data - Meaningful, ongoing, and compensated involvement of the people impacted</p>
<p>And I hope that when our data represents people we can remember the human side. As <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7296309/">AI researcher Inioluwa Deborah Raji wrote</a>, “Data are not bricks to be stacked, oil to be drilled, gold to be mined, opportunities to be harvested. Data are humans to be seen, maybe loved, hopefully taken care of.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2021-11-04-data-disasters/data-not-oil.jpg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Quote from AI researcher Inioluwa Deborah Raji</figcaption>
</figure>
</div>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>ethics</category>
  <category>machine learning</category>
  <guid>https://rachel.fast.ai/posts/2021-11-04-data-disasters/index.html</guid>
  <pubDate>Wed, 03 Nov 2021 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2021-11-04-data-disasters/covid-track.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Medicine is Political</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2021-10-12-medicine-political/index.html</link>
  <description><![CDATA[ 




<p>Experts warn that we are not prepared for the <a href="https://www.scientificamerican.com/article/a-tsunami-of-disability-is-coming-as-a-result-of-lsquo-long-covid-rsquo/">surge in disability</a> due to long covid, an illness that afflicts between <a href="https://health.ucdavis.edu/health-news/newsroom/studies-show-long-haul-covid-19-afflicts-1-in-4-covid-19-patients-regardless-of-severity/2021/03">one-fourth and one-third</a> of people who get covid, including mild cases, for months afterwards (<i>2023 update: This post was originally published in 2021, pre-Omicron. I believe that an updated estimate of long covid in 2023 is likely 4-10% of cases, which still leads to a significant impact on healthcare systems and labor participation, as well as much individual suffering.</i>). Some early covid cases have been sick for 18 months, with no end in sight. The physiological damage that covid causes can include <a href="https://onlinelibrary.wiley.com/doi/10.1002/acn3.51350">cognitive dysfunction</a> and <a href="https://www.thelancet.com/journals/eclinm/article/PIIS2589-5370(21)00324-2/fulltext">deficits</a>, <a href="https://www.npr.org/sections/health-shots/2021/07/26/1019875347/doctors-worry-that-memory-problems-after-covid-19-may-set-stage-for-alzheimers">brain activity scans similar to those seen in Alzheimer’s patients</a>, <a href="https://gut.bmj.com/content/70/4/698">GI immune system damage</a>, <a href="https://bjo.bmj.com/content/early/2021/07/08/bjophthalmol-2021-319450">cornea damage</a>, <a href="https://www.medrxiv.org/content/10.1101/2021.06.01.21257759v1">immune dysfunction</a>, <a href="https://jasn.asnjournals.org/content/early/2021/08/25/ASN.2021060734">increased risk of kidney outcomes</a>, <a href="https://www.medrxiv.org/content/10.1101/2021.08.08.21261763v1">dysfunction in T cell memory generation</a>, <a href="https://www.theguardian.com/society/2021/sep/29/covid-can-infect-cells-in-pancreas-that-make-insulin-research-shows">pancreas damage</a>, and <a href="https://pesquisa.bvsalud.org/global-literature-on-novel-coronavirus-2019-ncov/resource/en/covidwho-1265299">ovarian failure</a>. Children are at risk too.</p>
<p>As the evidence continues to mount of alarming long term physiological impacts of covid, and tens of millions are unable to return to work, we might expect leaders to take covid more seriously. Yet we are seeing concerted efforts to downplay the long-term health effects of covid using strategies straight out of the <a href="https://www.sciencedirect.com/science/article/pii/S2352154621000474?via%3Dihub">climate denial playbook</a>, such as <a href="https://blogs.bmj.com/bmj/2021/09/13/covid-19-and-the-new-merchants-of-doubt/">funding contrarian scientists</a>, <a href="https://www.theguardian.com/world/2020/oct/09/herd-immunity-letter-signed-fake-experts-dr-johnny-bananas-covid">misleading petitions</a>, <a href="https://fas.org/blogs/fas/2020/10/social-media-conversations-in-support-of-herd-immunity-are-driven-by-bots/">social media bots</a>, and disingenuous debate tactics that make the science seem murkier than it is. In many cases, these <a href="https://blogs.bmj.com/bmj/2021/09/13/covid-19-and-the-new-merchants-of-doubt/">minimization efforts are being funded</a> by the <a href="https://www.opendemocracy.net/en/dark-money-investigations/tory-billionaire-bankrolled-herd-immunity-scientist-who-advised-pm-against-lockdown/">same billionaires</a> and institutions that fund climate change denialism. Dealing with many millions of newly disabled people will be very expensive for governments, social service programs, private insurance companies, and others. Thus, many have a significant financial interest in distorting the science around long term effects of covid to minimize the perceived impact.</p>
<p>In topics ranging from covid-19 to HIV research to the long history of wrongly assuming women’s illnesses are psychosomatic, we have seen again and again that medicine, like all science, is political. This shows up in myriad ways, such as: who provides funding, who receives that funding, which questions get asked, how questions are framed, what data is recorded, what data is left out, what categories included, and whose suffering is counted.</p>
<p>Scientists often like to think of their work as perfectly objective, perfectly rational, free from any bias or influence. Yet by failing to acknowledge the reality that there is no “view from nowhere”, they miss their own blindspots and make themselves vulnerable to bad-faith attacks. As one <a href="https://twitter.com/KHayhoe/status/1442207481330114567?s=20">climate scientist recounted</a> of the last 3 decades, “We spent a long time thinking we were engaged in an argument about data and reason, but now we realize it’s a fight over money and power… They [climate change deniers] focused their lasers on the science and like cats we followed their pointer and their lead.”</p>
<p>The American Institute for Economic Research (AIER), a libertarian think tank funded by right wing billionaire Charles Koch which invests in fossil fuels, energy utilities, and tobacco, is best known for its research denying the climate crisis. In October 2020, a document called the <a href="https://theconversation.com/5-failings-of-the-great-barrington-declarations-dangerous-plan-for-covid-19-natural-herd-immunity-148975">Great Barrington Declaration (GBD)</a> was developed at a private AIER retreat, calling for a “herd immunity” approach to covid, arguing against lockdowns, and suggesting that young, healthy people have little to worry about. The three scientists who authored the GBD have prestigious pedigrees and are politically well-connected, speaking to White House Officials and having found favor in the British government. One of them, Sunetra Gupta of Oxford, had released a wildly inaccurate <a href="https://www.medrxiv.org/content/10.1101/2020.03.24.20042291v1.full-text">paper in March 2020</a> claiming that <a href="https://www.medscape.com/viewarticle/927504">up to 68% of the UK population</a> had been exposed to covid, and that there were already significant levels of herd immunity to coronavirus in both the UK and Italy (again, this was in March 2020). Gupta received funding from <a href="https://www.opendemocracy.net/en/dark-money-investigations/tory-billionaire-bankrolled-herd-immunity-scientist-who-advised-pm-against-lockdown/">billionaire conservative donors</a>, Georg and Emily von Opel. Another one of the authors, Jay Bhattacharya of Stanford, co-authored a <a href="https://www.buzzfeednews.com/article/stephaniemlee/coronavirus-antibody-test-santa-clara-los-angeles-stanford">widely criticized pre-print</a> in April 2020 that relied on a biased sampling method to “show” that 85 times more people in Santa Clara County California had already had covid compared to other estimates, and thus suggested that the fatality rate for covid was much lower than it truly is.</p>
<p><a href="https://fas.org/blogs/fas/2020/10/social-media-conversations-in-support-of-herd-immunity-are-driven-by-bots/">Half of the social media</a> accounts advocating for herd immunity seem to be bots, characterized as engaging in abnormally high levels of retweets &amp; low content diversity. <a href="https://blogs.bmj.com/bmj/2021/09/13/covid-19-and-the-new-merchants-of-doubt/">An article in the BMJ</a> recently advised that it is “critical for physicians, scientists, and public health officials to realize that they are not dealing with an orthodox scientific debate, but a well-funded sophisticated science denialist campaign based on ideological and corporate interests.”</p>
<p>This myth of perfect scientific objectivity positions modern medicine as completely distinct from a history where women were diagnosed with “hysteria” (roaming uterus) for a variety of symptoms, where Black men were denied syphilis treatment for decades as part of a “scientific study”, and <a href="https://www.theguardian.com/books/2020/sep/10/guardian-australias-book-club-why-does-medicine-care-so-little-about-womens-bodies">multiple sclerosis was</a> “called hysterical paralysis right up to the day they invented a CAT scan machine” and demyelination could be seen on brain scans.</p>
<p>However, there is not some sort of clean break where bias was eliminated and all unknowns were solved. Black patients, <a href="https://pubmed.ncbi.nlm.nih.gov/26366984/">including children</a>, still receive <a href="https://www.scientificamerican.com/article/how-doctors-can-confront-racial-bias-in-medicine/">less pain medication</a> than white patients for the same symptoms. Women are still more likely to have their physical symptoms dismissed as psychogenic. Nearly half of women with autoimmune disorders report being <a href="https://psmag.com/social-justice/is-medicines-gender-bias-killing-young-women">labeled as “chronic complainers”</a> by their doctors in the 5 years (on average) they spend seeking a diagnosis. All this impacts what data is recorded in their charts, what symptoms are counted.</p>
<p>Medical data are not objective truths. Like all data, the context is critical. <a href="https://bostonreview.net/science-nature/rachel-thomas-medicines-machine-learning-problem">It can be missing, biased, and incorrect</a>. It is filtered through the opinions of doctors. Even blood tests and imaging scans are filtered through the decisions of what tests to order, what types of scans to take, what accepted guidelines recommend, what technology currently exists. And the technology that exists depends on research and funding decisions stretching back decades, influenced by politics and cultural context.</p>
<p>One may hope that in 10 years we will have clearer diagnostic tests for some illnesses which remain contested now, just as the ability to identify multiple sclerosis improved with better imaging. In the meantime, we should listen to patients and trust in their ability to explain their own experiences, even if science can’t fully understand them yet.</p>
<p>Science does not just progress inevitably, independent of funding and politics and framing and biases. A self-fulfilling prophecy often occurs in which doctors:</p>
<ol type="1">
<li>label a new, poorly understood, multi-system disease as psychogenic,</li>
<li>use this as justification to not invest much funding into researching physiological origins,</li>
<li>and then point to the lack of evidence as a reason why the illness must be psychogenic.</li>
</ol>
<p>This is largely the experience of ME/CFS patients over the last several decades. Myalgic encephalomyelitis (ME/CFS), involves dysfunction of the immune system, autonomic systems, and energy metabolism (including <a href="https://pubmed.ncbi.nlm.nih.gov/32041178/">mitochondrial dysfunction</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/31277442/">hypoacetylation</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/30557887/">reduced oxygen uptake</a>, and <a href="https://portlandpress.com/clinsci/article-abstract/97/5/603/77282/Impaired-oxygen-delivery-to-muscle-in-chronic?redirectedFrom=fulltext">impaired oxygen delivery</a>). ME/CFS is <a href="https://content.iospress.com/articles/work/wor203173#ref019">more debilitating</a> than many chronic diseases, including chronic renal failure, lung cancer, stroke, and type-2 diabetes. It is estimated 25–29% of patients are homebound or bedbound. ME/CFS is often triggered by viral infections, so it is not surprising that we are seeing some <a href="https://www.frontiersin.org/articles/10.3389/fmicb.2021.698169/full">overlap between ME/CFS and long covid</a>. ME/CFS disproportionately impacts women, and a <a href="https://www.mdpi.com/1648-9144/57/10/1012/htm">now discredited 1970 paper</a> identified a major outbreak in 1958 amongst nurses at a British hospital as “epidemic hysteria”. This early narrative of ME/CFS as psychogenic has been difficult to shake. Even as evidence continues to accumulate of immune, metabolic, and autonomous system dysfunction, some doctors persist in believing that ME/CFS must be psychogenic. It has remained <a href="https://content.iospress.com/articles/work/wor203173#ref019">woefully underfunded</a>: from 2013-2017, NIH funding was only at 7.3% relative commensurate to its disease burden. Note that the <a href="https://content.iospress.com/articles/work/wor203173#ref019">below graph</a> is on a log scale: ME/CFS is at 7%, Depression and asthma are at 100% and diseases like cancer and HIV are closer to 1000%.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2021-10-12-medicine-political/mecfsfunding.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Graph of NIH funding on log scale, from above paper by Mirin, Dimmock, Leonard</figcaption>
</figure>
</div>
<p>Portraying patients as unscientific and irrational is the other side of the same coin for the myth that medicine is perfectly rational. Patients that disagree with having symptoms they know are physiological dismissed as psychogenic, that reject treatments from flawed studies, or who distrust medical institutions based on their experiences of racism, sexism, and mis-diagnosis, are labeled as “militant” or “irrational”, and placed in the same category with conspiracy theorists and those peddling disinformation.</p>
<p>On an individual level, receiving a psychological misdiagnosis lengthens the time it will take to get the right diagnosis, since many doctors will stop looking for physiological explanations. A study of 12,000 rare disease patients <a href="https://www.bbc.com/future/article/20180523-how-gender-bias-affects-your-healthcare">covered by the BBC</a> found that “while being misdiagnosed with the wrong physical disease doubled the time it took to get to the right diagnosis, getting a psychological misdiagnosis extended it even more – by 2.5 up to 14 times, depending on the disease.” This dynamic holds true at the disease level as well: once a disease is mis-labeled as psychogenic, many doctors will stop looking for physiological origins.</p>
<p>We are seeing increasing efforts to dismiss long covid as psychogenic in high profile platforms such as the WSJ and New Yorker. The <a href="https://www.fast.ai/2021/09/25/new-yorker/">New Yorker’s first feature article</a> on long covid, published last month, neglected to interview any clinicians who treat long covid patients nor to cite the abundant research on how covid causes damage to many organ systems, yet interviewed several doctors in unrelated fields who claim long covid is psychogenic. In response to a patient’s assertion that covid impacts the brain, the author spent an entire paragraph detailing how there is currently no evidence that covid crosses the blood-brain barrier, but didn’t mention the research on covid patients finding <a href="https://onlinelibrary.wiley.com/doi/10.1002/acn3.51350">cognitive dysfunction</a> and <a href="https://www.thelancet.com/journals/eclinm/article/PIIS2589-5370(21)00324-2/fulltext">deficits</a>, <a href="https://www.npr.org/sections/health-shots/2021/07/26/1019875347/doctors-worry-that-memory-problems-after-covid-19-may-set-stage-for-alzheimers">PET scans similar to those seen in Alzheimer’s patients</a>, <a href="https://link.springer.com/article/10.1007/s00259-021-05215-4">neurological damage</a>, and <a href="https://www.medrxiv.org/content/10.1101/2021.06.11.21258690v1">shrinking grey matter</a>. This leaves a general audience with the mistaken impression that it is unproven whether covid impacts the brain, and is a familiar tactic from bad-faith science debates.</p>
<p>The New Yorker article set up a strict dichotomy between long covid patients and doctors, suggesting that patients harbor a “disregard for expertise”; are less “concerned about what is and isn’t supported by evidence”; and are overly “impatient.” In contrast, doctors appreciate the “careful study design, methodical data analysis, and the skeptical interpretation of results” that medicine requires. Of course, this is a false dichotomy: many patients are more knowledgeable about the latest research than their doctors, some <a href="https://www.thelancet.com/journals/eclinm/article/PIIS2589-5370(21)00299-6/fulltext">patients are publishing in peer-reviewed journals</a>, and there are many <a href="https://www.nature.com/articles/s43856-021-00016-0">medical doctors that are also patients</a>. And on the other hand, doctors are just as prone as the rest of us to biases, blind spots, and institutional errors.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2021-10-12-medicine-political/actup.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">AP Photo/J. Scott Applewhit</figcaption>
</figure>
</div>
<p>In 1987, <a href="https://www.npr.org/sections/health-shots/2019/02/09/689924838/how-to-demand-a-medical-breakthrough-lessons-from-the-aids-fight">40,000 Americans had already died of AIDS</a>, yet the government and pharmaceutical companies were doing little to address this health crisis. AIDS was heavily stigmatized, federal spending was minimal, and pharmaceutical companies lacked urgency. The activists of ACT UP used a two pronged approach: creative and confrontational acts of protest, and informed scientific proposals. When the FDA refused to even discuss giving AIDS patients access to experimental drugs, ACT UP protested at their headquarters, blocking entrances and lying down in front of the building with tombstones saying “Killed by the FDA”. This opened up discussions, and <a href="https://www.npr.org/sections/health-shots/2019/02/09/689924838/how-to-demand-a-medical-breakthrough-lessons-from-the-aids-fight">ACT UP offered viable scientific proposals</a>, such as switching from the current approach of conducting drug trials on a small group of people over a long time, and instead testing a large group of people over a short time, radically speeding up the pace at which progress occurred. ACT UP used similar tactics to protest the NIH and pharmaceutical companies, demanding research on how to treat the opportunistic infections that killed AIDS patients, not solely research for a cure. The huge progress that has happened in HIV/AIDS research and treatment would not have happened without the efforts of ACT UP.</p>
<p>Across the world, we are at a pivotal time in determining how societies and governments will deal with the masses of newly disabled people due to long covid. Narratives that take hold early often have disproportionate staying power. Will we inaccurately label long covid as psychogenic, primarily invest in psychiatric research that can’t address the well-documented physiological damage caused by covid, and financially abandon the patients who are now unable to work? Or will we take the chance to transform medicine to better recognize the lived experiences and knowledge of patients, to center patient partnerships in biomedical research for complex and multi-system diseases, and strengthen inadequate disability support and services to improve life for all people with disabilities? The decisions we collectively make now on these questions will have reverberations for decades to come.</p>



<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>ethics</category>
  <category>science</category>
  <guid>https://rachel.fast.ai/posts/2021-10-12-medicine-political/index.html</guid>
  <pubDate>Mon, 11 Oct 2021 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2021-10-12-medicine-political/actup-square.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>11 Short Videos About AI Ethics</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2021-08-17-eleven-ethics-videos/index.html</link>
  <description><![CDATA[ 




<p>I made a playlist of 11 short videos (most are 6-13 mins long) on Ethics in Machine Learning. This is from my <a href="https://course.fast.ai/videos/?lesson=5">ethics lecture</a> in <a href="https://course.fast.ai/">Practical Deep Learning for Coders v4</a>. I thought these short videos would be easier to watch, share, or skip around.</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/F0cxzESR7ec" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</center>
<p><a href="https://www.youtube.com/watch?v=F0cxzESR7ec&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR"><strong>What are Ethics and Why do they Matter? Machine Learning Edition</strong></a>: Through 3 key case studies, I cover how people can be harmed by machine learning gone wrong, why we as machine learning practitioners should care, and what tech ethics are.</p>
<p><a href="https://www.youtube.com/watch?v=j3nqdZoQjy0&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR&amp;index=2"><strong>All machine learning systems need ways to identify &amp; address mistakes</strong></a>. It is crucial that all machine learning systems are implemented with ways to correctly surface and correct mistakes, and to provide recourse to those harmed.</p>
<p><a href="https://www.youtube.com/watch?v=bqCEUQq0z4o&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR&amp;index=3"><strong>The Problem with Metrics, Feedback Loops, and Hypergrowth</strong></a>: Overreliance on metrics is a core problem both in the field of machine learning and in the tech industry more broadly. As Goodhart’s Law tells us, when a measure becomes the target, it ceases to be a good measure, yet the incentives of venture capital push companies in this direction. We see out-of-control feedback loops, widespread gaming of metrics, and people being harmed as a result.</p>
<p><a href="https://www.youtube.com/watch?v=pbnqvS2yjNg&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR&amp;index=4"><strong>Not all types of bias are fixed by diversifying your dataset</strong></a>. The idea of bias is often too general to be useful. There are several different types of bias, and different types require different interventions to try to address them. Through a series of cases studies, we will go deeper into some of the various causes of bias.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2021-08-17-eleven-ethics-videos/short-ethics-playlist.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Part of the Ethics Videos Playlist</figcaption>
</figure>
</div>
<p><a href="https://www.youtube.com/watch?v=igVrrfDznOo&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR&amp;index=5"><strong>Humans are biased too, so why does machine learning bias matter?</strong></a> A common objection to concerns about bias in machine learning models is to point out that humans are really biased too. This is correct, yet machine learning bias differs from human bias in several key ways that we need to understand and which can heighten the impact.</p>
<p><a href="https://www.youtube.com/watch?v=zoAsnJAsLo8&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR&amp;index=6"><strong>7 Questions to Ask About Your Machine Learning Project</strong></a></p>
<p><a href="https://www.youtube.com/watch?v=PaowVrW3TZg&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR&amp;index=7"><strong>What You Need to Know about Disinformation</strong></a>: With a particular focus on how machine learning advances can contribute to disinformation, this covers some of the fundamental things to understand.</p>
<p><a href="https://www.youtube.com/watch?v=2A6js_EJ6MA&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR&amp;index=8"><strong>Foundations of Ethics</strong></a>: We consider different lenses through which to evaluate ethics, and what sort of questions to ask.</p>
<p><a href="https://www.youtube.com/watch?v=av7utkFXbU4&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR&amp;index=9"><strong>Tech Ethics Practices to Implement at your Workplace</strong></a>: Practical tech ethics practices you can implement at your workplace.</p>
<p><a href="https://www.youtube.com/watch?v=LbNO51E7NUs&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR&amp;index=10"><strong>How to Address the Machine Learning Diversity Crisis</strong></a>: Only 12% of machine learning researchers are women. Based on research studies, I outline some evidence-based steps to take towards addressing this diversity crisis.</p>
<p><a href="https://www.youtube.com/watch?v=IlrP4jqxYR8&amp;list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR&amp;index=11"><strong>Advanced Technology is not a Substitute for Good Policy</strong></a>: We will look at some examples of what incentives cause companies to change their behavior or not (e.g.&nbsp;being warned for years of your role in an escalating genocide vs.&nbsp;threat of a hefty fine), how many AI ethics concerns are actually about human rights, and case studies of what happened when regulation &amp; safety standards came to other industries.</p>
<p>You can find the <a href="https://www.youtube.com/playlist?list=PLtmWHNX-gukIU6V33Bc8eP8OD41I4GywR">playlist of 11 short videos here</a>. And here is a longer, <a href="https://ethics.fast.ai/">full-length free fast.ai course on practical data ethics</a>.</p>



<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>ethics</category>
  <category>machine learning</category>
  <guid>https://rachel.fast.ai/posts/2021-08-17-eleven-ethics-videos/index.html</guid>
  <pubDate>Sun, 15 Aug 2021 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2021-08-17-eleven-ethics-videos/short-ethics-playlist.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Essential Work-From-Home Advice: Cheap and Easy Ergonomic Setups</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2020-08-06-ergonomics/index.html</link>
  <description><![CDATA[ 




<p>You weren’t expecting to spend 2020 working from home. You can’t afford a fancy standing desk. You don’t have a home office, or even much spare space, in your apartment. Your neck is getting a permanent crick from hunching over your laptop on the couch. While those of us who are able to work from home are privileged to have this option, we still don’t want to permanently damage our backs, necks, or arms from a bad ergonomic setup.</p>
<p>This is not a post for ergonomic aficionados (the setups I share could all be further optimized). This is a post for folks who don’t know where to get started, have a limited budget, and are willing to try simple, scrappy approaches. Key takeway: for 34 dollars (21 for a good mouse, and 13 for a cheap keyboard), as well as some household items, you can create an ergonomic setup like the one below. I will show many other options throughout the post, for both sitting and standing, as well as approaches you can easily assemble/disassemble (if you are using the family dinner table and need to clear it off each evening).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2020-08-06-ergonomics/ergonomic1.jpg" class="img-fluid figure-img" style="width:40.0%"></p>
<figcaption class="figure-caption">While visiting family, I created an ergonomic setup on a counter</figcaption>
</figure>
</div>
<h2 id="damage" class="anchored">
You can permanently damage your body with bad ergonomics
</h2>
<p>You can permanently damage your back, neck, and wrists from working without an ergonomic setup. Almost two decades ago, my partner Jeremy suffered from repetitive stress injury due to working without an ergonomic setup. At the time, his arms were paralyzed and he had to take months off from work. Even now and after years filled with good ergonomics and yoga, this still impacts his life, severely limiting how much time he can spend in cars or on planes, and creating painful flare-ups. Please take this issue seriously.</p>
<h2 id="separate" class="anchored">
Key advice: Have a separate keyboard and mouse
</h2>
<p>The most important thing to know is that you want your screen approximately at eye height, and your elbows at approximately right angles to your torso as they type and use the mouse. This is the case whether you are sitting or standing. If you are using a laptop, this will be impossible with the built-in keyboard and trackpad (no matter how nice they are). It is essential to have a separate keyboard and mouse. If you only do one thing to address ergonomics, obtain a separate keyboard and mouse.</p>
<p>If you can’t afford an external monitor, no worries, you can just elevate your laptop. Over the years, I have used cardboard boxes, drinking glasses, bottles of soda, board games, and stacks of books to elevate my laptop. I will recommend some keyboards and mice that I like below, but anything is better than using the ones built into your laptop (since that forces you to keep your screen at the wrong height). For example, the picture in the intro is of a set-up I created while visiting a family member’s apartment in 2014, using books and a cardboard box to elevate my keyboard, mouse, and laptop to the appropriate heights.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2020-08-06-ergonomics/ergonomic5.jpg" class="img-fluid figure-img" style="width:40.0%"></p>
<figcaption class="figure-caption">For the deep learning study group, I routinely used a brown cardboard box. Bonus: I could store everything in the box when we had the clear out of that room each night.</figcaption>
</figure>
</div>
<p>Above is a picture from the deep learning study group, which meets 5 days a week, for 7 weeks, every time we run the deep learning course. I use a brown cardboard box to elevate my keyboard. We have to clear out of that conference room each evening, and it is simple for me to put my items in the box. This sort of solution could work if you don’t have a dedicated office space in your home, and need to be able to set up/take down your workstation regularly.</p>
<p>I rarely worked in coffee shops pre-pandemic (and never do now), but when I had to I would still try to create an ergonomic setup (and go to a coffeeshop where there was enough space!). Here, I’ve stacked my laptop on top of my rolled-up backpack. Ideally, my screen would be higher, but this is still better than having it at table level. Don’t let the perfect be the enemy of the good. Every step you take towards a more ergonomic setup is helpful.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2020-08-06-ergonomics/ergonomic2.jpg" class="img-fluid figure-img" style="width:40.0%"></p>
<figcaption class="figure-caption">When working at a coffee shop (pre-pandemic), I brought an external keyboard and mouse, and used my rolled-up backpack to raise the height of my laptop screen</figcaption>
</figure>
</div>
<h2 id="standing-desks" class="anchored">
About standing desks
</h2>
<p>If you have a regular desk (or even just a table) at home and want a standing desk, one option is to convert it using the <a href="https://alphacolin.com/ikea-standing-desk-for-22-dollars/">$22 standing desk approach</a>, which involves an Ikea side table and shelf. I had a previous job in which this was quite popular. Here is a photo of my work desk from that time.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2020-08-06-ergonomics/ergonomic3.jpg" class="img-fluid figure-img" style="width:40.0%"></p>
<figcaption class="figure-caption">In a previous job, many of us set up $22 standing desks using Ikea side tables</figcaption>
</figure>
</div>
<p>Standing on a hard floor can be difficult for your back. I have a GelPro mat, which I love. If you can’t afford a GelPro mat, standing on a folded-up yoga mat works great too.</p>
<p>Note that standing desks are not a cure-all. I’ve often seen people with expensive standing-desk converters (also known as desktop risers) that still have their monitor way too low. Even if you have an external monitor and desktop riser, makes sure your monitor is at an appropriate height. It is likely you will still need to stack it on top of something. If you don’t like the aesthetics of using books or other household items, you can buy a monitor stand, <a href="https://www.kensington.com/p/products/ergonomic-desk-accessorries/laptop-risers-monitor-stands/kensington-smartfit-monitor-stand-plus-for-up-to-21-screens/">such as this one</a>.</p>
<p>Using a standing desk with poor posture is not very ergonomic, so be cognizant of when you start feeling fatigued. I prefer to switch between standing and sitting throughout the day, as my energy fluctuates.</p>
<h2 id="budget-recs" class="anchored">
Budget Recommendations
</h2>
<p>My “budget recommendation” would be to get an <a href="https://www.newegg.com/p/0TP-005H-00095">Anker vertical mouse</a> for $21 and literally any keyboard. If you have to choose, I’ve found that having a good mouse is way more important than a good keyboard. It is important that you get some keyboard though, so that you can elevate your laptop screen. In the setup below, I’m using a lightweight travel keyboard that isn’t particularly ergonomic, but it works fine.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2020-08-06-ergonomics/ergonomic4.jpg" class="img-fluid figure-img" style="width:40.0%"></p>
<figcaption class="figure-caption">The barista at this coffee shop kindly let me use 2 plastic tubs to prop up my laptop (pre-pandemic).</figcaption>
</figure>
</div>
<p>I realize that at a time when many Americans do not have enough to eat, that you may not have 34 dollars to spare (21 dollars for a mouse and 13 dollars for a cheap keyboard). However, if this is an option for you, it is well worth the cost. If you permanently damage your back, neck, or arms, no amount of money may be enough to heal them later.</p>
<h2 id="products" class="anchored">
Other products I like
</h2>
<p>My favorite mouse is the <a href="https://www.newegg.com/Logitech-910-001799/p/24W-001B-00008">Logitech wireless trackball mouse</a>. I have also used and liked the <a href="https://www.newegg.com/p/0TP-005H-00095">Anker vertical mouse</a>. For keyboards, I like <a href="https://www.newegg.com/p/12K-00XE-00002">Goldtouch</a> (I use an older version of this one) or the <a href="https://www.newegg.com/microsoft-natural-4000-b2m-00012-usb-wired/p/N82E16823109148">Microsoft Ergonomic Keyboard</a>. And if you are looking for a compact, lightweight travel keyboard, I like the <a href="https://www.iclever.com/products/BK03-Bluetooth-Portable-Keyboard">iClever foldup keyboard</a>.</p>
<p>As mentioned above, <a href="https://www.gelpro.com/">GelPro mats</a> are great if you are going to be standing, and a folded-up yoga mat is a cheaper alternative.</p>
<p>I have a <a href="https://www.therooststand.com/">Roost portable, lightweight laptop stand</a>, which is great, although I can’t use it since I switched from a Macbook Air to a Microsoft Surface Pro. None of the links in this post are affiliate links; I’m just recommending what I’ve personally used and like.</p>
<p>For more about home office set-ups, Jeremy recently posted a twitter thread about his preferred computer set-up (which includes some pricier options). It’s also worth noting that his desk has a small footprint, and fits in the corner of our living room.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
I couldn't be happier with my little standing desk setup. I have tried far to many products over the years, and here's what I highly recommend:<br>1/ <a href="https://t.co/lMagQPLys1">pic.twitter.com/lMagQPLys1</a>
</p>
— Jeremy Howard (<span class="citation" data-cites="jeremyphoward">@jeremyphoward</span>) <a href="https://twitter.com/jeremyphoward/status/1285747820482318336?ref_src=twsrc%5Etfw">July 22, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>



<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>advice</category>
  <category>work</category>
  <guid>https://rachel.fast.ai/posts/2020-08-06-ergonomics/index.html</guid>
  <pubDate>Wed, 05 Aug 2020 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2020-08-06-ergonomics/ergonomic1-short.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>4 Principles for Responsible Government Use of Technology</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2020-01-21-responsible-govt/index.html</link>
  <description><![CDATA[ 




<p>As governments consider new uses of technology, whether that be <a href="https://www.citylab.com/transportation/2019/11/firefly-digital-advertising-driver-pay-uber-lyft-cars-data/602077/"><u>sensors on taxi cabs</u></a>, <a href="https://slate.com/technology/2016/11/how-not-to-respond-to-the-next-police-surveillance-technology.html"><u>police body cameras</u></a>, or <a href="https://features.propublica.org/aggression-detector/the-unproven-invasive-surveillance-technology-schools-are-using-to-monitor-students/"><u>gunshot detectors</u></a> in public places, this raises issues around surveillance of vulnerable populations, unintended consequences, and potential misuse. There are several principles to keep in mind in how these decisions can be made in a healthier and more responsible manner. It can be tempting to reduce debates about government adoption of technology into binary for/against narratives, but that fails to capture many crucial and nuanced aspects of these decisions.</p>
<p>We recently hosted the <a href="https://www.sfdatainstitute.org/"><u>Tech Policy Workshop</u></a> at the USF Center for Applied Data Ethics. One of the themes was how governments can promote the responsible use of technology. Here I will share some key recommendations that came out of these discussions.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2020-01-21-responsible-govt/govt-headlines.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Headlines of articles related to government use of technology</figcaption>
</figure>
</div>
<section id="listen-to-local-communities" class="level2">
<h2 class="anchored" data-anchor-id="listen-to-local-communities">Listen to local communities</h2>
<p>There aren’t universal ethical answers that will make sense in every country and culture. Therefore, decisions on technology use should be made in close consultation with local communities. In 2013, Oakland announced plans for a new Domain Awareness Center (DAC), which would implement over 700 cameras throughout schools and public housing, facial recognition software, automated license plate readers (ALPRs), storage capacity for 300 terabytes of data, and a centralized facility with live monitroy. <a href="https://www.nytimes.com/2019/05/15/technology/facial-recognition-san-francisco-ban.html"><u>Brian Hofer</u></a> was an Oakland resident who had never set foot in City Hall prior to this, but he was alarmed by the plans, particularly in light of Edward Snowden’s revelations, which had been released the same month. Together with other citizens and privacy advocates, Hofer was concerned about the intrusiveness of the plans and began attending city council meetings. There were a number of reasons for their concerns, including <a href="https://www.eastbayexpress.com/oakland/the-real-purpose-of-oaklands-surveillance-center/Content?oid=3789230"><u>the discovery</u></a> that city staff had been discussing using DAC to surveil protests and demonstrations. Through the advocacy of local citizens, the plans <a href="https://www.eastbayexpress.com/SevenDays/archives/2014/03/05/oakland-city-council-rolls-back-the-dac"><u>were dramatically scaled back</u></a> and the Oakland Privacy Commission was formed, which continues to provide valuable insight into potential government decisions and purchases.</p>
<p>Sadly, the concerns of local communities are often overridden, in part due to corporate interests and racist stereotypes. For instance, in Detroit, a city that is 79% Black, <a href="https://www.freep.com/story/news/local/michigan/detroit/2019/06/27/detroiters-concerned-over-facial-recognition-technology/1567113001/"><u>citizens protested</u></a> against police use of facial recognition. Yet the city council ended up voting to okay its use, in violation of the police department’s own policy. In contrast, the demographics of cities that have been successful at banning facial recognition are quite different: San Francisco is only 5% Black and Oakland is 25% Black (credit to <a href="https://twitter.com/Combsthepoet/status/1206544760049217537?s=20">Tawana Petty for highlighting these statistics</a>). The racial composition of cities is a significant factor in where and how technology is deployed and used. In another sobering example of the significance of race, <a href="https://www.theverge.com/2016/10/11/13243890/facebook-twitter-instagram-police-surveillance-geofeedia-api"><u>Baltimore Police Department used facial recognition</u></a> to identify people protesting the death of Freddie Gray, a Black man killed in police custody.</p>
</section>
<section id="beware-how-ndas-obscure-public-sector-process-and-law" class="level2">
<h2 class="anchored" data-anchor-id="beware-how-ndas-obscure-public-sector-process-and-law">Beware how NDAs obscure public sector process and law</h2>
<p>In order for citizens to have a voice in the use of technology by their local governments, the first step is that they need to know what technology is being used. Unfortunately, many local governments are shrouded in secrecy on this topic, and they often sign overly strict non-disclosure agreements (NDAs), hiding even the existence of the technology they use. In 2017 New York City passed a measure appointing <a href="https://www.citylab.com/equity/2019/12/ai-technology-computer-algorithm-cities-automated-systems/603349/"><u>a task force on Automated Decision Systems</u></a> to investigate the fairness of software being used by the city and make policy recommendations. However, members of the task force were repeatedly denied their requests for even a basic list of automated systems already in use, with the city claiming that this is proprietary information. When the city released the final report from the commission, many members dissented with it and released their own shadow report in tandem. Meredith Whittaker, a member of the task force and founder of AI Now Institute, <a href="https://www.theverge.com/2019/11/20/20974379/nyc-algorithm-task-force-report-de-blasio"><u>described the city’s failure</u></a> to share relevant information in what could have been a groundbreaking project, “<em>It’s a waste, really. This is a sad precedent.</em>”</p>
<p>The law typically develops through lots of cases over time, explained Elizabeth Joh. However, NDAs often prevent citizens from finding out that a particular technology even exists, much less how it is being used in their city. For instance, cell-site simulators (often referred to as sting-rays), which help police locate a person’s cell phone, were protected by particularly strong NDAs, in which police had to agree that it was better to drop a case than to reveal that a cell-site simulator had been used in apprehending the suspect. How can our law develop when such important details remain hidden? The traditional process of developing and refining our legal system breaks down. “<em>Typically we think we have oversight into what police can do</em>,” <a href="https://theintercept.com/2017/04/30/taser-will-use-police-body-camera-videos-to-anticipate-criminal-activity/"><u>Joh has said</u></a> previously. “<em>Now we have third-party intermediary, they have a kind of privacy shield, they’re not subject to state public record laws, and they have departments sign contracts that they are going to keep this secret</em>.”</p>
</section>
<section id="security-is-not-the-same-as-safety" class="level2">
<h2 class="anchored" data-anchor-id="security-is-not-the-same-as-safety">Security is not the same as safety</h2>
<p><a href="https://www.freep.com/story/news/local/michigan/detroit/2019/06/27/detroiters-concerned-over-facial-recognition-technology/1567113001/"><u>Project Green Light</u></a> is a public-private partnership in Detroit in which high-definition surveillance cameras outside business stream live data to police and are prioritized by police over non-participants. Over 500 businesses are a part of it. This is the largest experiment of facial recognition on a concentrated group of Black people (700,000) to date. <a href="https://www.theguardian.com/us-news/2020/jan/02/california-police-black-stops-force"><u>Black people are disproportionately likely</u></a> to be stopped by police (even though when police search Black, Latino and Native American people, they are less likely to find drugs, weapons or other contraband compared to when they search white people), <a href="https://www.washingtonpost.com/local/public-safety/study-finds-disproportionate-number-of-black-people-arrested-in-dc/2019/05/14/92cf2d26-735a-11e9-8be0-ca575670e91c_story.html"><u>disproportionately likely to be written up on minor infractions</u></a>, and thus <a href="https://www.perpetuallineup.org/"><u>disproportionately likely to have their faces appear</u></a> in police face databases (which are unregulated and not audited for mistakes). This is particularly concerning when combined with knowledge of <a href="https://www.eff.org/deeplinks/2019/02/watching-black-body"><u>America’s long history</u></a> of surveilling and abusing Black communities. While the aims of the program are ostensibly to make Detroit safer, we have to ask, “Safer FOR who? And safer FROM whom?”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2020-01-21-responsible-govt/project-greenlight.jpeg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Graphic about Detroit’s Project Greenlight, originally from data.detroitmi.gov and shared in <a href="https://detroitcommunitytech.org/?q=content/riverwise-magazine-detroiters-want-be-seen-not-watched">Detroit Riverwise Magazine</a>”</figcaption>
</figure>
</div>
<p><a href="https://www.honeycombthepoet.org/music.html">Tawana Petty</a> is a poet and social justice organizer who was born and raised in Detroit. She serves as Director of Data Justice Programming for the <a href="https://detroitcommunitytech.org/">Detroit Community Technology Project</a> and co-leads the <a href="https://www.odbproject.org/">Our Data Bodies Project</a>. At the CADE Tech Policy Workshop she shared how Project Green Light makes her feel <em>less</em> safe, and gave a more hopeful example of how to increase safety: give people chairs to sit on their front porches and encourage them to spend more time outside talking with their neighbors. <a href="https://detroitcommunitytech.org/?q=content/riverwise-magazine-detroiters-want-be-seen-not-watched"><u>Myrtle Thompson-Curtis wrote</u></a> about the origins of the idea: in 1980 in Milwaukee “<em>a group of young African Americans remembered how elders would sit on the front porch and keep an eye on them when they were small. These watchful eyes gave them a sense of safety, of being cared for and looked out for by the community. When these youth grew into adulthood, they noticed that no one sat on their porches anymore. Instead people were putting bars on their doors and windows, fearing one another.</em>” Young people went door to door and offered free chairs to neighbors if they would agree to sit on their front porches while children walked to and from school. This program has since been replicated in St.&nbsp;Clair Shores, Michigan, to help defuse racial tensions, and now in Detroit, to illustrate an alternative to the city’s invasive Green Light Surveillance program. “<em>Security is not safety</em>,” Tawana stated, contrasting surveillance with true safety.</p>
<p>Rumman Chowdhury, the leader of the Responsible AI group at Accenture, pointed out that surveillance is often part of a stealth increase in militarization. While on the surface, militarization is sold as improving security, it can often have the opposite effect. Low-trust societies tend to be very militarized, and militarized societies tend to be low-trust. As <a href="https://www.wired.com/story/internet-made-dupes-cynics-of-us-all/"><u>Zeynep Tufekci wrote in Wired</u></a>, sociologists distinguish between high-trust societies (in which people can expect most interactions to work and to have access to due process) and low-trust societies (in which people expect to be cheated and that there is no recourse when you are wronged). In low trust societies, it is harder to make business deals, to find or receive credit, or to forge professional relationships. People in low-trust societies may also be more vulnerable to authoritarian rulers, who promise to impose order. We are already seeing a shift of the internet having gone from a high-trust environment to a low-trust environment, and the use of surveillance may be accelerating this shift in the physical world.</p>
</section>
<section id="policy-decisions-should-not-be-outsourced-as-design-decisions" class="level2">
<h2 class="anchored" data-anchor-id="policy-decisions-should-not-be-outsourced-as-design-decisions">Policy decisions should not be outsourced as design decisions</h2>
<p>When considering <a href="https://www.wbur.org/hereandnow/2017/04/12/axon-free-body-cameras-police"><u>police body cameras</u></a>, there are a number of significant decisions: should the officer be able to turn them on and off at any time? Should the camera have a blinking red light to let people know it is recording? Where should the videos be stored and who should have access to them? Even though these decisions will have a profound impact on the public, they are currently decided by private tech companies. This is just one of the examples Elizabeth Joh shared in illustrating how <strong>what should be policy decisions often end up being determined by corporations as design decisions</strong>. In the case of police body cameras, this lack of choice/control is worsened by the fact that Axon (previously known as Taser) has a monopoly on police-body cameras: since they have a relationship with 17,000 of the 18,000 police departments in the USA, cities may not even have much choice. Vendor-customer relationships influence how police do their jobs and how we can hold them accountable.</p>
<p>Heather Patterson, a privacy researcher at Intel and a member of Oakland’s Privacy Commission, spoke about how tech companies often neglect cities, failing to build products that fit with their needs and requirements, and treating them as an afterthought. In many cases, cities may want to have fewer options or collect less data, which goes against the prevailing tech approach which Mozilla Head of Policy Chris Riley described as “collect now, monetize later, store forever just in case”.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2020-01-21-responsible-govt/tech-policy-horizontal.jpg" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Some of the many great speakers from our Tech Policy Workshop, who spoke on a variety of topics</figcaption>
</figure>
</div>
<p>These principles can guide us towards a more responsible use of technology by local governments. Technology can be used for good when it is developed and deployed responsibly, with input from a diverse group of relevant stakeholders, and embedded with the appropriate transparency and accountability.</p>
<p>More responsible government use of technology was just one of the themes discussed at the Tech Policy Workshop. Stay tuned for more resources and insights from the workshop!</p>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>ethics</category>
  <guid>https://rachel.fast.ai/posts/2020-01-21-responsible-govt/index.html</guid>
  <pubDate>Mon, 20 Jan 2020 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2020-01-21-responsible-govt/project-greenlight.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>The problem with metrics is a big problem for AI</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2019-09-24-metrics/index.html</link>
  <description><![CDATA[ 




<p><em>Update: This post was expanded into a paper, <a href="https://www.cell.com/patterns/fulltext/S2666-3899(22)00056-3">Reliance on metrics is a fundamental challenge for AI</a>, by Rachel Thomas and David Uminsky, which was accepted to the <a href="https://www.sydney.edu.au/data-science/news-and-events/ethics-of-data-science-conference.html">Ethics of Data Science Conference 2020</a> and to <a href="https://www.cell.com/patterns/fulltext/S2666-3899(22)00056-3">Cell Patterns</a>. The paper version includes more grounding in previous academic work and a framework towards mitigating these harms.</em></p>
<p>Goodhart’s Law states that <em>“When a measure becomes a target, it ceases to be a good measure.”</em> At their heart, what most current AI approaches do is to optimize metrics. The practice of optimizing metrics is not new nor unique to AI, yet AI can be particularly efficient (even <em>too</em> efficient!) at doing so.</p>
<p>This is important to understand, because any risks of optimizing metrics are heightened by AI. While metrics can be useful in their proper place, there are harms when they are unthinkingly applied. Some of the scariest instances of algorithms run amok (such as <a href="https://www.fast.ai/posts/2019-05-28-google-nyt-mohan.html">Google’s algorithm contributing to radicalizing people into white supremacy</a>, <a href="https://www.washingtonpost.com/local/education/creative--motivating-and-fired/2012/02/04/gIQAwzZpvR_story.html">teachers being fired by an algorithm</a>, or <a href="https://www.vice.com/en_us/article/pa7dj9/flawed-algorithms-are-grading-millions-of-students-essays">essay grading software</a> that rewards sophisticated garbage) all result from over-emphasizing metrics. We have to understand this dynamic in order to understand the urgent risks we are facing due to misuse of AI.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2019-09-24-metrics/metrics.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Headlines from HBR, Washington Post, and Vice on some of the outcomes of over-optimizing metrics: rewarding gibberish essays, promoting propaganda, massive fraud at Wells Fargo, and firing good teachers</figcaption>
</figure>
</div>
The following principles will be illustrated through a series of case studies:
<ul>
<li>
Any metric is just a proxy for what you really care about
</li>
<li>
Metrics can, and will, be gamed
</li>
<li>
Metrics tend to overemphasize short-term concerns
</li>
<li>
Many online metrics are gathered in highly addictive environments
</li>
<li>
Metrics are most likely to be useful when they are treated as one piece of a bigger picture
</li>
</ul>
<h2 id="proxy" class="anchored">
We can’t measure the things that matter most
</h2>
<p>Metrics are typically just a proxy for what we really care about. The paper <a href="https://scholar.harvard.edu/files/sendhil/files/aer.p20171084.pdf">Does Machine Learning Automate Moral Hazard and Error?</a> covers an interesting example: the researchers investigate which factors in someone’s electronic medical record are most predictive of a future stroke. However, the researchers found that several of the most predictive factors (such as accidental injury, a benign breast lump, or colonoscopy) don’t make sense as risk factors for stroke. So, just what is going on? It turned out that the model was just identifying people who <em>utilize</em> health care a lot. They didn’t actually have data of who had a stroke (a physiological event in which regions of the brain are denied new oxygen); they had data about who had access to medical care, chose to go to a doctor, were given the needed tests, and had this billing code added to their chart. But a number of factors influence this process: who has health insurance or can afford their co-pay, who can take time off of work or find childcare, gender and racial biases that impact who gets accurate diagnoses, cultural factors, and more. As a result, the model was largely picking out people who utilized healthcare versus who did not.</p>
<p>This an example of the common phenomenon of having to use proxies: You want to know what content users like, so you measure what they click on. You want to know which teachers are most effective, so you measure their students test scores. You want to know about crime, so you measure arrests. These things are not the same. Many things we <em>do</em> care about can not be measured. Metrics can be helpful, but we can’t forget that they are just proxies.</p>
<p>As another example, Google used hours spent watching YouTube as a proxy for how happy users were with the content, <a href="https://youtube-creators.googleblog.com/2012/08/youtube-now-why-we-focus-on-watch-time.html">writing on the Google blog</a> that <em>“If viewers are watching more YouTube, it signals to us that they’re happier with the content they’ve found.”</em> Guillaume Chaslot, an AI engineer who formerly worked at Google/YouTube, shares how this had the <a href="https://medium.com/@guillaumechaslot/how-algorithms-can-learn-to-discredit-the-media-d1360157c4fa">side effect of incentivizing conspiracy theories</a>, since convincing users that the rest of the media is lying kept them watching more YouTube.</p>
<h2 id="gamed" class="anchored">
Metrics can, and will, be gamed
</h2>
<p>It is almost inevitable that metrics will be gamed, particularly when they are given too much power. One week this spring, Chaslot collected 84,695 videos from YouTube and analyzed the number of views and the number of channels from which they were recommended. This is <a href="https://twitter.com/gchaslot/status/1121603851675553793?s=20">what he found</a> (also covered in <a href="https://www.washingtonpost.com/technology/2019/04/26/youtube-recommended-russian-media-site-above-all-others-analysis-mueller-report-watchdog-group-says/">the Washington Post</a>):</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2019-09-24-metrics/YTRT.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Chart showing Russia Today’s video on the Mueller Report as being an outlier in how many YouTube channels recommended it.</figcaption>
</figure>
</div>
<p>The state-owned media outlet Russia Today was an extreme outlier in how much YouTube’s algorithm had selected it to be recommended by a wide-variety of other YouTube channels. Such algorithmic selections, which begin autoplaying as soon as your current video is done, account for 70% of the time that users spend on YouTube. This chart strongly suggests that Russia Today has in some way gamed YouTube’s algorithm. Platforms are rife with attempts to game their algorithms, to show up higher in search results or recommended content, through fake clicks, fake reviews, fake followers, and more.</p>
<p><a href="https://www.vice.com/en_us/article/pa7dj9/flawed-algorithms-are-grading-millions-of-students-essays">Automatic essay grading software</a> focuses primarily on metrics like sentence length, vocabulary, spelling, and subject-verb agreement, but is unable to evaluate aspects of writing that are hard to quantify, such as creativity. As a result, gibberish essays randomly generated by computer programs to contain lots of sophisticated words score well. Essays from students in mainland China, which do well on essay length and sophisticated word choice, received higher scores from the algorithms than from expert human graders, suggesting that these students may be using chunks of pre-memorized text.</p>
<p>As USA education policy began over-emphasizing student test scores as the primary way to evaluate teachers, there have been <a href="https://www.nytimes.com/2010/06/11/education/11cheat.html">widespread scandals</a> of teachers and principals cheating by altering students scores, in Georgia, Indiana, Massachusetts, Nevada, Virginia, Texas, and elsewhere. One consequence of this is that <strong>teachers who don’t cheat may be penalized or <a href="https://www.washingtonpost.com/local/education/creative--motivating-and-fired/2012/02/04/gIQAwzZpvR_story.html">even fired</a></strong> (when it appears student test scores have dropped to more average levels under their instruction). When metrics are given undue importance, attempts to game those metrics become common.</p>
<h2 id="short-term" class="anchored">
Metrics tend to overemphasize short-term concerns
</h2>
<p>It is much easier to measure short-term quantities: click through rates, month-over-month churn, quarterly earnings. Many long-term trends have a complex mix of factors and are tougher to quantify. What is the long-term impact on user trust of having your brand associated with <a href="https://www.nytimes.com/2019/06/03/world/americas/youtube-pedophiles.html">promoting pedophilia</a>, <a href="https://www.theverge.com/2018/9/19/17876892/youtube-extremism-report-rebecca-lewis-data-society">white supremacy</a>, and <a href="https://www.bbc.com/news/technology-47279253">flat-earth theories</a>? What is the long-term impact on hiring to be the subject of years worth of <a href="https://www.wired.com/story/why-zuckerberg-15-year-apology-tour-hasnt-fixed-facebook/">privacy scandals</a>, <a href="https://www.vox.com/policy-and-politics/2019/1/22/18177076/social-media-facebook-far-right-authoritarian-populism">political manipulation</a>, and <a href="https://www.fast.ai/posts/2017-11-02-ethics.html">facilitating genocide</a>?</p>
<p>Simply measuring what users click on is a short-term concern, and does not take into account factors like the potential long-term impact of a long-form investigative article which may have taken months to research and which could help shape a reader’s understanding of a complex issue and even lead to significant societal changes.</p>
<p>A recent <a href="https://hbr.org/2019/09/dont-let-metrics-undermine-your-business">Harvard Business Review article</a> looked at Wells Fargo as a case study of how letting metrics replace strategy can harm a business. After identifying cross-selling as a measure of long-term customer relationships, Wells Fargo went overboard emphasizing the cross-selling metric: intense pressure on employees combined with an unethical sales culture led to 3.5 million fraudulent deposit and credit card accounts being opened without customers’ consent. The metric of cross-selling is a much more short-term concern compared to the loftier goal of nurturing long-term customer relationships. Overemphasizing metrics removes our focus from long-term concerns such as our values, trust and reputation, and our impact on society and the environment, and myopically focuses on the short-term.</p>
<h2 id="addictive" class="anchored">
Many metrics gather data of what we do in highly addictive environments
</h2>
<p>It matters which metrics we gather and in what environment we do so. Metrics such as what users click on, how much time they spend on sites, and “engagement” are heavily relied on by tech companies as proxies for user preference, and are used to drive important business decisions. Unfortunately, these metrics are gathered in environments engineered to be highly addictive, <a href="https://twitter.com/random_walker/status/1143601343279579137?s=20">laden with dark patterns</a>, and where financial and design decisions have already greatly circumscribed the range of options.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2019-09-24-metrics/junkfood.jpg" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Our online environment is a buffet of junk food</figcaption>
</figure>
</div>
<p>Zeynep Tufekci, a professor at UNC and regular contributor to the New York Times, compares recommendation algorithms (such as YouTube choosing which videos to auto-play for you and Facebook deciding what to put at the top of your newsfeed) to a <a href="https://www.theguardian.com/technology/2018/feb/02/how-youtubes-algorithm-distorts-truth">cafeteria shoving junk food</a> into children’s faces. <em>“This is a bit like an autopilot cafeteria in a school that has figured out children have sweet teeth, and also like fatty and salty foods. So you make a line offering such food, automatically loading the next plate as soon as the bag of chips or candy in front of the young person has been consumed.”</em> As those selections get normalized, the output becomes ever more extreme: <em>“So the food gets higher and higher in sugar, fat and salt – natural human cravings – while the videos recommended and auto-played by YouTube get more and more bizarre or hateful.”</em> Too many of our online environments are like this, with metrics capturing that we love sugar, fat, and salt, not taking into account that we are in the digital equivalent of a <a href="https://en.wikipedia.org/wiki/Food_desert">food desert</a> and that companies haven’t been required to put nutrition labels on what they are offering. Such metrics are not indicative of what we would prefer in a healthier or more empowering environment.</p>
<h2 id="better" class="anchored">
When Metrics are Useful
</h2>
<p>All this is not to say that we should throw metrics out altogether. Data can be valuable in helping us understand the world, test hypotheses, and move beyond gut instincts or hunches. Metrics can be useful when they are in their proper context and place. One way to keep metrics in their place is to consider a slate of many metrics for a fuller picture (and resist the temptation to try to boil these down to a single score). For instance, knowing the rates at which tech companies hire people from under-indexed groups is a very limited data point. For evaluating diversity and inclusion at tech companies, we need to know comparative promotion rates, cap table ownership, retention rates (many tech companies are revolving doors driving people from under-indexed groups away with their toxic cultures), number of harassment victims silenced by NDAs, rates of under-leveling, and more. Even then, all this data should still be combined with <strong>listening to first-person experiences</strong> of those working at these companies.</p>
<p>Columbia professor and New York Times Chief Data Scientist <a href="https://datascience.columbia.edu/ethical-principles-okrs-and-kpis-what-youtube-and-facebook-could-learn-tukey">Chris Wiggins wrote</a> that quantitative measures should always be combined with qualitative information, <em>“Since we can not know in advance every phenomenon users will experience, we can not know in advance what metrics will quantify these phenomena. To that end, data scientists and machine learning engineers must partner with or learn the skills of user experience research, giving users a voice.”</em></p>
<p>Another key to keeping metrics in their proper place is to keep domain experts and those who will be most impacted closely involved in their development and use. Surely most teachers could have foreseen that evaluating teachers primarily on the standardized test scores of their students would lead to a host of negative consequences.</p>
<p>I am not opposed to metrics; I am alarmed about the harms caused when metrics are overemphasized, a phenomenon that we see frequently with AI, and which is having a negative, real-world impact. AI running unchecked to optimize metrics has led to Google/YouTube’s heavy promotion of white supremacist material, essay grading software that rewards garbage, and more. By keeping the risks of metrics in mind, we can try to prevent these harms.</p>



<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>ethics</category>
  <category>machine learning</category>
  <guid>https://rachel.fast.ai/posts/2019-09-24-metrics/index.html</guid>
  <pubDate>Mon, 23 Sep 2019 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2019-09-24-metrics/metrics.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>8 Things You Need to Know about Surveillance</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2019-08-07-surveillance/index.html</link>
  <description><![CDATA[ 




<p>Over 225 police departments have partnered with Amazon to have access to Amazon’s video footage obtained as part of the “smart” doorbell product Ring, and in many cases these partnerships are <a href="https://www.vice.com/en_us/article/d3ag37/us-cities-are-helping-people-buy-amazon-surveillance-cameras-using-taxpayer-money">heavily subsidized with taxpayer money</a>. Police departments are allowing Amazon <a href="https://gizmodo.com/cops-are-giving-amazons-ring-your-real-time-911-data-1836883867">to stream 911 call</a> information directly in real-time, and Amazon requires police departments to <a href="https://gizmodo.com/everything-cops-say-about-amazons-ring-is-scripted-or-a-1836812538">read pre-approved scripts</a> when talking about the program. If a homeowner doesn’t want to share data from their video camera doorbell with police, an officer for the Fresno County Sheriff’s Office said <a href="https://gizmodo.com/amazons-ring-is-teaching-cops-how-to-persuade-customers-1837000515">they can just go directly to Amazon</a> to obtain it. This creation of an extensive surveillance network, the murky private-public partnership surrounding it, and a lack of any sort of regulations or oversight is frightening. And this is just one of many examples related to surveillance technology that have recently come to light.</p>
<p>I frequently talk with people who are not that concerned about surveillance, or who feel that the positives outweigh the risks. Here, I want to share some important truths about surveillance:</p>
<ol>
<li>
Surveillance can facilitate human rights abuses and even genocide
</li>
<li>
Data is often used for different purposes than why it was collected
</li>
<li>
Data often contains errors
</li>
<li>
Surveillance typically operates with no accountability
</li>
<li>
Surveillance changes our behavior
</li>
<li>
Surveillance disproportionately impacts the marginalized
</li>
<li>
Data privacy is a public good
</li>
<li>
We don’t have to accept invasive surveillance
</li>
</ol>
<p>While I was writing this post, a number of investigative articles came out with disturbing new developments related to surveillance. I decided that rather than attempt to include everything in one post (which would make it too long and too dense), I would go ahead and share the above facts about surveillance, as they are just a relevant as ever.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
The last 24 hours:<br>- NYC police using facial recognition on 11 year old kids<br>- Cops are giving Amazon real-time 911 caller data<br>- California Facial Recognition Interconnect<br>- contd facial rec on protesters in Hong Kong<br>- Palantir founder Peter Thiel gets op-ed in NYTimes
</p>
— Rachel Thomas (<span class="citation" data-cites="math_rachel">@math_rachel</span>) <a href="https://twitter.com/math_rachel/status/1157357983036137473?ref_src=twsrc%5Etfw">August 2, 2019</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<h2 id="genocide" class="anchored">
<ol type="1">
<li>Surveillance can facilitate human rights abuses and even genocide
</li></ol></h2>

<p><a href="https://www.theengineroom.org/dangerous-data-the-role-of-data-collection-in-genocides/">There is a long history</a> of data about sensitive attributes being misused, including the use of the 1940 USA Census to intern Japanese Americans, a system of identity cards introduced by the Belgian colonial government that were later used during the 1994 Rwandan genocide (in which nearly a million people were murdered), and the <a href="https://www.huffpost.com/entry/ibm-holocaust_b_1301691">role of IBM in helping Nazi Germany</a> use punchcard computers to identify and track the mass killing of millions of Jewish people. More recently, the mass internment of over one million people who are part of an ethnic minority in Western China was facilitated through <a href="https://www.wired.com/story/inside-chinas-massive-surveillance-operation/">the use of a surveillance network</a> of cameras, biometric data (including images of people’s faces, audio of their voices, and blood samples), and phone monitoring.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2019-08-07-surveillance/ibm-hitler.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Adolf Hitler meeting with IBM CEO Tom Watson Sr.&nbsp;in 1937. Source: https://www.computerhistory.org/revolution/punched-cards/2/15/109</figcaption>
</figure>
</div>
<p>Pictured above is Adolf Hitler (far left) meeting with IBM CEO Tom Watson Sr.&nbsp;(2nd from left), shortly before Hitler awarded Watson a special “Service to the Reich” medal in 1937 (<a href="https://www.jewishgen.org/ForgottenCamps/General/TimeEng.html">for a timeline of the Holocaust, see here</a>). Watson returned the medal in 1940, although IBM continued to do business with the Nazis. IBM technology helped the Nazis conduct detailed censuses in countries they occupied, to thoroughly identify anyone of Jewish descent. <a href="https://www.huffpost.com/entry/ibm-holocaust_b_1301691">Nazi concentration camps used IBM’s punchcard machines</a> to tabulate prisoners, recording whether they were Jewish, gay, or Gypsies, and whether they died of “natural causes,” execution, suicide, or via “special treatment” in gas chambers. It is not the case that IBM sold the machines and then was done with it. Rather, IBM and its subsidiaries provided regular training and maintenance on-site at the concentration camps: printing off cards, configuring machines, and repairing them as they broke frequently.</p>
<h2 id="purposes" class="anchored">
<ol start="2" type="1">
<li>Data is often used for different purposes than why it was collected
</li></ol></h2>

<p>In the above examples, the data collection began before genocide was committed. IBM began selling to Nazi Germany well before the Holocaust (although continued for far too long), including helping with Germany’s 1933 census conducted by Adolf Hitler, which was effective at identifying far more Jewish people than had previously been recognized in Germany.</p>
<p>It is important to recognize how data and images gathered through surveillance can be weaponized later. Columbia professor <a href="https://www.nytimes.com/2019/04/10/opinion/sunday/privacy-capitalism.html">Tim Wu wrote</a> that <em>“One [hard truth] is that data and surveillance networks created for one purpose can and will be used for others. You must assume that any personal data that Facebook or Android keeps are data that governments around the world will try to get or that thieves will try to steal.”</em></p>
<p>Plenty of data collection is not involved with such extreme abuse as genocide; however, in a time of global resurgence of white supremacist, ethno-nationalist, and authoritarian movements, it would be deeply irresponsible to not consider how data &amp; surveillance can and will be weaponized against already vulnerable groups.</p>
<h2 id="errors" class="anchored">
<ol start="3" type="1">
<li>Data often has errors (and no mechanism for correcting them)
</li></ol></h2>

<p>A <a href="https://www.latimes.com/local/lanow/la-me-ln-calgangs-audit-20160811-snap-story.html">database of suspected gang members</a> maintained by California law enforcement officials was found to be full of errors, including 42 babies who had been added to the database when they were less than 1 year old (28 of whom were marked as “admitting to being gang members”). Even worse, there was no process in place for correcting mistakes or removing people once they’ve been added.</p>
<p>An <a href="https://www.washingtonpost.com/posteverything/wp/2016/09/08/how-the-careless-errors-of-credit-reporting-agencies-are-ruining-peoples-lives/">NPR reporter recounts his experience</a> of trying to rent an apartment and discovering that TransUnion, one of the 3 major credit bureaus, incorrectly reported him as having two felony firearms convictions. TransUnion only removed the mistakes after a dozen phone calls and notification that the story would be reported on. This is not an unusual story: the FTC’s large-scale study of credit reports in 2012 found 26% of consumers had at least one mistake in their files and 5% had errors that could be devastating. An even more opaque, <a href="https://www.washingtonpost.com/business/economy/little-known-firms-tracking-data-used-in-credit-scores/2011/05/24/gIQAXHcWII_story.html?utm_term=.19efcc7df056">unregulated “4th bureau” exists</a>: a collection of companies buying and selling personal information about people on the margins of the banking system (such as immigrants, students, and people with low incomes), with no standards on what types of data are included, no way to opt out, and no system for identifying or correcting mistakes.</p>
<h2 id="accountability" class="anchored">
<ol start="4" type="1">
<li>Surveillance typically operates with no accountability
</li></ol></h2>

<p>What makes the examples in the previous section disturbing is not just that errors occurred, but that there was no way to identify or correct them, and no accountability for those profiting off the error-laden data. Often, even the existence of the systems being used is not publicly known (much less details of how these systems work), unless discovered by journalists or revealed by whistleblowers. The <a href="https://www.metrotimes.com/news-hits/archives/2019/07/29/bipartisan-panel-why-detroits-facial-recognition-technology-should-be-banned">Detroit Police Dept</a> used facial recognition technology for nearly two years without public input and in violation of a requirement that a policy be approved by the city’s Board of Police Commissioners, until a <a href="https://www.americaunderwatch.com/">study from Georgetown Law’s Center for Privacy &amp; Technology</a> drew attention to the issue. Palantir, the defense startup founded by billionaire Peter Thiel, ran a program with <a href="https://www.theverge.com/2018/2/27/17054740/palantir-predictive-policing-tool-new-orleans-nopd">New Orleans Police Department for 6 years</a> which city council members did not even know about, much less have any oversight.</p>
<p>After two studies found that Amazon’s facial recognition software produced <a href="https://www.nytimes.com/2018/07/26/technology/amazon-aclu-facial-recognition-congress.html">inaccurate</a> and <a href="https://www.theverge.com/2019/1/25/18197137/amazon-rekognition-facial-recognition-bias-race-gender">racially biased results</a>, Amazon countered that the researchers should have changed the default parameters. However, it turned out that <a href="https://gizmodo.com/defense-of-amazons-face-recognition-tool-undermined-by-1832238149">Amazon was not instructing police departments</a> that use its software to do this either. Surveillance programs are operating with few regulations, no oversight, no accountability around accuracy or mistakes, and in many cases, no public knowledge of what is going on.</p>
<h2 id="behavior" class="anchored">
<ol start="5" type="1">
<li>Surveillance changes our behavior
</li></ol></h2>

<p>Hundreds of thousands of people in <a href="https://www.bbc.com/news/world-asia-china-48656471">Hong Kong are protesting</a> an unpopular new bill which would allow extradition to China. Typically, Hong Kong locals use their rechargeable smart cards to ride the subway. However, during the protests, <a href="https://qz.com/1642441/extradition-law-why-hong-kong-protesters-didnt-use-own-metro-cards/">long lines of people</a> waited to use cash to buy paper tickets (usually something that only tourists do) concerned that they would be tracked for having attended the protests. Would fewer people protest if this was not an option?</p>
<p>In the United States, in 2015 the <a href="https://www.theverge.com/2016/10/11/13243890/facebook-twitter-instagram-police-surveillance-geofeedia-api">Baltimore Police Department used facial recognition</a> technology to surveil people protesting the death of Freddie Grey, a young Black man who was killed in police custody, and arrested protesters with outstanding warrants. Mass surveillance could have a chilling impact on our rights to move about freely, to express ourselves, and to protest. <em>“We act differently when we know we are ‘on the record.’ Mass privacy is the freedom to act without being watched and thus in a sense, to be who we really are,”</em> Columbia professor <a href="https://www.nytimes.com/2019/04/10/opinion/sunday/privacy-capitalism.html">Tim Wu wrote</a> in the New York Times.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://rachel.fast.ai/posts/2019-08-07-surveillance/geofeedia.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption class="figure-caption">Flyer from the company Geofeedia. Source: https://www.aclunc.org/docs/20161011_geofeedia_baltimore_case_study.pdf</figcaption>
</figure>
</div>
<h2 id="uneven" class="anchored">
<ol start="6" type="1">
<li>Surveillance disproportionately impacts those who are already marginalized
</li></ol></h2>

<p>Surveillance is applied unevenly, causing the greatest harm to people who are already marginalized, including immigrants, people of color, and people living in poverty. These groups are more heavily policed and surveilled. <a href="https://www.law.georgetown.edu/privacy-technology-center/publications/the-perpetual-line-up/">The Perpetual Line-Up</a> from the Georgetown Law Center on Privacy and Technology studied the unregulated use of facial recognition by police, with half of all Americans appearing in law enforcement databases, and the risks of errors, racial bias, misuses, and threats to civil liberties. The researchers pointed out that African Americans are <a href="https://www.perpetuallineup.org/findings/racial-bias">more likely to appear</a> in these databases (many of which are drawn from mug shots) since they are disproportionately likely to be stopped, interrogated, or arrested. For another example, consider the contrast between how easily people over 65 can apply for Medicare benefits by filling out an online form, with <a href="https://tcf.org/content/report/disparate-impact-surveillance/">the invasive personal questions</a> asked of a low-income mother on Medicaid about her lovers, hygiene, parental shortcomings, and personal habits.</p>
<p>In an article titled <a href="https://www.fastcompany.com/90317495/another-tax-on-the-poor-surrendering-privacy-for-survival">Trading privacy for survival is another tax on the poor</a>, Ciara Byrne wrote, <em>“Current public benefits programs ask applicants extremely detailed and personal questions and sometimes mandate home visits, drug tests, fingerprinting, and collection of biometric information… Employers of low-income workers listen to phone calls, conduct drug tests, monitor closed-circuit television, and require psychometric tests as conditions of employment. Prisoners in some states have to consent to be voiceprinted in order to make phone calls.”</em></p>
<h2 id="aggregate" class="anchored">
<ol start="7" type="1">
<li>Data privacy is a public good, like air quality or safe drinking water
</li></ol></h2>

<p>Data is more revealing in aggregate. It can be nearly impossible to know what your individual data could reveal when combined with the data of others or with data from other sources, or when machine learning inference is performed on it. For instance, as <a href="https://www.nytimes.com/2018/01/30/opinion/strava-privacy.html">Zeynep Tufekci wrote</a> in the New York Times, individual Strava users could not have predicted how in aggregate their data could be used to identify the locations of US military bases. <em>“Data privacy is not like a consumer good, where you click ‘I accept’ and all is well. Data privacy is more like air quality or safe drinking water, a public good that cannot be effectively regulated by trusting in the wisdom of millions of individual choices. A more collective response is needed.”</em></p>
<p>Unfortunately, this also means that you can’t fully safeguard your privacy on your own. You may choose not to purchase Amazon’s ring doorbell, yet you can still show up in the video footage collected by others. You might strengthen your online privacy practices, yet conclusions will still be inferred about you based on the behavior of others. As Professor Tufekci wrote, <strong>we need a collective response</strong>.</p>
<h2 id="hope" class="anchored">
<ol start="8" type="1">
<li>We don’t have to accept invasive surveillance
</li></ol></h2>

<p>Many people are uncomfortable with surveillance, but feel like they have no say in the matter. While the threats surveillance poses are large, it is not too late to act. We are seeing success: in response to community organizing and an audit, Los Angeles Police Department <a href="https://www.latimes.com/local/lanow/la-me-lapd-predictive-policing-big-data-20190405-story.html">scrapped a controversial program</a> to predict who is most likely to commit violent crimes. <a href="https://www.metrotimes.com/news-hits/archives/2019/07/29/bipartisan-panel-why-detroits-facial-recognition-technology-should-be-banned">Citizens, researchers, and activists in Detroit</a> have been effective at drawing attention to the Detroit Police Department’s unregulated use of facial recognition and a bill calling for a 5-year moratorium has been introduced to the state legislature. Local governments in <a href="https://www.bbc.com/news/technology-48276660">San Francisco</a>, <a href="https://www.sfchronicle.com/bayarea/article/Oakland-bans-use-of-facial-recognition-14101253.php">Oakland</a>, and <a href="https://www.bostonglobe.com/metro/2019/06/27/somerville-city-council-passes-facial-recognition-ban/SfaqQ7mG3DGulXonBHSCYK/story.html">Somerville</a> have banned the use of facial recognition by police.</p>
<p>For further resources, please check out: - <a href="https://www.law.georgetown.edu/privacy-technology-center/">Georgetown Law Center on Privacy and Technology</a> - <a href="https://www.odbproject.org/tools/">Digital Defense Playbook</a></p>



<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>ethics</category>
  <guid>https://rachel.fast.ai/posts/2019-08-07-surveillance/index.html</guid>
  <pubDate>Tue, 06 Aug 2019 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2019-08-07-surveillance/ibm-hitler.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Advice for Better Blog Posts</title>
  <dc:creator>Rachel Thomas</dc:creator>
  <link>https://rachel.fast.ai/posts/2019-05-13-blogging-advice/index.html</link>
  <description><![CDATA[ 




<p>A blog is like a resume, only better. I’ve been invited to give keynote talks based on my posts, and I know of people for whom blog posts have led to job offers. I’ve encouraged people to start blogging in <a href="http://www.fast.ai/2017/04/06/alternatives/">several of</a> <a href="https://rachel.fast.ai/posts/2017-12-18-personal-brand/">my previous</a> <a href="https://medium.com/@racheltho/why-you-yes-you-should-blog-7d2544ac1045">posts</a>, and I even required students in my <a href="https://github.com/fastai/numerical-linear-algebra">computational linear algebra course</a> to write a blog post (although they weren’t required to publish it), since good technical writing skills are useful in the workplace and in interviews. Also, explaining something you’ve learned to someone else is a way to cement your knowledge. I gave a list of tips for <a href="https://medium.com/@racheltho/why-you-yes-you-should-blog-7d2544ac1045">getting started with your first blog post</a> previously, and I wanted to offer some more advanced advice here.</p>
<section id="who-is-your-audience" class="level2">
<h2 class="anchored" data-anchor-id="who-is-your-audience">Who is your audience?</h2>
<p>Advice that my speech coach gave me about <a href="https://rachel.fast.ai/posts/2017-12-18-personal-brand/">preparing talks</a>, which I think also applies to writing, is to choose one particular person that you can think of as your target audience. <strong>Be as specific as possible.</strong> It’s great if this is a real person (and it is totally fine if they are not actually going to read your post or attend your talk), although it doesn’t have to be (you just need to be extra-thorough in making up details about them if it’s not). Either way, what is their background? What sort of questions or misconceptions might they have about the topic? At various points, the person I’m thinking of has been a friend or colleague, one of my students, or my younger self.</p>
<p>Being unclear about your audience can lead to a muddled post: for instance, I’ve seen blog posts that contain both beginner material (e.g.&nbsp;defining what training and test sets are) as well as very advanced material (e.g.&nbsp;describing complex new architectures). Experts would be bored and beginners would get lost.</p>
</section>
<section id="dos-and-donts" class="level2">
<h2 class="anchored" data-anchor-id="dos-and-donts">Dos and Don’ts</h2>
<p>When you read other people’s blog posts, think about what works well. What did you like about it? And when you read blog posts that you don’t enjoy as much, think about why not? What would make the post more engaging for you? Note that not every post will appeal to every person. Part of having a target audience means that there are people who are not in your target audience, which is fine. And sometimes I’m not somebody else’s target audience. As with all advice, this is based on my personal experience and I’m sure that there are exceptions.</p>
<section id="things-that-often-work-well" class="level3">
<h3 class="anchored" data-anchor-id="things-that-often-work-well">Things that often work well:</h3>
<ul>
<li>Bring together many useful resources (but don’t include everything! the value is in <strong>your curation</strong>)</li>
<li>Do provide motivation and context. If you are going to explain how an algorithm works, first give some examples of real-world applications where it is used, or how it is different from other options.</li>
<li>People are convinced by several different things: stories, statistics, research, and visuals. Try using a blend of these.</li>
<li>If you’re using a lot of code, try writing in a Jupyter notebook (which can be <a href="https://cduvallet.github.io/posts/2018/03/ipython-notebooks-jekyll">converted into a blog post</a>) or a <a href="https://www.kaggle.com/kernels">Kaggle Kernel</a>.</li>
</ul>
</section>
<section id="donts" class="level3">
<h3 class="anchored" data-anchor-id="donts">Don’ts</h3>
<ul>
<li><strong>Don’t reinvent the wheel.</strong> If you know of a great explanation of something elsewhere, link to it! Include a quote or one sentence summary about the resource you’re linking to.</li>
<li><strong>Don’t try to build everything up from first principles.</strong> For example, if you want to explain the transformer architecture, don’t begin by defining machine learning. Who is your target audience? People already familiar with machine learning will lose interest, and those who are brand new to machine learning are probably not seeking out posts on the transformer architecture. You can assume that your reader already has a certain background (sometimes it is helpful to make this explicit).</li>
<li><strong>Don’t be afraid to have an opinion.</strong> For example, TensorFlow (circa 2016, before eager execution) <a href="https://twitter.com/math_rachel/status/821044526571614208">made me feel unintelligent</a>, even though everyone else seemed to be saying how awesome it was. I was pretty nervous <a href="https://www.fast.ai/2017/01/03/keras/">writing a blog post</a> that said this, but a lot of people responded positively.</li>
<li><strong>Don’t be too dull or dry.</strong> If people lose interest, they will stop reading, so you want to hook them (and keep them hooked!)</li>
<li><strong>Don’t plagiarize.</strong> Always cite sources, and use quote marks around direct quotes. Do this even as you are first gathering sources and taking notes, so you don’t make a mistake later and forget which material is someone else’s. It is wrong to plagiarize the work of others and ultimately will hurt your reputation. Cite and link to people who have given you ideas.</li>
<li><strong>Don’t be too general.</strong> You don’t have to cover everything on a topic– focus on the part that interests (or frustrates) you most.</li>
</ul>
</section>
</section>
<section id="put-the-time-in-to-do-it-well" class="level2">
<h2 class="anchored" data-anchor-id="put-the-time-in-to-do-it-well">Put the time in to do it well</h2>
<p>As DeepMind researcher and University of Oxford PhD student <a href="https://hackernoon.com/interview-with-deep-learning-researcher-and-leader-of-openmined-andrew-trask-77cd33570a8c">Andrew Trask advised</a>, “<em>The secret to getting into the deep learning community is high quality blogging… Don’t just write something ok, either—take 3 or 4 full days on a post and try to make it as short and simple (yet complete) as possible.</em>” Honestly, I’ve spent far more than 3 or 4 days on <a href="https://rachel.fast.ai/posts/2018-04-29-categorical-embeddings/">many of</a> <a href="https://www.fast.ai/posts/2017-03-01-changing-careers.html">my most</a> <a href="https://rachel.fast.ai/posts/2018-07-23-automl3/">popular</a> <a href="https://rachel.fast.ai/posts/2018-07-12-automl1/">posts</a>.</p>
<p>However, this doesn’t mean that you need to be a “naturally gifted” writer. I attended a poor, public high school in a small city in Texas, where I had few writing assignments and didn’t really learn to write a proper essay. An introductory English class my first semester of college highlighted how much I struggled with writing, and after that, I tried to avoid classes that would require much writing (part of the reason I studied math and computer science is that those were the only fields I knew of that involved minimal writing AND didn’t have lab sessions). It wasn’t until I was in my 30s and <a href="https://medium.com/tech-diversity-files/if-you-think-women-in-tech-is-just-a-pipeline-problem-you-haven-t-been-paying-attention-cb7a2073b996">wanted to start blogging</a> that I began to practice writing. I typically go through many, many drafts, and do lots of revisions. As with most things, <a href="https://hbr.org/2007/07/the-making-of-an-expert">skill is not innate</a>; it is something you build through deliberate practice.</p>
<p>Note: I realize many people may not have time to blog– perhaps you are a parent, dealing with chronic illness, suffering burnout from a toxic job, or prefer to do other things in your free time– that’s alright! You can still have a successful career without blogging, this post is only for those who are interested.</p>
</section>
<section id="write-a-blog-version-of-your-academic-paper" class="level2">
<h2 class="anchored" data-anchor-id="write-a-blog-version-of-your-academic-paper">Write a blog version of your academic paper</h2>
<p>The top item on my wish list for AI researchers is that more of them would write blog posts to accompany their papers:</p>
<center>
<blockquote class="twitter-tweet blockquote" data-lang="en">
<p lang="en" dir="ltr">
my wish list for AI researchers <a href="https://t.co/Cel5x32K9O">https://t.co/Cel5x32K9O</a> <a href="https://t.co/AyYBqwYDFX">pic.twitter.com/AyYBqwYDFX</a>
</p>
— Rachel Thomas (<span class="citation" data-cites="math_rachel">@math_rachel</span>) <a href="https://twitter.com/math_rachel/status/983874014392152064?ref_src=twsrc%5Etfw">April 11, 2018</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<p>Far more people may read your blog post than will read an academic paper. This is a chance to get your message to a broader audience, in a more conversational and accessible format. You can and should link to your academic paper from your blog post, so there’s no need to worry about including all the technical details. People will read your paper if they want more detail!</p>
<p>Check out these excellent pairs of academic papers and blog posts for inspiration: - <a href="http://gendershades.org/overview.html">Gender Shades</a> (blog post &amp; visualization) and <a href="http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf">Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification</a> (paper), by Joy Buolamwini &amp; Timnit Gebru - <a href="https://medium.com/@harinisuresh/the-problem-with-biased-data-5700005e514c">The Problem with “Biased Data”</a> (blog post) and <a href="https://arxiv.org/abs/1901.10002">A Framework for Understanding Unintended Consequences of Machine Learning</a> (paper), by Harini Suresh &amp; John Guttag - <a href="http://nlp.fast.ai/">Introducing state of the art text classification with universal language models</a> (blog post) and <a href="https://arxiv.org/abs/1801.06146">Universal Language Model Fine-tuning for Text Classification</a> (paper), by Jeremy Howard &amp; Sebastian Ruder</p>
<p>I usually advise new bloggers that your target audience could be you-6-months-ago. For grad students, you may need to change this to you-2-years-ago. Assume that unlike your paper reviewers, the reader of your blog post has not read the related research papers. Assume your audience is intelligent, but not in your subfield. What does it take to explain your research to a friend in a different field?</p>
</section>
<section id="getting-started-with-your-first-post" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-your-first-post">Getting Started with your first post</h2>
<p>Here are some tips I’ve <a href="https://medium.com/@racheltho/why-you-yes-you-should-blog-7d2544ac1045">shared previously</a> to help you start your first post:</p>
<ul>
<li>Make a list of links to other blog posts, articles, or studies that you like, and write brief summaries or highlight what you particularly like about them. Part of my first blog post came from my making just such a list, because I couldn’t believe more people hadn’t read the posts and articles that I thought were awesome.</li>
<li>Summarize what you learned at a conference you attended, or in a class you are taking.</li>
<li>Any email you’ve written twice should be a blog post. Now, if I’m asked a question that I think someone else would also be interested in, I try to write it up.</li>
<li>You are best positioned to help people one step behind you. The material is still fresh in your mind. Many experts have forgotten what it was like to be a beginner (or an intermediate) and have forgotten why the topic is hard to understand when you first hear it.</li>
<li>What would have helped you a year ago? What would have helped you a week ago?</li>
<li>If you’re wondering about the actual logistics, <a href="https://medium.com/new-story">Medium</a> makes it super simple to get started. Another option is to use <a href="https://help.github.com/articles/using-jekyll-as-a-static-site-generator-with-github-pages/">Jekyll and Github pages</a>. I can personally recommend both, as I have 2 blogs and use one for each (my <a href="https://medium.com/@racheltho">other blog is here</a>).</li>
</ul>
</section>
<section id="related-posts" class="level2">
<h2 class="anchored" data-anchor-id="related-posts">Related Posts</h2>
<ul>
<li><a href="https://rachel.fast.ai/posts/2017-12-18-personal-brand/">Making Peace with Personal Branding</a></li>
<li><a href="https://www.fast.ai/posts/2017-04-06-alternatives.html">Alternatives to a Degree to Prove Yourself in Deep Learning</a></li>
<li><a href="https://www.fast.ai/posts/2018-04-10-stanford-salon.html">A Discussion about Accessibility in AI at Stanford</a></li>
</ul>


</section>

<p><br><br><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p> ]]></description>
  <category>advice</category>
  <guid>https://rachel.fast.ai/posts/2019-05-13-blogging-advice/index.html</guid>
  <pubDate>Sun, 12 May 2019 14:00:00 GMT</pubDate>
  <media:content url="https://rachel.fast.ai/posts/2019-05-13-blogging-advice/blog.jpeg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
